2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('Замена полисов ОМС: разбор телефонной аферы',), kwargs={}
Результат: замена полисов омс разбор телефонной аферы
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: contains_keywords
Аргументы: args=('Замена полисов ОМС: разбор телефонной аферы', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('Всем привет! На связи снова Яков Филевский, эксперт по социотехническому тестированию Angara Security, поделился опытом общения с мошенникамиВ разгар рабочего дня вам звонят с мобильного номера (в моём случае — оператор «Сбер Мобайл»). Голос уверенный, деловой, даже слегка фамильярный:\xa0 — «Здравствуйте, я представляю вашу страховую компанию. Сейчас идёт массовый обмен старых ОМС-полисов на новый образец с QR-кодом. Подтвердите, пожалуйста: у вас полис пластиковый или электронный?».\xa0 Затем собеседник мгновенно называет ваши ФИО и дату рождения — данные, которые должны быть известны только официальным структурам… или мошенникам.\xa0 Первый крючок: эффект авторитета\xa0 Когда незнакомец свободно оперирует вашими персональными данными, срабатывает автоматическое доверие: «Раз знает такие детали — наверное, действительно из страховой». Но это ловушка. Персональные данные давно не признак легитимности — их сливают из баз или получают через утечки.\xa0 Давление и управление разговором\xa0 Мошенник говорит быстро, сыпет терминами, не оставляет времени на раздумья:\xa0 — «Новый полис будет пластиковым, но с QR-кодом, он позволит получать часть лекарств безоплатно. Вам всё понятно?».\xa0 Ответ ждут только «да» или «нет». Если вы говорите «ну, допустим», собеседник раздражённо переспрашивает: «Значит, да?» — и продолжает. Это не случайно: последовательные «да» создают иллюзию согласия.\xa0 Фиктивный выбор и ложное ощущение контроля\xa0 — «Где вам удобнее получить полис: в МФЦ или в страховой?».Вопрос бессмысленный — замены полисов нет. Но он вовлекает вас в процесс, закрепляя доверие.\xa0 Подготовка к финальному обману\xa0 — «В течение нескольких дней придёт уведомление на "Госуслуги"».\xa0 Здесь нет ничего подозрительного: ни номера карты, ни оплаты. Всё выглядит как бюрократическая формальность.\xa0 И только в конце, будто мельком:\xa0 — «Сейчас завершим регистрацию. На ваш номер придёт код — подтвердите, пожалуйста».\xa0 Если назвать код из SMS (например, от finuslugiru), мошенники зарегистрируют учётную запись на платформе «Финуслуги» (официальный маркетплейс ЦБ РФ) и смогут оформить микрозаймы от вашего имени.\xa0 Почему это работает? Психология аферы\xa0 С психологической точки зрения эта схема рассчитана на несколько ключевых уязвимостей. Первая — уважение к авторитету. Голос уверенный, темп деловой, манера общения напоминает службу, с которой трудно спорить. Вторая — информационная перегрузка. В быстро сменяющемся потоке слов человеку сложно заметить, что всё происходящее лишёно логической основы. Третья — избегание конфликта. Многим людям тяжело прерывать разговор с якобы официальным представителем: это воспринимается как неуважение, и потому они продолжают диалог из вежливости, даже если интуитивно что-то кажется странным. И, наконец, четвёртая — желание «быстрее закончить». Когда человеку навязывают длинную процедуру, он может согласиться на завершающий шаг (ввести код), лишь бы поскорее это завершилось.Если бы в описанном случае код был введён, мошенники получили бы доступ к полноценной учётной записи, оформленной на имя жертвы. После этого происходят классические действия: заявка на микрозайм, смена контактных данных в личном кабинете, возможно — попытка доступа к иным государственным сервисам. Последствия — долгие месяцы споров, оспаривание долгов, восстановление кредитной истории и утечка персональных данных.  Как защититься?\xa0 1. Никогда не сообщайте коды из SMS — даже если звонят «из банка» или «от государства».\xa0 2. Прервите подозрительный звонок — вежливо скажите «Я перезвоню сам» и положите трубку.\xa0 3. Проверяйте информацию — позвоните в страховую по номеру с полиса или в МФЦ.\xa0 4. Не переходите по ссылкам и не вводите данные под диктовку — госорганы так не работают.\xa0 5. Не бойтесь сказать «нет» — вежливость не должна перевешивать безопасность.\xa0 6. Включайте запись звонков — это поможет в случае мошенничества.\xa0 7. Если код всё же назвали — срочно меняйте пароли на «Госуслугах» и в банках, подайте заявление в полицию.\xa0 8. Запретите дистанционное оформление кредитов — это можно сделать через МФЦ или приложение «Госуслуги».\xa0 9. Помните: массовые замены полисов анонсируют официально — через СМИ, сайты ведомств, рассылки.\xa0 Финансовое мошенничество стало технологичным и психологически выверенным. Умение распознать сценарий, не поддаться эмоциональному давлению и взять паузу — ключевые навыки, которые сегодня критически важны для нашей безопасности.',), kwargs={}
Результат: всем привет на связи снова яков филевский эксперт по социотехническому тестированию angara security поделился опытом общения с мошенникамив разгар рабочего дня вам звонят с мобильного номера в моём случае  оператор сбер мобайл голос уверенный деловой даже слегка фамильярный   здравствуйте я представляю вашу страховую компанию сейчас идёт массовый обмен старых омсполисов на новый образец с qrкодом подтвердите пожалуйста у вас полис пластиковый или электронный  затем собеседник мгновенно называет ваши фио и дату рождения  данные которые должны быть известны только официальным структурам или мошенникам  первый крючок эффект авторитета  когда незнакомец свободно оперирует вашими персональными данными срабатывает автоматическое доверие раз знает такие детали  наверное действительно из страховой но это ловушка персональные данные давно не признак легитимности  их сливают из баз или получают через утечки  давление и управление разговором  мошенник говорит быстро сыпет терминами не оставляет времени на раздумья   новый полис будет пластиковым но с qrкодом он позволит получать часть лекарств безоплатно вам всё понятно  ответ ждут только да или нет если вы говорите ну допустим собеседник раздражённо переспрашивает значит да  и продолжает это не случайно последовательные да создают иллюзию согласия  фиктивный выбор и ложное ощущение контроля   где вам удобнее получить полис в мфц или в страховойвопрос бессмысленный  замены полисов нет но он вовлекает вас в процесс закрепляя доверие  подготовка к финальному обману   в течение нескольких дней придёт уведомление на госуслуги  здесь нет ничего подозрительного ни номера карты ни оплаты всё выглядит как бюрократическая формальность  и только в конце будто мельком   сейчас завершим регистрацию на ваш номер придёт код  подтвердите пожалуйста  если назвать код из sms например от finuslugiru мошенники зарегистрируют учётную запись на платформе финуслуги официальный маркетплейс цб рф и смогут оформить микрозаймы от вашего имени  почему это работает психология аферы  с психологической точки зрения эта схема рассчитана на несколько ключевых уязвимостей первая  уважение к авторитету голос уверенный темп деловой манера общения напоминает службу с которой трудно спорить вторая  информационная перегрузка в быстро сменяющемся потоке слов человеку сложно заметить что всё происходящее лишёно логической основы третья  избегание конфликта многим людям тяжело прерывать разговор с якобы официальным представителем это воспринимается как неуважение и потому они продолжают диалог из вежливости даже если интуитивно чтото кажется странным и наконец четвёртая  желание быстрее закончить когда человеку навязывают длинную процедуру он может согласиться на завершающий шаг ввести код лишь бы поскорее это завершилосьесли бы в описанном случае код был введён мошенники получили бы доступ к полноценной учётной записи оформленной на имя жертвы после этого происходят классические действия заявка на микрозайм смена контактных данных в личном кабинете возможно  попытка доступа к иным государственным сервисам последствия  долгие месяцы споров оспаривание долгов восстановление кредитной истории и утечка персональных данных  как защититься  1 никогда не сообщайте коды из sms  даже если звонят из банка или от государства  2 прервите подозрительный звонок  вежливо скажите я перезвоню сам и положите трубку  3 проверяйте информацию  позвоните в страховую по номеру с полиса или в мфц  4 не переходите по ссылкам и не вводите данные под диктовку  госорганы так не работают  5 не бойтесь сказать нет  вежливость не должна перевешивать безопасность  6 включайте запись звонков  это поможет в случае мошенничества  7 если код всё же назвали  срочно меняйте пароли на госуслугах и в банках подайте заявление в полицию  8 запретите дистанционное оформление кредитов  это можно сделать через мфц или приложение госуслуги  9 помните массовые замены полисов анонсируют официально  через сми сайты ведомств рассылки  финансовое мошенничество стало технологичным и психологически выверенным умение распознать сценарий не поддаться эмоциональному давлению и взять паузу  ключевые навыки которые сегодня критически важны для нашей безопасности
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: contains_keywords
Аргументы: args=('Всем привет! На связи снова Яков Филевский, эксперт по социотехническому тестированию Angara Security, поделился опытом общения с мошенникамиВ разгар рабочего дня вам звонят с мобильного номера (в моём случае — оператор «Сбер Мобайл»). Голос уверенный, деловой, даже слегка фамильярный:\xa0 — «Здравствуйте, я представляю вашу страховую компанию. Сейчас идёт массовый обмен старых ОМС-полисов на новый образец с QR-кодом. Подтвердите, пожалуйста: у вас полис пластиковый или электронный?».\xa0 Затем собеседник мгновенно называет ваши ФИО и дату рождения — данные, которые должны быть известны только официальным структурам… или мошенникам.\xa0 Первый крючок: эффект авторитета\xa0 Когда незнакомец свободно оперирует вашими персональными данными, срабатывает автоматическое доверие: «Раз знает такие детали — наверное, действительно из страховой». Но это ловушка. Персональные данные давно не признак легитимности — их сливают из баз или получают через утечки.\xa0 Давление и управление разговором\xa0 Мошенник говорит быстро, сыпет терминами, не оставляет времени на раздумья:\xa0 — «Новый полис будет пластиковым, но с QR-кодом, он позволит получать часть лекарств безоплатно. Вам всё понятно?».\xa0 Ответ ждут только «да» или «нет». Если вы говорите «ну, допустим», собеседник раздражённо переспрашивает: «Значит, да?» — и продолжает. Это не случайно: последовательные «да» создают иллюзию согласия.\xa0 Фиктивный выбор и ложное ощущение контроля\xa0 — «Где вам удобнее получить полис: в МФЦ или в страховой?».Вопрос бессмысленный — замены полисов нет. Но он вовлекает вас в процесс, закрепляя доверие.\xa0 Подготовка к финальному обману\xa0 — «В течение нескольких дней придёт уведомление на "Госуслуги"».\xa0 Здесь нет ничего подозрительного: ни номера карты, ни оплаты. Всё выглядит как бюрократическая формальность.\xa0 И только в конце, будто мельком:\xa0 — «Сейчас завершим регистрацию. На ваш номер придёт код — подтвердите, пожалуйста».\xa0 Если назвать код из SMS (например, от finuslugiru), мошенники зарегистрируют учётную запись на платформе «Финуслуги» (официальный маркетплейс ЦБ РФ) и смогут оформить микрозаймы от вашего имени.\xa0 Почему это работает? Психология аферы\xa0 С психологической точки зрения эта схема рассчитана на несколько ключевых уязвимостей. Первая — уважение к авторитету. Голос уверенный, темп деловой, манера общения напоминает службу, с которой трудно спорить. Вторая — информационная перегрузка. В быстро сменяющемся потоке слов человеку сложно заметить, что всё происходящее лишёно логической основы. Третья — избегание конфликта. Многим людям тяжело прерывать разговор с якобы официальным представителем: это воспринимается как неуважение, и потому они продолжают диалог из вежливости, даже если интуитивно что-то кажется странным. И, наконец, четвёртая — желание «быстрее закончить». Когда человеку навязывают длинную процедуру, он может согласиться на завершающий шаг (ввести код), лишь бы поскорее это завершилось.Если бы в описанном случае код был введён, мошенники получили бы доступ к полноценной учётной записи, оформленной на имя жертвы. После этого происходят классические действия: заявка на микрозайм, смена контактных данных в личном кабинете, возможно — попытка доступа к иным государственным сервисам. Последствия — долгие месяцы споров, оспаривание долгов, восстановление кредитной истории и утечка персональных данных.  Как защититься?\xa0 1. Никогда не сообщайте коды из SMS — даже если звонят «из банка» или «от государства».\xa0 2. Прервите подозрительный звонок — вежливо скажите «Я перезвоню сам» и положите трубку.\xa0 3. Проверяйте информацию — позвоните в страховую по номеру с полиса или в МФЦ.\xa0 4. Не переходите по ссылкам и не вводите данные под диктовку — госорганы так не работают.\xa0 5. Не бойтесь сказать «нет» — вежливость не должна перевешивать безопасность.\xa0 6. Включайте запись звонков — это поможет в случае мошенничества.\xa0 7. Если код всё же назвали — срочно меняйте пароли на «Госуслугах» и в банках, подайте заявление в полицию.\xa0 8. Запретите дистанционное оформление кредитов — это можно сделать через МФЦ или приложение «Госуслуги».\xa0 9. Помните: массовые замены полисов анонсируют официально — через СМИ, сайты ведомств, рассылки.\xa0 Финансовое мошенничество стало технологичным и психологически выверенным. Умение распознать сценарий, не поддаться эмоциональному давлению и взять паузу — ключевые навыки, которые сегодня критически важны для нашей безопасности.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('Внедрение ML кластера для масштабирования AI сервисов',), kwargs={}
Результат: внедрение ml кластера для масштабирования ai сервисов
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: contains_keywords
Аргументы: args=('Внедрение ML кластера для масштабирования AI сервисов', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:09 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('Привет! С вами Олег, Рамиль и Андрей из Flocktory. Мы руководим машинным обучением и разработкой в компании, сейчас активно внедряем AI для лучшей персонализации. В прошлом году наши команды реализовали ML-сервисы, внедрили ML Feature Store и переработали жизненный цикл моделей (о чём мы подробно рассказывали на HighLoad++: https://highload.ru/moscow/2024/abstracts/12929). В этой статье поразмышляем над следующим шагом для среднего размера компании, которая внедряет AI – как масштабировать проекты машинного обучения. Обработка, анализ и обучение на данных влекут за собой применение ML систем, в том числе нейросетей. Это требует больших вычислительных ресурсов: сотни гигабайт ОЗУ, десятки ядер CPU, а также видеокарты и (или) специальные чипы для ускорения вычислений.Рассмотрим основные варианты ресурсов, которые можно использовать, сложности, связанные с их эксплуатацией, целесообразность вложений и vendor lock. Но сначала поговорим о природе трудностей, возникающих при масштабировании.Проблемы с масштабированием и откуда они берутсяНа первый взгляд кажется, что если вы хорошо решаете задачи малыми усилиями, то с большими ресурсами делать это будет еще проще. Но нет. И вот несколько причин, почему так:При работе над крупной системой в большой разнородной команде, где есть аналитики и исследователи данных, инженеры-разработчики, системные инженеры и так далее, сотрудники из разных команд часто используют различные инструменты для решения задач. Это касается как сред разработки и исполнения (Python, Matlab, Java, C/C++ etc.) так и используемых баз данных (RDBMS, NO SQL, файлы и пр.). Переквалификация может быть долгой, дорогой или невозможной в краткосрочной перспективе.Внедрение новых технологий может сделать неудобным или невозможным использование единого инструментария. К примеру, основная часть ML системы может быть реализована на Java, но при имплементации новой модели могут потребоваться библиотеки на Python, C/С++ etc. Их придется интегрировать: повторная имплементация фич в текущем инструментарии может потребовать много времени и чревата большими издержками для бизнеса.Вертикальное масштабирование системы может быть недоступно или слишком дорого. Конечно, это зависит от мощностей дата-центров вашего провайдера, но у любого из них есть практический предел. Это ограничивает увеличение вычислительных ресурсов на одном узле. Приходится использовать несколько узлов, объединенных в кластер, чтобы достичь требуемых мощностей.В ряде случаев, когда требуется специализированное оборудование для вычислений, например, Nvidia Tesla и Tensor Cores, целесообразна покупка собственных серверов и установка их в дата-центрах провайдера.Какие решения существуют?Для решения проблем неоднородности инструментария используется контейнеризация приложений с помощью Docker и система оркестрации контейнеров.\xa0Контейнерное приложение – это приложение и необходимая для него среда исполнения, собранные в определенном формате для запуска в изолированной среде в системе управления контейнерными приложениями.В контейнерах могут быть практически любые приложения прикладного и системного уровня. они будут запущены в изолированной среде, что позволяет избегать конфликтов между системными библиотеками, а также гибко разграничивать доступ и ресурсы.Docker – это наиболее распространенная платформа контейнеризации приложений. В ее состав входят как инструменты позволяющие собирать контейнерные приложения, так и демон, позволяющий запускать контейниризованные приложения и управлять ими в пределах одного узла.Kubernetes – самая известная и стандартизированная система оркестрации контейнеров в кластере. Kubernetes кластеры доступны практически у любого крупного облачного провайдера (AWS, Azure, GCP и пр.).\xa0Оговорюсь, что существуют другие технологии контейнеризации и кластерные системы управления контейнерами, но Kubernetes on Docker – наиболее распространенные и стандартные решения сейчас.\xa0Сначала поговорим об особенностях выбора платформы для Kubernetes, а потом – об особенностях архитектуры ML систем в кластере Kubernetes. Как я отметил выше, основные варианты – это managed кластер in cloud или собственный кластер on bare metal. Рассмотрим подробнее эти варианты.Кластер в облакеПлюсы:Обслуживанием занимается облачный провайдер. Отдельный администратор кластера не требуется, чаще всего разработчики сами справятся.Доступны базы данных и другая инфраструктура с автоматическим масштабированием (S3, DynamoDB, RDS, Redshift и пр.).Возможность быстро изменять количество ресурсов кластера при возникновении такой потребности.Неисправности происходят реже.Минусы:Дорого, очевидно что bare metal сервера стоят дешевле без учета поддержки.Большая вероятность получить жесткий vendor lock-in при использовании технологий провайдера (например, DynamoDB)Неисправности, когда случаются, чинятся дольше.Выбор оборудования ограничен, невозможно использовать специфическое железо.Часто непрозрачное ценообразование.Комментарий:Конечно, сначала проще пользоваться managed кластером, чем разворачивать свой. Но потом, при возникновении проблем в расследованиях с траблшутингом, поиск причины и возможного решения может быть гораздо более долгим и болезненным. Вы будете ограничены в доступе к системному уровню, что влечет дополнительные сложности в диагностике и решении этих проблем. Некоторые, возможно, вы и не сможете решить самостоятельно при отсутствии доступа к системному уровню, придется ожидать помощи техподдержки.С осторожностью нужно относиться к проприетарным сервисам in cloud. Они формируют vendor lock-in. Если вас перестанет устраивать провайдер, вам будет тяжелее отказаться от его услуг из-за внедренных решений на базе этих продуктов (например, проприетарные NO SQL хранилища).Собственный кластер на физических серверахПлюсы:Аренда физических серверов у хостеров в несколько раз дешевле аренды узлов у cloud провайдеров (пример сравнения цен будет ниже).\xa0Большая гибкость в выборе, конфигурировании и размещении оборудования. Colocation. Можно собрать собственные и разместить их в дата-центре. Актуально при использовании специфического оборудования (видеокарты, тензорные ядра, аппаратное шифрование и пр.).Скорость устранения неисправностей часто выше, этому способствует отсутствие жестких vendor lock-in, что вводит возможность быстрой миграции и широту выбора решений провайдеров.Большая гибкость в выборе и конфигурации систем и сервисов.Минусы:\xa0Для обслуживания кластера, включая развертывание, мониторинг, резервирование, требуется выделенный эксперт или даже целая команда администрирования.Неисправности на раннем этапе происходят чаще, в зависимости от квалификации эксперта.Масштабирование требует больше времени, в том числе на добавление серверов, изменение конфигурации, не исключена миграция между стойками и (или) датацентрами.Комментарий:При выборе оборудования надо отдать предпочтение именно dedicated серверам. При использовании virtual серверов можно заметить периодические просадки по IO или CPU – это аффектит скорость и стабильность вычислений.Также имеет смысл обратить внимание на организацию сети между вашими серверами. Размещение в одном дата-центре – это хорошо, но гораздо лучше – в одной стойке и на одном коммутаторе. Скорость и стабильность связи между вашими серверами убирает множество проблем. У bare metal providers услуга размещения серверов на одной стойке называется colocation, обращайте на нее внимание.Архитектура ML кластераРассмотрим минимальную схему кластера с типизацией по узлам, чтобы говорить предметнее. Каждый тип узла может быть отмаcштабирован в зависимости от требований.На узлах Data приложений собираются данные для ML приложений. Хранилище Мастер Данных – это хранилище, в которое поды Data приложений загружают подготовленные данные. Если весь набор данных помещается в локальное хранилище узлов, то рекомендуется делать полную репликацию этих данных на все узлы. Это значительно снижает количество сбоев и нагрузку на сеть, когда поды с ML приложением читают данные. В качестве Хранилища Мастер Данных можно использовать ClickHouse и (или) MinIO.Можно использовать colocation и подключить всю стойку (rack) к одному быстрому 10GE коммутатору. Однако, даже в этом случае, подготовленные данные важно грамотно сгруппировать. Это позволит использовать один из бинарных форматов хранения, тем самым исключить накладные расходы на парсинг, обращайте на это внимание.На узлах ML приложений запускаются модели и связанные с ними функции. Они делают инференс и фиксируют результат. Узлы Хранилища Результатов Данных должны уметь принять результаты анализа данных, оценить их и предоставить доступ к ним извне. В качестве Хранилища Мастер Данных можно использовать ClickHouse и (или) MinIO.Можно написать свой планировщик, используя Kubernetes API, либо воспользоваться встроенным в Dagster, Airflow и других планировщиках. В имплементации важно иметь контроль количества записей в etcd для подов. Завершившиеся поды приложений нужно периодически очищать, иначе etcd распухнет и кластер умрет.Распределение нагрузки по нескольким узлам. При работе ML приложений ресурсы задействованы максимально, и это типичная ситуация, Важно, чтобы для системных сервисов всегда оставались свободные ресурсы. Исключение – environments for dev testing, в целях экономии их можно размещать на одном узле.Резервирование должно быть выделено в отдельную систему, которая не зависит от работы самой ML системы. Важно, чтобы она включала в себя создание набора бекапов в разные моменты времени и их тестирование в плановых учениях по отработке внезапных отказов.ВыводыКогда ваши ML сервисы только развиваются и не потребляют ресурсы круглосуточно, целесообразно пользоваться услугами in cloud. Можно арендовать spot и on-demand инстансы под выполнение конкретной задачи чтобы не платить за них постоянно. Да, это в разы дороже, чем virtual или bare metal инстансы (в пересчете на часы), но особенность оплаты по часам, в которых были действительно задействованы эти ресурсы, поможет сэкономить здесь и сейчас.Если ваши ML сервисы будут круглосуточно нагружать кластер, то, при наличии экспертизы в команде, целесообразно рассмотреть bare metal провайдера. При отсутствии специальных скидок от cloud провайдера, даже при максимальной экономии и с учетом пакетных годовых офферов, стоимость virtual инстансов будет выше, чем стоимость bare metal инстансов. При резервировании менее чем на год — еще выше. ',), kwargs={}
Результат: привет с вами олег рамиль и андрей из flocktory мы руководим машинным обучением и разработкой в компании сейчас активно внедряем ai для лучшей персонализации в прошлом году наши команды реализовали mlсервисы внедрили ml feature store и переработали жизненный цикл моделей о чём мы подробно рассказывали на highload httpshighloadrumoscow2024abstracts12929 в этой статье поразмышляем над следующим шагом для среднего размера компании которая внедряет ai  как масштабировать проекты машинного обучения обработка анализ и обучение на данных влекут за собой применение ml систем в том числе нейросетей это требует больших вычислительных ресурсов сотни гигабайт озу десятки ядер cpu а также видеокарты и или специальные чипы для ускорения вычисленийрассмотрим основные варианты ресурсов которые можно использовать сложности связанные с их эксплуатацией целесообразность вложений и vendor lock но сначала поговорим о природе трудностей возникающих при масштабированиипроблемы с масштабированием и откуда они берутсяна первый взгляд кажется что если вы хорошо решаете задачи малыми усилиями то с большими ресурсами делать это будет еще проще но нет и вот несколько причин почему такпри работе над крупной системой в большой разнородной команде где есть аналитики и исследователи данных инженерыразработчики системные инженеры и так далее сотрудники из разных команд часто используют различные инструменты для решения задач это касается как сред разработки и исполнения python matlab java cc etc так и используемых баз данных rdbms no sql файлы и пр переквалификация может быть долгой дорогой или невозможной в краткосрочной перспективевнедрение новых технологий может сделать неудобным или невозможным использование единого инструментария к примеру основная часть ml системы может быть реализована на java но при имплементации новой модели могут потребоваться библиотеки на python cс etc их придется интегрировать повторная имплементация фич в текущем инструментарии может потребовать много времени и чревата большими издержками для бизнесавертикальное масштабирование системы может быть недоступно или слишком дорого конечно это зависит от мощностей датацентров вашего провайдера но у любого из них есть практический предел это ограничивает увеличение вычислительных ресурсов на одном узле приходится использовать несколько узлов объединенных в кластер чтобы достичь требуемых мощностейв ряде случаев когда требуется специализированное оборудование для вычислений например nvidia tesla и tensor cores целесообразна покупка собственных серверов и установка их в датацентрах провайдеракакие решения существуютдля решения проблем неоднородности инструментария используется контейнеризация приложений с помощью docker и система оркестрации контейнеров контейнерное приложение  это приложение и необходимая для него среда исполнения собранные в определенном формате для запуска в изолированной среде в системе управления контейнерными приложениямив контейнерах могут быть практически любые приложения прикладного и системного уровня они будут запущены в изолированной среде что позволяет избегать конфликтов между системными библиотеками а также гибко разграничивать доступ и ресурсыdocker  это наиболее распространенная платформа контейнеризации приложений в ее состав входят как инструменты позволяющие собирать контейнерные приложения так и демон позволяющий запускать контейниризованные приложения и управлять ими в пределах одного узлаkubernetes  самая известная и стандартизированная система оркестрации контейнеров в кластере kubernetes кластеры доступны практически у любого крупного облачного провайдера aws azure gcp и пр оговорюсь что существуют другие технологии контейнеризации и кластерные системы управления контейнерами но kubernetes on docker  наиболее распространенные и стандартные решения сейчас сначала поговорим об особенностях выбора платформы для kubernetes а потом  об особенностях архитектуры ml систем в кластере kubernetes как я отметил выше основные варианты  это managed кластер in cloud или собственный кластер on bare metal рассмотрим подробнее эти вариантыкластер в облакеплюсыобслуживанием занимается облачный провайдер отдельный администратор кластера не требуется чаще всего разработчики сами справятсядоступны базы данных и другая инфраструктура с автоматическим масштабированием s3 dynamodb rds redshift и првозможность быстро изменять количество ресурсов кластера при возникновении такой потребностинеисправности происходят режеминусыдорого очевидно что bare metal сервера стоят дешевле без учета поддержкибольшая вероятность получить жесткий vendor lockin при использовании технологий провайдера например dynamodbнеисправности когда случаются чинятся дольшевыбор оборудования ограничен невозможно использовать специфическое железочасто непрозрачное ценообразованиекомментарийконечно сначала проще пользоваться managed кластером чем разворачивать свой но потом при возникновении проблем в расследованиях с траблшутингом поиск причины и возможного решения может быть гораздо более долгим и болезненным вы будете ограничены в доступе к системному уровню что влечет дополнительные сложности в диагностике и решении этих проблем некоторые возможно вы и не сможете решить самостоятельно при отсутствии доступа к системному уровню придется ожидать помощи техподдержкис осторожностью нужно относиться к проприетарным сервисам in cloud они формируют vendor lockin если вас перестанет устраивать провайдер вам будет тяжелее отказаться от его услуг изза внедренных решений на базе этих продуктов например проприетарные no sql хранилищасобственный кластер на физических серверахплюсыаренда физических серверов у хостеров в несколько раз дешевле аренды узлов у cloud провайдеров пример сравнения цен будет ниже большая гибкость в выборе конфигурировании и размещении оборудования colocation можно собрать собственные и разместить их в датацентре актуально при использовании специфического оборудования видеокарты тензорные ядра аппаратное шифрование и прскорость устранения неисправностей часто выше этому способствует отсутствие жестких vendor lockin что вводит возможность быстрой миграции и широту выбора решений провайдеровбольшая гибкость в выборе и конфигурации систем и сервисовминусы для обслуживания кластера включая развертывание мониторинг резервирование требуется выделенный эксперт или даже целая команда администрированиянеисправности на раннем этапе происходят чаще в зависимости от квалификации экспертамасштабирование требует больше времени в том числе на добавление серверов изменение конфигурации не исключена миграция между стойками и или датацентрамикомментарийпри выборе оборудования надо отдать предпочтение именно dedicated серверам при использовании virtual серверов можно заметить периодические просадки по io или cpu  это аффектит скорость и стабильность вычисленийтакже имеет смысл обратить внимание на организацию сети между вашими серверами размещение в одном датацентре  это хорошо но гораздо лучше  в одной стойке и на одном коммутаторе скорость и стабильность связи между вашими серверами убирает множество проблем у bare metal providers услуга размещения серверов на одной стойке называется colocation обращайте на нее вниманиеархитектура ml кластерарассмотрим минимальную схему кластера с типизацией по узлам чтобы говорить предметнее каждый тип узла может быть отмаcштабирован в зависимости от требованийна узлах data приложений собираются данные для ml приложений хранилище мастер данных  это хранилище в которое поды data приложений загружают подготовленные данные если весь набор данных помещается в локальное хранилище узлов то рекомендуется делать полную репликацию этих данных на все узлы это значительно снижает количество сбоев и нагрузку на сеть когда поды с ml приложением читают данные в качестве хранилища мастер данных можно использовать clickhouse и или minioможно использовать colocation и подключить всю стойку rack к одному быстрому 10ge коммутатору однако даже в этом случае подготовленные данные важно грамотно сгруппировать это позволит использовать один из бинарных форматов хранения тем самым исключить накладные расходы на парсинг обращайте на это вниманиена узлах ml приложений запускаются модели и связанные с ними функции они делают инференс и фиксируют результат узлы хранилища результатов данных должны уметь принять результаты анализа данных оценить их и предоставить доступ к ним извне в качестве хранилища мастер данных можно использовать clickhouse и или minioможно написать свой планировщик используя kubernetes api либо воспользоваться встроенным в dagster airflow и других планировщиках в имплементации важно иметь контроль количества записей в etcd для подов завершившиеся поды приложений нужно периодически очищать иначе etcd распухнет и кластер умретраспределение нагрузки по нескольким узлам при работе ml приложений ресурсы задействованы максимально и это типичная ситуация важно чтобы для системных сервисов всегда оставались свободные ресурсы исключение  environments for dev testing в целях экономии их можно размещать на одном узлерезервирование должно быть выделено в отдельную систему которая не зависит от работы самой ml системы важно чтобы она включала в себя создание набора бекапов в разные моменты времени и их тестирование в плановых учениях по отработке внезапных отказоввыводыкогда ваши ml сервисы только развиваются и не потребляют ресурсы круглосуточно целесообразно пользоваться услугами in cloud можно арендовать spot и ondemand инстансы под выполнение конкретной задачи чтобы не платить за них постоянно да это в разы дороже чем virtual или bare metal инстансы в пересчете на часы но особенность оплаты по часам в которых были действительно задействованы эти ресурсы поможет сэкономить здесь и сейчасесли ваши ml сервисы будут круглосуточно нагружать кластер то при наличии экспертизы в команде целесообразно рассмотреть bare metal провайдера при отсутствии специальных скидок от cloud провайдера даже при максимальной экономии и с учетом пакетных годовых офферов стоимость virtual инстансов будет выше чем стоимость bare metal инстансов при резервировании менее чем на год  еще выше 
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: contains_keywords
Аргументы: args=('Привет! С вами Олег, Рамиль и Андрей из Flocktory. Мы руководим машинным обучением и разработкой в компании, сейчас активно внедряем AI для лучшей персонализации. В прошлом году наши команды реализовали ML-сервисы, внедрили ML Feature Store и переработали жизненный цикл моделей (о чём мы подробно рассказывали на HighLoad++: https://highload.ru/moscow/2024/abstracts/12929). В этой статье поразмышляем над следующим шагом для среднего размера компании, которая внедряет AI – как масштабировать проекты машинного обучения. Обработка, анализ и обучение на данных влекут за собой применение ML систем, в том числе нейросетей. Это требует больших вычислительных ресурсов: сотни гигабайт ОЗУ, десятки ядер CPU, а также видеокарты и (или) специальные чипы для ускорения вычислений.Рассмотрим основные варианты ресурсов, которые можно использовать, сложности, связанные с их эксплуатацией, целесообразность вложений и vendor lock. Но сначала поговорим о природе трудностей, возникающих при масштабировании.Проблемы с масштабированием и откуда они берутсяНа первый взгляд кажется, что если вы хорошо решаете задачи малыми усилиями, то с большими ресурсами делать это будет еще проще. Но нет. И вот несколько причин, почему так:При работе над крупной системой в большой разнородной команде, где есть аналитики и исследователи данных, инженеры-разработчики, системные инженеры и так далее, сотрудники из разных команд часто используют различные инструменты для решения задач. Это касается как сред разработки и исполнения (Python, Matlab, Java, C/C++ etc.) так и используемых баз данных (RDBMS, NO SQL, файлы и пр.). Переквалификация может быть долгой, дорогой или невозможной в краткосрочной перспективе.Внедрение новых технологий может сделать неудобным или невозможным использование единого инструментария. К примеру, основная часть ML системы может быть реализована на Java, но при имплементации новой модели могут потребоваться библиотеки на Python, C/С++ etc. Их придется интегрировать: повторная имплементация фич в текущем инструментарии может потребовать много времени и чревата большими издержками для бизнеса.Вертикальное масштабирование системы может быть недоступно или слишком дорого. Конечно, это зависит от мощностей дата-центров вашего провайдера, но у любого из них есть практический предел. Это ограничивает увеличение вычислительных ресурсов на одном узле. Приходится использовать несколько узлов, объединенных в кластер, чтобы достичь требуемых мощностей.В ряде случаев, когда требуется специализированное оборудование для вычислений, например, Nvidia Tesla и Tensor Cores, целесообразна покупка собственных серверов и установка их в дата-центрах провайдера.Какие решения существуют?Для решения проблем неоднородности инструментария используется контейнеризация приложений с помощью Docker и система оркестрации контейнеров.\xa0Контейнерное приложение – это приложение и необходимая для него среда исполнения, собранные в определенном формате для запуска в изолированной среде в системе управления контейнерными приложениями.В контейнерах могут быть практически любые приложения прикладного и системного уровня. они будут запущены в изолированной среде, что позволяет избегать конфликтов между системными библиотеками, а также гибко разграничивать доступ и ресурсы.Docker – это наиболее распространенная платформа контейнеризации приложений. В ее состав входят как инструменты позволяющие собирать контейнерные приложения, так и демон, позволяющий запускать контейниризованные приложения и управлять ими в пределах одного узла.Kubernetes – самая известная и стандартизированная система оркестрации контейнеров в кластере. Kubernetes кластеры доступны практически у любого крупного облачного провайдера (AWS, Azure, GCP и пр.).\xa0Оговорюсь, что существуют другие технологии контейнеризации и кластерные системы управления контейнерами, но Kubernetes on Docker – наиболее распространенные и стандартные решения сейчас.\xa0Сначала поговорим об особенностях выбора платформы для Kubernetes, а потом – об особенностях архитектуры ML систем в кластере Kubernetes. Как я отметил выше, основные варианты – это managed кластер in cloud или собственный кластер on bare metal. Рассмотрим подробнее эти варианты.Кластер в облакеПлюсы:Обслуживанием занимается облачный провайдер. Отдельный администратор кластера не требуется, чаще всего разработчики сами справятся.Доступны базы данных и другая инфраструктура с автоматическим масштабированием (S3, DynamoDB, RDS, Redshift и пр.).Возможность быстро изменять количество ресурсов кластера при возникновении такой потребности.Неисправности происходят реже.Минусы:Дорого, очевидно что bare metal сервера стоят дешевле без учета поддержки.Большая вероятность получить жесткий vendor lock-in при использовании технологий провайдера (например, DynamoDB)Неисправности, когда случаются, чинятся дольше.Выбор оборудования ограничен, невозможно использовать специфическое железо.Часто непрозрачное ценообразование.Комментарий:Конечно, сначала проще пользоваться managed кластером, чем разворачивать свой. Но потом, при возникновении проблем в расследованиях с траблшутингом, поиск причины и возможного решения может быть гораздо более долгим и болезненным. Вы будете ограничены в доступе к системному уровню, что влечет дополнительные сложности в диагностике и решении этих проблем. Некоторые, возможно, вы и не сможете решить самостоятельно при отсутствии доступа к системному уровню, придется ожидать помощи техподдержки.С осторожностью нужно относиться к проприетарным сервисам in cloud. Они формируют vendor lock-in. Если вас перестанет устраивать провайдер, вам будет тяжелее отказаться от его услуг из-за внедренных решений на базе этих продуктов (например, проприетарные NO SQL хранилища).Собственный кластер на физических серверахПлюсы:Аренда физических серверов у хостеров в несколько раз дешевле аренды узлов у cloud провайдеров (пример сравнения цен будет ниже).\xa0Большая гибкость в выборе, конфигурировании и размещении оборудования. Colocation. Можно собрать собственные и разместить их в дата-центре. Актуально при использовании специфического оборудования (видеокарты, тензорные ядра, аппаратное шифрование и пр.).Скорость устранения неисправностей часто выше, этому способствует отсутствие жестких vendor lock-in, что вводит возможность быстрой миграции и широту выбора решений провайдеров.Большая гибкость в выборе и конфигурации систем и сервисов.Минусы:\xa0Для обслуживания кластера, включая развертывание, мониторинг, резервирование, требуется выделенный эксперт или даже целая команда администрирования.Неисправности на раннем этапе происходят чаще, в зависимости от квалификации эксперта.Масштабирование требует больше времени, в том числе на добавление серверов, изменение конфигурации, не исключена миграция между стойками и (или) датацентрами.Комментарий:При выборе оборудования надо отдать предпочтение именно dedicated серверам. При использовании virtual серверов можно заметить периодические просадки по IO или CPU – это аффектит скорость и стабильность вычислений.Также имеет смысл обратить внимание на организацию сети между вашими серверами. Размещение в одном дата-центре – это хорошо, но гораздо лучше – в одной стойке и на одном коммутаторе. Скорость и стабильность связи между вашими серверами убирает множество проблем. У bare metal providers услуга размещения серверов на одной стойке называется colocation, обращайте на нее внимание.Архитектура ML кластераРассмотрим минимальную схему кластера с типизацией по узлам, чтобы говорить предметнее. Каждый тип узла может быть отмаcштабирован в зависимости от требований.На узлах Data приложений собираются данные для ML приложений. Хранилище Мастер Данных – это хранилище, в которое поды Data приложений загружают подготовленные данные. Если весь набор данных помещается в локальное хранилище узлов, то рекомендуется делать полную репликацию этих данных на все узлы. Это значительно снижает количество сбоев и нагрузку на сеть, когда поды с ML приложением читают данные. В качестве Хранилища Мастер Данных можно использовать ClickHouse и (или) MinIO.Можно использовать colocation и подключить всю стойку (rack) к одному быстрому 10GE коммутатору. Однако, даже в этом случае, подготовленные данные важно грамотно сгруппировать. Это позволит использовать один из бинарных форматов хранения, тем самым исключить накладные расходы на парсинг, обращайте на это внимание.На узлах ML приложений запускаются модели и связанные с ними функции. Они делают инференс и фиксируют результат. Узлы Хранилища Результатов Данных должны уметь принять результаты анализа данных, оценить их и предоставить доступ к ним извне. В качестве Хранилища Мастер Данных можно использовать ClickHouse и (или) MinIO.Можно написать свой планировщик, используя Kubernetes API, либо воспользоваться встроенным в Dagster, Airflow и других планировщиках. В имплементации важно иметь контроль количества записей в etcd для подов. Завершившиеся поды приложений нужно периодически очищать, иначе etcd распухнет и кластер умрет.Распределение нагрузки по нескольким узлам. При работе ML приложений ресурсы задействованы максимально, и это типичная ситуация, Важно, чтобы для системных сервисов всегда оставались свободные ресурсы. Исключение – environments for dev testing, в целях экономии их можно размещать на одном узле.Резервирование должно быть выделено в отдельную систему, которая не зависит от работы самой ML системы. Важно, чтобы она включала в себя создание набора бекапов в разные моменты времени и их тестирование в плановых учениях по отработке внезапных отказов.ВыводыКогда ваши ML сервисы только развиваются и не потребляют ресурсы круглосуточно, целесообразно пользоваться услугами in cloud. Можно арендовать spot и on-demand инстансы под выполнение конкретной задачи чтобы не платить за них постоянно. Да, это в разы дороже, чем virtual или bare metal инстансы (в пересчете на часы), но особенность оплаты по часам, в которых были действительно задействованы эти ресурсы, поможет сэкономить здесь и сейчас.Если ваши ML сервисы будут круглосуточно нагружать кластер, то, при наличии экспертизы в команде, целесообразно рассмотреть bare metal провайдера. При отсутствии специальных скидок от cloud провайдера, даже при максимальной экономии и с учетом пакетных годовых офферов, стоимость virtual инстансов будет выше, чем стоимость bare metal инстансов. При резервировании менее чем на год — еще выше. ', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('AI делает разработчиков тупее',), kwargs={}
Результат: ai делает разработчиков тупее
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: contains_keywords
Аргументы: args=('AI делает разработчиков тупее', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:10 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('Графические материалы взяты с freepik, постер носит иллюстративный характерВсем привет!\xa0Предлагаю\xa0вашему вниманию перевод статьи «AI is Making Developers Dumb».\xa0Перевод выполнен человеком, а не LLM :)Тема статьи мне очень близка,\xa0соответствует личному опыту.\xa0Ещё\xa0я бы добавил,\xa0что всё сказанное в принципе справедливо для любой сферы деятельности.Люди часто говорят о повышении производительности благодаря LLM,\xa0и с моей стороны было бы лицемерно отрицать это.\xa0Это правда.\xa0С использованием LLM-ассистента,\xa0ваш рабочий процесс станет продуктивнее,\xa0но этот же рабочий процесс будет делать вас глупее.Я утверждаю это не на пустом месте.\xa0Со временем у вас развивается зависимость от инструментов LLM.\xa0Это приведёт к тому,\xa0что вам будет трудно работать без AI-помощника.Я занялся разработкой ПО,\xa0потому что мне нравится что-то создавать и разбираться,\xa0как это работает.\xa0Это значит,\xa0что я получаю удовольствие,\xa0кропотливо набирая блоки кода на своей клавиатуре.Использование LLM-ассистента в рабочем процессе лишает этого.\xa0Вместо радости от самостоятельного решения проблем, теперь нужно просто попросить LLM предложить дополнение кода.Вместо того чтобы разбираться,\xa0что и как работает,\xa0вы впадаете в зависимость от ожидания,\xa0что ассистент скажет,\xa0что нужно делать.Возможно,\xa0некоторые люди не испытывают удовольствия от написания собственного кода.\xa0В таком случае,\xa0как бы это жёстко не звучало,\xa0я бы сказал,\xa0что они заняты не своим делом.\xa0Возможно\xa0они занимаются этим только ради денег?\xa0Справедливо подмечено.\xa0Это есть в любой сфере деятельности,\xa0и обычно это отражается на увлечённости и поведении человека.Лучшие инженеры,\xa0которых я встречал — \xa0люди,\xa0которые могут в свой выходной часами просидеть над улучшением ПО или созданием своей тулзы.\xa0Чёрт возьми,\xa0вот откуда берутся новшества и достижения.\xa0Вы не сможете улучшить производительность ПО без чёткого понимания как работает система.\xa0Иначе вы просто тыкнете пальцем в небо.Есть такое понятие «Отставание Второго Пилота»   (англ.\xa0«Copilot Lag»  ).\xa0Оно описывает состояние,\xa0когда после каждого действия разработчик останавливается,\xa0ожидая подсказки,\xa0что ему делать дальше.\xa0Самостоятельности\xa0мышления больше нет,\xa0осталось только ожидание подсказки от AI,\xa0что нужно делать дальше.\xa0Это сродни первым шагам новичка\xa0—\xa0полагаться на более опытных коллег,\xa0которые направляют твои действия и понимают,\xa0что нужно делать дальше.Это реально.Вечность назад\xa0я\xa0использовал «Github Copilot» в «VSCode».\xa0Когда я оглядываюсь на то время,\xa0то поражаюсь,\xa0что не растерял ещё больше знаний.Со временем я начал забывать базовые конструкции языков,\xa0с которыми работаю.\xa0Я начал забывать элементы синтаксиса,\xa0как использовать основные операторы.\xa0Очень неловко взглянуть в прошлое и осмыслить,\xa0как я разрушал накопленные знания\xa0только потому,\xa0что хотел мгновенного прироста скорости.Это реально случается,\xa0когда\xa0вы используете Copilot в течении года.\xa0Вы начнёте забывать многие вещи,\xa0потому что вам больше не нужно думать,\xa0о том что нужно сделать.\xa0По крайней мере,\xa0вам больше не нужно думать таким же образом,\xa0как если бы над решением проблемы пришлось размышлять самостоятельно.Но,\xa0на самом деле,\xa0осознать это и столкнуться лицом к лицу с реальностью мне помогло видео «ThePrimeagen».\xa0У него есть вырезка из одного из его стримов,\xa0где он рассказывал про «Задержку Второго Пилота».\xa0Насколько это был тревожный звоночек!После этого я перестал пользоваться LLM-аccистентами для кодинга.\xa0И\xa0очень рад,\xa0что сделал это.В качестве примера:\xa0мне\xa0очень интересна сфера компиляторостроения.\xa0В то время я пробовал работать по книге «Writing An Interpreter In Go» Thorsten Ball.\xa0Но это была пустая трата времени.\xa0Вместо изучения матчасти из книги,\xa0Copilot просто генерировал мне код.\xa0В самом деле,\xa0вы можете почувствовать себя очень крутым,\xa0написав парсер.\xa0А сможете это повторить,\xa0выключив Copilot?\xa0Наверняка нет.\xa0Вы так же теряете возможность изучить концепции типа «управление памятью» или «Data Oriented Design»,\xa0потому что Copilot даст вам код,\xa0который\xa0по его мнению,\xa0может сработать,\xa0вместо того\xa0чтобы самостоятельно исследовать тему и разобраться в деталях.На самом деле мы подходим к другой стороне вопроса.\xa0Исследование.\xa0На этот раз с более позитивным отношением к AI.Верно.\xa0Большие Языковые Модели полезны.\xa0Они\xa0подобны поисковой системе.\xa0Мы часто обращались к\xa0Stackoverflow\xa0за помощью в программировании.\xa0Поскольку Большие Языковые Модели обучены на всех этих данных,\xa0они\xa0могут стать эффективным инструментом для получения дополнительной информации по определённой теме.\xa0Но только если вы будете использовать их,\xa0имея пытливый ум,\xa0и не будете им слепо доверять.Поскольку они печально известны тем,\xa0что генерируют всякую чушь.\xa0Так\xa0уж устроены LLM.\xa0В\xa0половине случаев они создают бессмыслицу.\xa0Это просто шаблоны и последовательности токенов,\xa0а не реальные знания безумно умного человека.\xa0Они обучены на материалах,\xa0созданных людьми с пониманием предметной области,\xa0но при этом сами LLM изрыгают это совершенно оторвано от изначального контекста.В любом случае,\xa0изучение ответов и размышление,\xa0почему предложено именно это решение\xa0—\xa0единственный верный путь получить выгоду от LLM.\xa0Относитесь к этому как к диалогу,\xa0в котором вы пытаетесь понять,\xa0почему собеседник предпочёл определённое решение.\xa0Вы допустите ошибку,\xa0если не будете понимать,\xa0почему вам предложили именно это или как это работает\xa0под капотом.А ещё делайте заметки!\xa0Много заметок!\xa0Недавно я начал изучать Zig,\xa0и я постоянно делаю заметки по изученным разделам языка,\xa0особенно учитывая,\xa0что я впервые столкнулся с ручным управлением памяти.\xa0Они могут стать полезным справочником и выручить,\xa0когда вы застрянете над каким-то вопросом или захотите помочь другим!Я написал эту статью во время утренней поездки,\xa0и мой поезд прибыл к месту назначения.\xa0Так\xa0что я закончу на этой ноте.От переводчикаЯ добавлю немного своих мыслей:\xa0я\xa0пошёл немного дальше автора и генерировал функции и целые программы (и сайты) с помощью «DeepSeek», просто давая описание того что мне нужно.\xa0В какой-то момент это действительно дало прирост производительности и у себя в голове я уже рисовал картину,\xa0как 1 инструмент заменит мне целую команду напарников.\xa0Так длилось до тех пор,\xa0пока я не увидел "The server is busy".Шучу.\xa0На\xa0самом деле я понял свою ошибку раньше.\xa0Когда нужно было внести правки в функции,\xa0которые сгенерировал сам AI.\xa0Оказалось,\xa0что вместо банального исправления ошибки он мог выдать совершенно другую реализацию, совершено\xa0другую архитектурно.\xa0В\xa0итоге в проекте накапливаются рудименты,\xa0и он превращается в архитектурную помойку.Но самое печальное,\xa0кроме чудовищной Задержки Второго Пилота в виде тайм-аута сервера,\xa0возникает проблема:\xa0когда код компилируется и вроде работает,\xa0но почему-то не так,\xa0как хотелось бы.\xa0Ты\xa0понятия не имеешь,\xa0как вообще устроена программа.Кстати почему пилот второй,\xa0если на самом деле ему достаётся ведущая роль?',), kwargs={}
Результат: графические материалы взяты с freepik постер носит иллюстративный характервсем привет предлагаю вашему вниманию перевод статьи ai is making developers dumb перевод выполнен человеком а не llm тема статьи мне очень близка соответствует личному опыту ещё я бы добавил что всё сказанное в принципе справедливо для любой сферы деятельностилюди часто говорят о повышении производительности благодаря llm и с моей стороны было бы лицемерно отрицать это это правда с использованием llmассистента ваш рабочий процесс станет продуктивнее но этот же рабочий процесс будет делать вас глупеея утверждаю это не на пустом месте со временем у вас развивается зависимость от инструментов llm это приведёт к тому что вам будет трудно работать без aiпомощникая занялся разработкой по потому что мне нравится чтото создавать и разбираться как это работает это значит что я получаю удовольствие кропотливо набирая блоки кода на своей клавиатуреиспользование llmассистента в рабочем процессе лишает этого вместо радости от самостоятельного решения проблем теперь нужно просто попросить llm предложить дополнение кодавместо того чтобы разбираться что и как работает вы впадаете в зависимость от ожидания что ассистент скажет что нужно делатьвозможно некоторые люди не испытывают удовольствия от написания собственного кода в таком случае как бы это жёстко не звучало я бы сказал что они заняты не своим делом возможно они занимаются этим только ради денег справедливо подмечено это есть в любой сфере деятельности и обычно это отражается на увлечённости и поведении человекалучшие инженеры которых я встречал   люди которые могут в свой выходной часами просидеть над улучшением по или созданием своей тулзы чёрт возьми вот откуда берутся новшества и достижения вы не сможете улучшить производительность по без чёткого понимания как работает система иначе вы просто тыкнете пальцем в небоесть такое понятие отставание второго пилота   англ copilot lag   оно описывает состояние когда после каждого действия разработчик останавливается ожидая подсказки что ему делать дальше самостоятельности мышления больше нет осталось только ожидание подсказки от ai что нужно делать дальше это сродни первым шагам новичка  полагаться на более опытных коллег которые направляют твои действия и понимают что нужно делать дальшеэто реальновечность назад я использовал github copilot в vscode когда я оглядываюсь на то время то поражаюсь что не растерял ещё больше знанийсо временем я начал забывать базовые конструкции языков с которыми работаю я начал забывать элементы синтаксиса как использовать основные операторы очень неловко взглянуть в прошлое и осмыслить как я разрушал накопленные знания только потому что хотел мгновенного прироста скоростиэто реально случается когда вы используете copilot в течении года вы начнёте забывать многие вещи потому что вам больше не нужно думать о том что нужно сделать по крайней мере вам больше не нужно думать таким же образом как если бы над решением проблемы пришлось размышлять самостоятельноно на самом деле осознать это и столкнуться лицом к лицу с реальностью мне помогло видео theprimeagen у него есть вырезка из одного из его стримов где он рассказывал про задержку второго пилота насколько это был тревожный звоночекпосле этого я перестал пользоваться llmаccистентами для кодинга и очень рад что сделал этов качестве примера мне очень интересна сфера компиляторостроения в то время я пробовал работать по книге writing an interpreter in go thorsten ball но это была пустая трата времени вместо изучения матчасти из книги copilot просто генерировал мне код в самом деле вы можете почувствовать себя очень крутым написав парсер а сможете это повторить выключив copilot наверняка нет вы так же теряете возможность изучить концепции типа управление памятью или data oriented design потому что copilot даст вам код который по его мнению может сработать вместо того чтобы самостоятельно исследовать тему и разобраться в деталяхна самом деле мы подходим к другой стороне вопроса исследование на этот раз с более позитивным отношением к aiверно большие языковые модели полезны они подобны поисковой системе мы часто обращались к stackoverflow за помощью в программировании поскольку большие языковые модели обучены на всех этих данных они могут стать эффективным инструментом для получения дополнительной информации по определённой теме но только если вы будете использовать их имея пытливый ум и не будете им слепо доверятьпоскольку они печально известны тем что генерируют всякую чушь так уж устроены llm в половине случаев они создают бессмыслицу это просто шаблоны и последовательности токенов а не реальные знания безумно умного человека они обучены на материалах созданных людьми с пониманием предметной области но при этом сами llm изрыгают это совершенно оторвано от изначального контекстав любом случае изучение ответов и размышление почему предложено именно это решение  единственный верный путь получить выгоду от llm относитесь к этому как к диалогу в котором вы пытаетесь понять почему собеседник предпочёл определённое решение вы допустите ошибку если не будете понимать почему вам предложили именно это или как это работает под капотома ещё делайте заметки много заметок недавно я начал изучать zig и я постоянно делаю заметки по изученным разделам языка особенно учитывая что я впервые столкнулся с ручным управлением памяти они могут стать полезным справочником и выручить когда вы застрянете над какимто вопросом или захотите помочь другимя написал эту статью во время утренней поездки и мой поезд прибыл к месту назначения так что я закончу на этой нотеот переводчикая добавлю немного своих мыслей я пошёл немного дальше автора и генерировал функции и целые программы и сайты с помощью deepseek просто давая описание того что мне нужно в какойто момент это действительно дало прирост производительности и у себя в голове я уже рисовал картину как 1 инструмент заменит мне целую команду напарников так длилось до тех пор пока я не увидел the server is busyшучу на самом деле я понял свою ошибку раньше когда нужно было внести правки в функции которые сгенерировал сам ai оказалось что вместо банального исправления ошибки он мог выдать совершенно другую реализацию совершено другую архитектурно в итоге в проекте накапливаются рудименты и он превращается в архитектурную помойкуно самое печальное кроме чудовищной задержки второго пилота в виде таймаута сервера возникает проблема когда код компилируется и вроде работает но почемуто не так как хотелось бы ты понятия не имеешь как вообще устроена программакстати почему пилот второй если на самом деле ему достаётся ведущая роль
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: contains_keywords
Аргументы: args=('Графические материалы взяты с freepik, постер носит иллюстративный характерВсем привет!\xa0Предлагаю\xa0вашему вниманию перевод статьи «AI is Making Developers Dumb».\xa0Перевод выполнен человеком, а не LLM :)Тема статьи мне очень близка,\xa0соответствует личному опыту.\xa0Ещё\xa0я бы добавил,\xa0что всё сказанное в принципе справедливо для любой сферы деятельности.Люди часто говорят о повышении производительности благодаря LLM,\xa0и с моей стороны было бы лицемерно отрицать это.\xa0Это правда.\xa0С использованием LLM-ассистента,\xa0ваш рабочий процесс станет продуктивнее,\xa0но этот же рабочий процесс будет делать вас глупее.Я утверждаю это не на пустом месте.\xa0Со временем у вас развивается зависимость от инструментов LLM.\xa0Это приведёт к тому,\xa0что вам будет трудно работать без AI-помощника.Я занялся разработкой ПО,\xa0потому что мне нравится что-то создавать и разбираться,\xa0как это работает.\xa0Это значит,\xa0что я получаю удовольствие,\xa0кропотливо набирая блоки кода на своей клавиатуре.Использование LLM-ассистента в рабочем процессе лишает этого.\xa0Вместо радости от самостоятельного решения проблем, теперь нужно просто попросить LLM предложить дополнение кода.Вместо того чтобы разбираться,\xa0что и как работает,\xa0вы впадаете в зависимость от ожидания,\xa0что ассистент скажет,\xa0что нужно делать.Возможно,\xa0некоторые люди не испытывают удовольствия от написания собственного кода.\xa0В таком случае,\xa0как бы это жёстко не звучало,\xa0я бы сказал,\xa0что они заняты не своим делом.\xa0Возможно\xa0они занимаются этим только ради денег?\xa0Справедливо подмечено.\xa0Это есть в любой сфере деятельности,\xa0и обычно это отражается на увлечённости и поведении человека.Лучшие инженеры,\xa0которых я встречал — \xa0люди,\xa0которые могут в свой выходной часами просидеть над улучшением ПО или созданием своей тулзы.\xa0Чёрт возьми,\xa0вот откуда берутся новшества и достижения.\xa0Вы не сможете улучшить производительность ПО без чёткого понимания как работает система.\xa0Иначе вы просто тыкнете пальцем в небо.Есть такое понятие «Отставание Второго Пилота»   (англ.\xa0«Copilot Lag»  ).\xa0Оно описывает состояние,\xa0когда после каждого действия разработчик останавливается,\xa0ожидая подсказки,\xa0что ему делать дальше.\xa0Самостоятельности\xa0мышления больше нет,\xa0осталось только ожидание подсказки от AI,\xa0что нужно делать дальше.\xa0Это сродни первым шагам новичка\xa0—\xa0полагаться на более опытных коллег,\xa0которые направляют твои действия и понимают,\xa0что нужно делать дальше.Это реально.Вечность назад\xa0я\xa0использовал «Github Copilot» в «VSCode».\xa0Когда я оглядываюсь на то время,\xa0то поражаюсь,\xa0что не растерял ещё больше знаний.Со временем я начал забывать базовые конструкции языков,\xa0с которыми работаю.\xa0Я начал забывать элементы синтаксиса,\xa0как использовать основные операторы.\xa0Очень неловко взглянуть в прошлое и осмыслить,\xa0как я разрушал накопленные знания\xa0только потому,\xa0что хотел мгновенного прироста скорости.Это реально случается,\xa0когда\xa0вы используете Copilot в течении года.\xa0Вы начнёте забывать многие вещи,\xa0потому что вам больше не нужно думать,\xa0о том что нужно сделать.\xa0По крайней мере,\xa0вам больше не нужно думать таким же образом,\xa0как если бы над решением проблемы пришлось размышлять самостоятельно.Но,\xa0на самом деле,\xa0осознать это и столкнуться лицом к лицу с реальностью мне помогло видео «ThePrimeagen».\xa0У него есть вырезка из одного из его стримов,\xa0где он рассказывал про «Задержку Второго Пилота».\xa0Насколько это был тревожный звоночек!После этого я перестал пользоваться LLM-аccистентами для кодинга.\xa0И\xa0очень рад,\xa0что сделал это.В качестве примера:\xa0мне\xa0очень интересна сфера компиляторостроения.\xa0В то время я пробовал работать по книге «Writing An Interpreter In Go» Thorsten Ball.\xa0Но это была пустая трата времени.\xa0Вместо изучения матчасти из книги,\xa0Copilot просто генерировал мне код.\xa0В самом деле,\xa0вы можете почувствовать себя очень крутым,\xa0написав парсер.\xa0А сможете это повторить,\xa0выключив Copilot?\xa0Наверняка нет.\xa0Вы так же теряете возможность изучить концепции типа «управление памятью» или «Data Oriented Design»,\xa0потому что Copilot даст вам код,\xa0который\xa0по его мнению,\xa0может сработать,\xa0вместо того\xa0чтобы самостоятельно исследовать тему и разобраться в деталях.На самом деле мы подходим к другой стороне вопроса.\xa0Исследование.\xa0На этот раз с более позитивным отношением к AI.Верно.\xa0Большие Языковые Модели полезны.\xa0Они\xa0подобны поисковой системе.\xa0Мы часто обращались к\xa0Stackoverflow\xa0за помощью в программировании.\xa0Поскольку Большие Языковые Модели обучены на всех этих данных,\xa0они\xa0могут стать эффективным инструментом для получения дополнительной информации по определённой теме.\xa0Но только если вы будете использовать их,\xa0имея пытливый ум,\xa0и не будете им слепо доверять.Поскольку они печально известны тем,\xa0что генерируют всякую чушь.\xa0Так\xa0уж устроены LLM.\xa0В\xa0половине случаев они создают бессмыслицу.\xa0Это просто шаблоны и последовательности токенов,\xa0а не реальные знания безумно умного человека.\xa0Они обучены на материалах,\xa0созданных людьми с пониманием предметной области,\xa0но при этом сами LLM изрыгают это совершенно оторвано от изначального контекста.В любом случае,\xa0изучение ответов и размышление,\xa0почему предложено именно это решение\xa0—\xa0единственный верный путь получить выгоду от LLM.\xa0Относитесь к этому как к диалогу,\xa0в котором вы пытаетесь понять,\xa0почему собеседник предпочёл определённое решение.\xa0Вы допустите ошибку,\xa0если не будете понимать,\xa0почему вам предложили именно это или как это работает\xa0под капотом.А ещё делайте заметки!\xa0Много заметок!\xa0Недавно я начал изучать Zig,\xa0и я постоянно делаю заметки по изученным разделам языка,\xa0особенно учитывая,\xa0что я впервые столкнулся с ручным управлением памяти.\xa0Они могут стать полезным справочником и выручить,\xa0когда вы застрянете над каким-то вопросом или захотите помочь другим!Я написал эту статью во время утренней поездки,\xa0и мой поезд прибыл к месту назначения.\xa0Так\xa0что я закончу на этой ноте.От переводчикаЯ добавлю немного своих мыслей:\xa0я\xa0пошёл немного дальше автора и генерировал функции и целые программы (и сайты) с помощью «DeepSeek», просто давая описание того что мне нужно.\xa0В какой-то момент это действительно дало прирост производительности и у себя в голове я уже рисовал картину,\xa0как 1 инструмент заменит мне целую команду напарников.\xa0Так длилось до тех пор,\xa0пока я не увидел "The server is busy".Шучу.\xa0На\xa0самом деле я понял свою ошибку раньше.\xa0Когда нужно было внести правки в функции,\xa0которые сгенерировал сам AI.\xa0Оказалось,\xa0что вместо банального исправления ошибки он мог выдать совершенно другую реализацию, совершено\xa0другую архитектурно.\xa0В\xa0итоге в проекте накапливаются рудименты,\xa0и он превращается в архитектурную помойку.Но самое печальное,\xa0кроме чудовищной Задержки Второго Пилота в виде тайм-аута сервера,\xa0возникает проблема:\xa0когда код компилируется и вроде работает,\xa0но почему-то не так,\xa0как хотелось бы.\xa0Ты\xa0понятия не имеешь,\xa0как вообще устроена программа.Кстати почему пилот второй,\xa0если на самом деле ему достаётся ведущая роль?', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('Как я удалил clickstream, но его восстановили из небытия',), kwargs={}
Результат: как я удалил clickstream но его восстановили из небытия
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: contains_keywords
Аргументы: args=('Как я удалил clickstream, но его восстановили из небытия', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:11 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('Всем привет! Я Дмитрий Немчин из Т-Банка. Расскажу не очень успешную историю о том, как я удалил данные и что из этого вышло. В ИТ я больше 12 лет, начинал DBA и разработчиком в кровавом энтерпрайзе с Oracle. В 2015 году познакомился с Greenplum в Т, да так тут и остался. С 2017 года стал лидить команду, потом все чуть усложнилось и команда стала не одна.\xa0Возможно, вы могли видеть меня как организатора Greenplum-митапов в России.\xa0Но команда командой, менеджмент менеджментом, а руки чешутся…Как я все удалилОдним погожим зимним днем, 11 января 2024 года, в первый рабочий день года, произошла замечательная история. У нас есть кластер Hadoop, не очень большой (по меркам Bigdata), порядка пяти петабайт (общей capacity), и в нем в очередной раз закончилось место.Исторически у нас в Т Hadoop используется не как DataLake, куда стекаются все данные компании, а скорее как «дача для данных». Там лежит то, что мы не хотим или не можем по разным причинам сложить в Greenplum. Таких данных не очень много, но на них бывают и важные процессы. И еще там лежат архивы, то есть иногда данные приходят сюда доживать свой век и умирать.Конечно, я очень хотел помочь инженерам что-то с этим сделать.С Data Governance в этом кластере, конечно, все плохо, мы не понимали, что чистить, и нашли большую папочку, которая называлась Amplitude. По названию можно догадаться, что это были наши кликстримы, собираемые когда-то одноименным сервисом.Началось обсуждение в нескольких тредах. В одном говорили, что в этой папке лежит то, что никому не нужно, и можно легко удалить 200 терабайт. В другом треде говорили, что там лежат самые важные данные компании и ни в коем случае удалять и даже дышать на них нельзя.Естественно, я посмотрел не туда и все удалил.Через 20 минут признался коллегам, что снес 200 терабайт кликстрима, и позвал всех на мозговой штурм, как теперь исправить ситуацию.Решили, что данные терять нельзя, мы все-таки дата-платформа. Будем делать что можем. Мы поняли, что восстановить данные неоткуда физически: я провел удаление мимо корзины, бэкапов нет.Не все могут себе позволить бэкапить мультипетабайтные кластеры (привет и некоторая зависть компании «Одноклассники»). А источник (Amplitude) по некоторым независящим от нас причинам недоступен.Прошел час беготни по индустрии со странными вопросами типа «А как бы нам бы поднять бы данные из ниоткуда?». Все смотрели на нас как на дурачков альтернативно одаренных и сочувственно говорили: «Ну все, ребят, попрощайтесь с ними, это конец».И тут мы поняли, что у нас львиная доля процессов, работающих на HDFS, могут подождать, но при этом работающий HDFS-кластер — это точно потеря данных.\xa0Да, мы решили остановить продакшен. Подняли в стороне небольшой кластерок из восьми нод общим объемом меньше петабайта и туда переключили все самое критичное. После этого начали искать способ восстановить данные.\xa0Закономерный вопрос: если у вас места нет, чего раньше эти ноды не подняли? Они нужны были для другого, все было расписано.Задача — восстановить данныеОпишем задачу восстановления. У нас есть набор parquet-файлов, parquet-файлы лежат на HDFS, HDFS кластерный. Как это выглядит: есть много серверов, на этих серверах есть куча дисков с локальными ФС, в нашем случае это XFS — и это нам пригодится.Файл, который мы пишем в HDFS, может влезать в один блок файловой системы, а может в несколько. Каждый блок — это файл на диске, который можно увидеть через ls в консоли сервера. А если файл занимает больше одного блока HDFS, он просто пилится где-то посередине и раскладывается на несколько блоков (которые попадают на несколько серверов).\xa0У HDFS есть репликейшен-фактор. У нас репликейшен-фактор был два. Дети, не делайте так в большом продакшене никогда!Репликейшен-фактор должен быть три либо какой-нибудь erasure coding и вот эти вот всякие штуки. Но что было, то было. В итоге нам RF2 даже помог.Как выглядят наши данныеЧтобы восстановить данные, нам нужно было поднять сначала нижний слой. Файлы были удалены мимо корзины, мониторинг сообщал, что 200 терабайт освободилось.Но фактически в современных файловых системах, как и в современных СУБД, если вы что-то удалили — никто ничего не удаляет. Прямо как ремонт: если вы его закончили, это не значит, что кто-то что-то закончил делать.Место помечается как очищенное, его можно переиспользовать, пока никто ничего не записал. Соответственно, в теории можно успеть поднять то, что осталось на дисках в блоках, помеченных как удаленные.Блок-схема скрипта xfs_undeleteМы прошерстили интернеты и нашли на Гитхабе скриптик под названием xfs_undelete. Скрипт на TCL, на вид не очень сложный. Решили его внимательно изучить.Он поднимает по некоторым введенным параметрам удаленные с дисков айноды: сканирует файловую систему, пытается найти айноды по заданным параметрам, если получилось — поднимает их в память, если они нормально прочитались — записывает их на диск. У него даже есть отдельный сабреддит с поддержкой — практически уровень энтерпрайзного ПО.Мы попробовали позапускать скрипт на наших дисках — все работало. Но был ряд дополнительных сложностей (куда же без них).Проблема: как поднять данные с 800 дисковНужно поднять данные не с одного диска, а с 800. И записать эти данные в тучу S3-бакетов (больше некуда было).Мы написали сложную bash-магию, которая вылилась в три скрипта: подготовка, запуск и watchdog.Блок-схема скрипта подготовкиСкрипт подготовки из нашего инвентори собирает информацию о серверах и примонтированных дисках, создает S3-бакеты, разливает пакеты и монтирует S3-бакеты через S3-fuse. Это не лучший метод, но какой был: быстро, просто, а на скорость записи тогда смотрели в последнюю очередь.Скрипт запуска xfs_undeleteСкрипт запуска собирал из inventory все точки монтирования для всех серверов, рассчитывал временные метки (он знал, когда я удалил данные, и отсчитывал от текущего момента разницу), собирал shell-однострочники для запуска xfs_undetele с нужными параметрами, раскладывал это на серверы и запускал. Ну и да, еще логировал свои действия.WatchdogТретий скрипт делал до четырех попыток перезапуска xfs_undelete и писал понятный лог, с которым можно было работать.В итоге мы восстановили некое количество бинарных блоков и не особо выбирали, что можем восстановить. У нас был таймфрейм с 16:00 до 17:00 11 января. Мы пытались восстановить данные, но в это время (в указанный таймфрейм, пока мы бегали и думали, что делать) работала еще куча процессов — и в итоге мы подняли 1,1 петабайта вместо 200 терабайт.Мы рассчитывали на 400 терабайт, потому что RF2: 200 удалили + 200 копия — 400 подняли. В итоге притащили кучу мусора и потеряли длину исходных файлов, потому что восстанавливались не начальные файлы, а блоки файловой системы. Блоки устроены так, что если записал чуть меньше блока, то в конце будут нули или вообще какой-то мусор.Теперь у нас был фарш и, кажется, можно было делать котлеты. Но задача была, наоборот, провернуть фарш назад и найти мясо.\xa0Кажется, это был хороший момент поднять продакшен, ведь мы подняли данные. Но это не так, потому что мы подняли не паркеты и вообще не доверяли тем блокам. В тот момент мы пока не знали, как восстанавливать паркеты. Если бы мы включили кластер, то гарантированно отрезали бы себе путь к перевыгрузке удаленных блоков или к возможности еще что-то сделать с данными, потому что их могли перетереть.Были и другие проблемыРасскажу, что у нас произошло из-за выключенного кластера. Пострадала аналитика звонков, охлаждение данных из нашего основного движка Greenplum, встала поставка данных из внешних источников NiFi и работа с А/В-тестами. Но главное, январь на дворе, а логистика — суровая штука. И у нас проблемы с подарками детям и сотрудникам из-за того, что доступа к нужным данным нет (они в том самом выключенном проде).Проблема: как спасти productionМаленького HDFS на все не хватало, и мы подняли еще один HDFS на 5 петабайт.\xa0И тут опять вопрос: отчего вы его раньше-то не подняли? А это были не наши серверы, нам их по доброте душевной дали коллеги, которые должны были там поднять для нас кое-что другое.\xa0Подняли большой кластер, благо у нас был довольно свежий дамп метаданных HDFS. При помощи Питона, напильника и простого советского мата научились выгружать данные из выключенного кластера HDFS во включенный.\xa0Мы перелили все самое критичное, что просили пользователи, на новый кластер и пошли дальше заниматься восстановлением.У нас было 800+ бакетов S3, и нужно было найти там что-нибудь полезное. Поднялись на уровень HDFS и взяли бэкап меты. Из него мы нашли список исходных файлов и для части файлов нашли оригинальное расположение, которое нам пригодилось позже.Проблема: как восстановить блоки HDFS и сделать из них parquet-файлыТребовалось поднять нужные блоки HDFS из фарша и очистить их от мусора. А потом разобраться, где там паркеты, и восстановить их.Структура parquet-файлаСверху — parquet одноблочный, который влез в блок HDFS. В нашем случае это 512 мегабайт, и нам очень повезло, что это parquet.Parquet — структурированный файл, у него есть четкая метка начала и метка конца: PAR1. При этом в конце файла есть метаданные, в которых указана структура файла, row-группы и их расположение и еще много чего полезного.Нюанс вот в чем: если файлы небольшие, они влезают в блоки HDFS, они неразрывные, есть начало и конец. Все счастливы, все классно.\xa0Но есть история, когда паркет не влез в один блок файловой системы и он занимает больше: два блока или триста — сколько угодно. Parquet где-то пилится, причем он может пилиться посередине, а может пилиться непонятно как.Мы попытались все это восстановить. Для начала нам надо было хотя бы отфильтровать и разметить данные.\xa0Алгоритм для одноблочных файлов:Проверяем PAR1 в начале файла.Проверяем PAR1 в конце файла.Восстанавливаем исходную длину файла и обрезаем нули в конце.Пытаемся прочитать.Если в конце PAR1, по смещению с конца достаем мету паркета.Считаем hash от файла для поиска дублей (RF2).Алгоритм восстановления примерно такой же:Проверяем PAR1 в начале файла.Проверяем PAR1 в конце файла.В метаданных находим правильное имя таблицы.Проверяем правильную схему паркета.Файл полностью читается (нет битых блоков внутри).Алгоритмы для одноблочных файлов выглядят довольно просто. А вот дальше началось еще одно веселье — многоблочные паркеты. Там оказалось немного черной магии.Конец паркета несложно найти, у него в конце PAR1 — читаем метку, это будет хвост.\xa0Мы нашли интересную закономерность: внутри parquet-файла, в той части, где данные, есть magic numbers, но они нефиксированные и зависят от того, чем и как мы записываем эти паркеты.Magic numbers в parquet-файлах (зависят от реализации записи)Алгоритм восстановления:\xa0Взять хвост паркета, там есть карта офсетов — расстояний между началами row groups.\xa0Найти magic numbers.Отсканировать все-все байты.Получить для всех файлов, похожих на то, что нам надо, карту офсетов внутри этих файлов.Наложить одно на другое и так собрать большие пакеты.Попытаться прочитать то, что получилось.Задача была не самая простая и не самая быстрая, но там, где это получилось, мы считали, что данные восстановились.У нас были собранные паркеты в S3, теперь очередь данных в HDFS. Вроде ничего сложного, но с нюансом: нужно было восстановить структуру партиций.Как выглядят партиции в HDFSНужно было восстановить партиции, потому что код обработки заточен под структуру папок. Иначе обработка была бы неоптимальной. Ну и в целом — откуда данные удалил, туда и верни.В данных обычно можно найти поле, по которому сделано партиционирование, но это не всегда так. Иногда внутри данных не остается полей, по которым разложены партиции, и это как раз наш случай.Довольно много времени занял разбор данных, чтобы понять, как синтезировать те поля, по которым все было разложено, или хотя бы близкие к ним. Получилась некая аналитическая работа.Например, в одной из таблиц были партиции по времени загрузки данных на сервер. Для большинства случаев это время очень близко к времени отправки данных клиентом, а оно у нас сохранилось внутри файлов.По таймлайну мы начали в феврале — и сделали только к концу апреля. Пусть долго, но хотя бы разложили.Проблема: нет половины данныхМы проверили итоги — и вроде бы 90% минимум было по объему. Но аналитики сказали: «Ребята, извините, 45% восстановлено». Нам показалось, что совпадение какое-то странное.\xa0Оказалось, что в эксельке, по которой ребята сверялись, всплыли неочевидные дубли. Строка Total подло закралась в середину файла, а не сидела себе в конце, как все остальные Total. И когда считали сумму нужных строк, данные фактически задвоились.Что у нас получилосьСначала о позитивном: у нас получилось поднять фарш и из фарша восстановить 90%. Какое-то время мы были счастливы: продакшен-процессы вернули, подарки детям и сотрудникам доехали — праздник не пострадал.В процессе мы подняли пару кластеров HDFS. Казалось бы, нужно что-то удалить и сломать — и у нас тут же появятся мощности. Не надо так делать.Но было много не очень хорошего:Считали систему неважной. Hadoop где-то там далеко и заброшен, эдакая дача для данных — кладите и не будем разбираться.Не было Governance и квотирования, поэтому у нас был RF2, и это нас спасло. Если бы был RF3, нам бы потребовалось 1,5 петабайта — и их точно некуда было девать.Удаление мимо корзины и без уведомления — плохое решение.Какие выводы сделалиТеперь поговорим о том, как этого можно было избежать. Тут я надеваю погоны капитана Очевидность:\xa0Удалять данные только через корзину. Да, это чуть дороже, но нервы всем еще пригодятся.Не делать на проде ничего без явных апрувов (лучше в git). Если есть важная система хранения, нужно стараться использовать инструменты управления данными, в которых нужны вторые руки для серьезных действий. Если нет готовых, то напишите. Это не панацея, но неплохой аварийный клапан.Что мы сделали у себя нового для избежания подобных ситуацийTTL для данных из коробки. Есть репозиторий, в который нам приносят yaml, в yaml указан путь владельца или группа, потому что владелец может уволиться или еще что-то с ним может произойти.Gitops для TTL данных на HDFSТри важных параметра:\xa0Наличие подпапок — это важно, потому что у нас вся эта история заточена на определенную структуру папок или подпапок.\xa0TTL — сколько дней хранить данные.Откуда считать TTL — суперважный флаг, который может выстрелить в ногу, если его не сделать.\xa0Почему это важно? Потому что вполне может быть картина, что грузили, грузили, грузили данные и потом перестали их грузить. И вот они год лежат без дела.\xa0Если считать TTL год от сегодня, когда уже прошел год — мы все удалим. Если надо хранить последний год, а это вполне бывает по регуляторным соображениям, то вот этот флаг вас может как раз спасти.\xa0Если yaml валидный, он проверяется на корректность того, что этот yaml правильный, yaml на схему. Прогоняется dry run при MR и пишет что-то вроде: «Я бы удалил такое, проверь, корректно или нет». Если корректно, выставляется в cron и по указанным правилам данные чистятся.Но на семь дней данные всегда помещаются в корзину и там маринуются. Если семь дней прошло и никто не пришел — можно удалять. Если больше семи дней — извините. Можно, конечно, держать данные дольше, но не всегда это оправданно. Нам пока вроде семи дней хватает. Квотирование — важная штука, которой у нас не было и которую мы очень хотели. В HDFS квотирование есть из коробки, можно по папочкам настроить квоты.\xa0Gitops для квотирования записи на HDFSКвоты работают изолированно: если кончилась квота на запись в папку A, тому, кто в нее пишет, придет ошибка. При этом в папку B все продолжит писаться.\xa0Но есть нюанс. Нам хотелось к этой штуке какого-то внятного управления (а не руками по консолям бегать), и мы написали gitops c yaml: путь, владелец, квота и какое-то описание.Напоследок скажу еще пару слов по поводу «как можно было бы избежать», но это уже про процессы и про подумать.\xa0Данные в дата-платформах растут, никаких исключений. Если данные в платформе не растут, что-то не так с платформой или с бизнесом.Если ваша система не под EOL, то озаботьтесь ее расширением. Или хотя бы такой возможностью. Если вы считаете ее EOL / legacy / как хотите называйте, то убедитесь, что все вокруг считают так же. Желательно, чтобы была какая-то замена, но это отдельный вопрос.',), kwargs={}
Результат: всем привет я дмитрий немчин из тбанка расскажу не очень успешную историю о том как я удалил данные и что из этого вышло в ит я больше 12 лет начинал dba и разработчиком в кровавом энтерпрайзе с oracle в 2015 году познакомился с greenplum в т да так тут и остался с 2017 года стал лидить команду потом все чуть усложнилось и команда стала не одна возможно вы могли видеть меня как организатора greenplumмитапов в россии но команда командой менеджмент менеджментом а руки чешутсякак я все удалилодним погожим зимним днем 11 января 2024 года в первый рабочий день года произошла замечательная история у нас есть кластер hadoop не очень большой по меркам bigdata порядка пяти петабайт общей capacity и в нем в очередной раз закончилось местоисторически у нас в т hadoop используется не как datalake куда стекаются все данные компании а скорее как дача для данных там лежит то что мы не хотим или не можем по разным причинам сложить в greenplum таких данных не очень много но на них бывают и важные процессы и еще там лежат архивы то есть иногда данные приходят сюда доживать свой век и умиратьконечно я очень хотел помочь инженерам чтото с этим сделатьс data governance в этом кластере конечно все плохо мы не понимали что чистить и нашли большую папочку которая называлась amplitude по названию можно догадаться что это были наши кликстримы собираемые когдато одноименным сервисомначалось обсуждение в нескольких тредах в одном говорили что в этой папке лежит то что никому не нужно и можно легко удалить 200 терабайт в другом треде говорили что там лежат самые важные данные компании и ни в коем случае удалять и даже дышать на них нельзяестественно я посмотрел не туда и все удалилчерез 20 минут признался коллегам что снес 200 терабайт кликстрима и позвал всех на мозговой штурм как теперь исправить ситуациюрешили что данные терять нельзя мы всетаки датаплатформа будем делать что можем мы поняли что восстановить данные неоткуда физически я провел удаление мимо корзины бэкапов нетне все могут себе позволить бэкапить мультипетабайтные кластеры привет и некоторая зависть компании одноклассники а источник amplitude по некоторым независящим от нас причинам недоступенпрошел час беготни по индустрии со странными вопросами типа а как бы нам бы поднять бы данные из ниоткуда все смотрели на нас как на дурачков альтернативно одаренных и сочувственно говорили ну все ребят попрощайтесь с ними это конеци тут мы поняли что у нас львиная доля процессов работающих на hdfs могут подождать но при этом работающий hdfsкластер  это точно потеря данных да мы решили остановить продакшен подняли в стороне небольшой кластерок из восьми нод общим объемом меньше петабайта и туда переключили все самое критичное после этого начали искать способ восстановить данные закономерный вопрос если у вас места нет чего раньше эти ноды не подняли они нужны были для другого все было расписанозадача  восстановить данныеопишем задачу восстановления у нас есть набор parquetфайлов parquetфайлы лежат на hdfs hdfs кластерный как это выглядит есть много серверов на этих серверах есть куча дисков с локальными фс в нашем случае это xfs  и это нам пригодитсяфайл который мы пишем в hdfs может влезать в один блок файловой системы а может в несколько каждый блок  это файл на диске который можно увидеть через ls в консоли сервера а если файл занимает больше одного блока hdfs он просто пилится гдето посередине и раскладывается на несколько блоков которые попадают на несколько серверов у hdfs есть репликейшенфактор у нас репликейшенфактор был два дети не делайте так в большом продакшене никогдарепликейшенфактор должен быть три либо какойнибудь erasure coding и вот эти вот всякие штуки но что было то было в итоге нам rf2 даже помогкак выглядят наши данныечтобы восстановить данные нам нужно было поднять сначала нижний слой файлы были удалены мимо корзины мониторинг сообщал что 200 терабайт освободилосьно фактически в современных файловых системах как и в современных субд если вы чтото удалили  никто ничего не удаляет прямо как ремонт если вы его закончили это не значит что ктото чтото закончил делатьместо помечается как очищенное его можно переиспользовать пока никто ничего не записал соответственно в теории можно успеть поднять то что осталось на дисках в блоках помеченных как удаленныеблоксхема скрипта xfs_undeleteмы прошерстили интернеты и нашли на гитхабе скриптик под названием xfs_undelete скрипт на tcl на вид не очень сложный решили его внимательно изучитьон поднимает по некоторым введенным параметрам удаленные с дисков айноды сканирует файловую систему пытается найти айноды по заданным параметрам если получилось  поднимает их в память если они нормально прочитались  записывает их на диск у него даже есть отдельный сабреддит с поддержкой  практически уровень энтерпрайзного помы попробовали позапускать скрипт на наших дисках  все работало но был ряд дополнительных сложностей куда же без нихпроблема как поднять данные с 800 дисковнужно поднять данные не с одного диска а с 800 и записать эти данные в тучу s3бакетов больше некуда быломы написали сложную bashмагию которая вылилась в три скрипта подготовка запуск и watchdogблоксхема скрипта подготовкискрипт подготовки из нашего инвентори собирает информацию о серверах и примонтированных дисках создает s3бакеты разливает пакеты и монтирует s3бакеты через s3fuse это не лучший метод но какой был быстро просто а на скорость записи тогда смотрели в последнюю очередьскрипт запуска xfs_undeleteскрипт запуска собирал из inventory все точки монтирования для всех серверов рассчитывал временные метки он знал когда я удалил данные и отсчитывал от текущего момента разницу собирал shellоднострочники для запуска xfs_undetele с нужными параметрами раскладывал это на серверы и запускал ну и да еще логировал свои действияwatchdogтретий скрипт делал до четырех попыток перезапуска xfs_undelete и писал понятный лог с которым можно было работатьв итоге мы восстановили некое количество бинарных блоков и не особо выбирали что можем восстановить у нас был таймфрейм с 1600 до 1700 11 января мы пытались восстановить данные но в это время в указанный таймфрейм пока мы бегали и думали что делать работала еще куча процессов  и в итоге мы подняли 11 петабайта вместо 200 терабайтмы рассчитывали на 400 терабайт потому что rf2 200 удалили  200 копия  400 подняли в итоге притащили кучу мусора и потеряли длину исходных файлов потому что восстанавливались не начальные файлы а блоки файловой системы блоки устроены так что если записал чуть меньше блока то в конце будут нули или вообще какойто мусортеперь у нас был фарш и кажется можно было делать котлеты но задача была наоборот провернуть фарш назад и найти мясо кажется это был хороший момент поднять продакшен ведь мы подняли данные но это не так потому что мы подняли не паркеты и вообще не доверяли тем блокам в тот момент мы пока не знали как восстанавливать паркеты если бы мы включили кластер то гарантированно отрезали бы себе путь к перевыгрузке удаленных блоков или к возможности еще чтото сделать с данными потому что их могли перетеретьбыли и другие проблемырасскажу что у нас произошло изза выключенного кластера пострадала аналитика звонков охлаждение данных из нашего основного движка greenplum встала поставка данных из внешних источников nifi и работа с автестами но главное январь на дворе а логистика  суровая штука и у нас проблемы с подарками детям и сотрудникам изза того что доступа к нужным данным нет они в том самом выключенном продепроблема как спасти productionмаленького hdfs на все не хватало и мы подняли еще один hdfs на 5 петабайт и тут опять вопрос отчего вы его раньшето не подняли а это были не наши серверы нам их по доброте душевной дали коллеги которые должны были там поднять для нас коечто другое подняли большой кластер благо у нас был довольно свежий дамп метаданных hdfs при помощи питона напильника и простого советского мата научились выгружать данные из выключенного кластера hdfs во включенный мы перелили все самое критичное что просили пользователи на новый кластер и пошли дальше заниматься восстановлениему нас было 800 бакетов s3 и нужно было найти там чтонибудь полезное поднялись на уровень hdfs и взяли бэкап меты из него мы нашли список исходных файлов и для части файлов нашли оригинальное расположение которое нам пригодилось позжепроблема как восстановить блоки hdfs и сделать из них parquetфайлытребовалось поднять нужные блоки hdfs из фарша и очистить их от мусора а потом разобраться где там паркеты и восстановить ихструктура parquetфайласверху  parquet одноблочный который влез в блок hdfs в нашем случае это 512 мегабайт и нам очень повезло что это parquetparquet  структурированный файл у него есть четкая метка начала и метка конца par1 при этом в конце файла есть метаданные в которых указана структура файла rowгруппы и их расположение и еще много чего полезногонюанс вот в чем если файлы небольшие они влезают в блоки hdfs они неразрывные есть начало и конец все счастливы все классно но есть история когда паркет не влез в один блок файловой системы и он занимает больше два блока или триста  сколько угодно parquet гдето пилится причем он может пилиться посередине а может пилиться непонятно какмы попытались все это восстановить для начала нам надо было хотя бы отфильтровать и разметить данные алгоритм для одноблочных файловпроверяем par1 в начале файлапроверяем par1 в конце файлавосстанавливаем исходную длину файла и обрезаем нули в концепытаемся прочитатьесли в конце par1 по смещению с конца достаем мету паркетасчитаем hash от файла для поиска дублей rf2алгоритм восстановления примерно такой жепроверяем par1 в начале файлапроверяем par1 в конце файлав метаданных находим правильное имя таблицыпроверяем правильную схему паркетафайл полностью читается нет битых блоков внутриалгоритмы для одноблочных файлов выглядят довольно просто а вот дальше началось еще одно веселье  многоблочные паркеты там оказалось немного черной магииконец паркета несложно найти у него в конце par1  читаем метку это будет хвост мы нашли интересную закономерность внутри parquetфайла в той части где данные есть magic numbers но они нефиксированные и зависят от того чем и как мы записываем эти паркетыmagic numbers в parquetфайлах зависят от реализации записиалгоритм восстановления взять хвост паркета там есть карта офсетов  расстояний между началами row groups найти magic numbersотсканировать всевсе байтыполучить для всех файлов похожих на то что нам надо карту офсетов внутри этих файловналожить одно на другое и так собрать большие пакетыпопытаться прочитать то что получилосьзадача была не самая простая и не самая быстрая но там где это получилось мы считали что данные восстановилисьу нас были собранные паркеты в s3 теперь очередь данных в hdfs вроде ничего сложного но с нюансом нужно было восстановить структуру партицийкак выглядят партиции в hdfsнужно было восстановить партиции потому что код обработки заточен под структуру папок иначе обработка была бы неоптимальной ну и в целом  откуда данные удалил туда и вернив данных обычно можно найти поле по которому сделано партиционирование но это не всегда так иногда внутри данных не остается полей по которым разложены партиции и это как раз наш случайдовольно много времени занял разбор данных чтобы понять как синтезировать те поля по которым все было разложено или хотя бы близкие к ним получилась некая аналитическая работанапример в одной из таблиц были партиции по времени загрузки данных на сервер для большинства случаев это время очень близко к времени отправки данных клиентом а оно у нас сохранилось внутри файловпо таймлайну мы начали в феврале  и сделали только к концу апреля пусть долго но хотя бы разложилипроблема нет половины данныхмы проверили итоги  и вроде бы 90 минимум было по объему но аналитики сказали ребята извините 45 восстановлено нам показалось что совпадение какоето странное оказалось что в эксельке по которой ребята сверялись всплыли неочевидные дубли строка total подло закралась в середину файла а не сидела себе в конце как все остальные total и когда считали сумму нужных строк данные фактически задвоилисьчто у нас получилосьсначала о позитивном у нас получилось поднять фарш и из фарша восстановить 90 какоето время мы были счастливы продакшенпроцессы вернули подарки детям и сотрудникам доехали  праздник не пострадалв процессе мы подняли пару кластеров hdfs казалось бы нужно чтото удалить и сломать  и у нас тут же появятся мощности не надо так делатьно было много не очень хорошегосчитали систему неважной hadoop гдето там далеко и заброшен эдакая дача для данных  кладите и не будем разбиратьсяне было governance и квотирования поэтому у нас был rf2 и это нас спасло если бы был rf3 нам бы потребовалось 15 петабайта  и их точно некуда было деватьудаление мимо корзины и без уведомления  плохое решениекакие выводы сделалитеперь поговорим о том как этого можно было избежать тут я надеваю погоны капитана очевидность удалять данные только через корзину да это чуть дороже но нервы всем еще пригодятсяне делать на проде ничего без явных апрувов лучше в git если есть важная система хранения нужно стараться использовать инструменты управления данными в которых нужны вторые руки для серьезных действий если нет готовых то напишите это не панацея но неплохой аварийный клапанчто мы сделали у себя нового для избежания подобных ситуацийttl для данных из коробки есть репозиторий в который нам приносят yaml в yaml указан путь владельца или группа потому что владелец может уволиться или еще чтото с ним может произойтиgitops для ttl данных на hdfsтри важных параметра наличие подпапок  это важно потому что у нас вся эта история заточена на определенную структуру папок или подпапок ttl  сколько дней хранить данныеоткуда считать ttl  суперважный флаг который может выстрелить в ногу если его не сделать почему это важно потому что вполне может быть картина что грузили грузили грузили данные и потом перестали их грузить и вот они год лежат без дела если считать ttl год от сегодня когда уже прошел год  мы все удалим если надо хранить последний год а это вполне бывает по регуляторным соображениям то вот этот флаг вас может как раз спасти если yaml валидный он проверяется на корректность того что этот yaml правильный yaml на схему прогоняется dry run при mr и пишет чтото вроде я бы удалил такое проверь корректно или нет если корректно выставляется в cron и по указанным правилам данные чистятсяно на семь дней данные всегда помещаются в корзину и там маринуются если семь дней прошло и никто не пришел  можно удалять если больше семи дней  извините можно конечно держать данные дольше но не всегда это оправданно нам пока вроде семи дней хватает квотирование  важная штука которой у нас не было и которую мы очень хотели в hdfs квотирование есть из коробки можно по папочкам настроить квоты gitops для квотирования записи на hdfsквоты работают изолированно если кончилась квота на запись в папку a тому кто в нее пишет придет ошибка при этом в папку b все продолжит писаться но есть нюанс нам хотелось к этой штуке какогото внятного управления а не руками по консолям бегать и мы написали gitops c yaml путь владелец квота и какоето описаниенапоследок скажу еще пару слов по поводу как можно было бы избежать но это уже про процессы и про подумать данные в датаплатформах растут никаких исключений если данные в платформе не растут чтото не так с платформой или с бизнесомесли ваша система не под eol то озаботьтесь ее расширением или хотя бы такой возможностью если вы считаете ее eol  legacy  как хотите называйте то убедитесь что все вокруг считают так же желательно чтобы была какаято замена но это отдельный вопрос
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: contains_keywords
Аргументы: args=('Всем привет! Я Дмитрий Немчин из Т-Банка. Расскажу не очень успешную историю о том, как я удалил данные и что из этого вышло. В ИТ я больше 12 лет, начинал DBA и разработчиком в кровавом энтерпрайзе с Oracle. В 2015 году познакомился с Greenplum в Т, да так тут и остался. С 2017 года стал лидить команду, потом все чуть усложнилось и команда стала не одна.\xa0Возможно, вы могли видеть меня как организатора Greenplum-митапов в России.\xa0Но команда командой, менеджмент менеджментом, а руки чешутся…Как я все удалилОдним погожим зимним днем, 11 января 2024 года, в первый рабочий день года, произошла замечательная история. У нас есть кластер Hadoop, не очень большой (по меркам Bigdata), порядка пяти петабайт (общей capacity), и в нем в очередной раз закончилось место.Исторически у нас в Т Hadoop используется не как DataLake, куда стекаются все данные компании, а скорее как «дача для данных». Там лежит то, что мы не хотим или не можем по разным причинам сложить в Greenplum. Таких данных не очень много, но на них бывают и важные процессы. И еще там лежат архивы, то есть иногда данные приходят сюда доживать свой век и умирать.Конечно, я очень хотел помочь инженерам что-то с этим сделать.С Data Governance в этом кластере, конечно, все плохо, мы не понимали, что чистить, и нашли большую папочку, которая называлась Amplitude. По названию можно догадаться, что это были наши кликстримы, собираемые когда-то одноименным сервисом.Началось обсуждение в нескольких тредах. В одном говорили, что в этой папке лежит то, что никому не нужно, и можно легко удалить 200 терабайт. В другом треде говорили, что там лежат самые важные данные компании и ни в коем случае удалять и даже дышать на них нельзя.Естественно, я посмотрел не туда и все удалил.Через 20 минут признался коллегам, что снес 200 терабайт кликстрима, и позвал всех на мозговой штурм, как теперь исправить ситуацию.Решили, что данные терять нельзя, мы все-таки дата-платформа. Будем делать что можем. Мы поняли, что восстановить данные неоткуда физически: я провел удаление мимо корзины, бэкапов нет.Не все могут себе позволить бэкапить мультипетабайтные кластеры (привет и некоторая зависть компании «Одноклассники»). А источник (Amplitude) по некоторым независящим от нас причинам недоступен.Прошел час беготни по индустрии со странными вопросами типа «А как бы нам бы поднять бы данные из ниоткуда?». Все смотрели на нас как на дурачков альтернативно одаренных и сочувственно говорили: «Ну все, ребят, попрощайтесь с ними, это конец».И тут мы поняли, что у нас львиная доля процессов, работающих на HDFS, могут подождать, но при этом работающий HDFS-кластер — это точно потеря данных.\xa0Да, мы решили остановить продакшен. Подняли в стороне небольшой кластерок из восьми нод общим объемом меньше петабайта и туда переключили все самое критичное. После этого начали искать способ восстановить данные.\xa0Закономерный вопрос: если у вас места нет, чего раньше эти ноды не подняли? Они нужны были для другого, все было расписано.Задача — восстановить данныеОпишем задачу восстановления. У нас есть набор parquet-файлов, parquet-файлы лежат на HDFS, HDFS кластерный. Как это выглядит: есть много серверов, на этих серверах есть куча дисков с локальными ФС, в нашем случае это XFS — и это нам пригодится.Файл, который мы пишем в HDFS, может влезать в один блок файловой системы, а может в несколько. Каждый блок — это файл на диске, который можно увидеть через ls в консоли сервера. А если файл занимает больше одного блока HDFS, он просто пилится где-то посередине и раскладывается на несколько блоков (которые попадают на несколько серверов).\xa0У HDFS есть репликейшен-фактор. У нас репликейшен-фактор был два. Дети, не делайте так в большом продакшене никогда!Репликейшен-фактор должен быть три либо какой-нибудь erasure coding и вот эти вот всякие штуки. Но что было, то было. В итоге нам RF2 даже помог.Как выглядят наши данныеЧтобы восстановить данные, нам нужно было поднять сначала нижний слой. Файлы были удалены мимо корзины, мониторинг сообщал, что 200 терабайт освободилось.Но фактически в современных файловых системах, как и в современных СУБД, если вы что-то удалили — никто ничего не удаляет. Прямо как ремонт: если вы его закончили, это не значит, что кто-то что-то закончил делать.Место помечается как очищенное, его можно переиспользовать, пока никто ничего не записал. Соответственно, в теории можно успеть поднять то, что осталось на дисках в блоках, помеченных как удаленные.Блок-схема скрипта xfs_undeleteМы прошерстили интернеты и нашли на Гитхабе скриптик под названием xfs_undelete. Скрипт на TCL, на вид не очень сложный. Решили его внимательно изучить.Он поднимает по некоторым введенным параметрам удаленные с дисков айноды: сканирует файловую систему, пытается найти айноды по заданным параметрам, если получилось — поднимает их в память, если они нормально прочитались — записывает их на диск. У него даже есть отдельный сабреддит с поддержкой — практически уровень энтерпрайзного ПО.Мы попробовали позапускать скрипт на наших дисках — все работало. Но был ряд дополнительных сложностей (куда же без них).Проблема: как поднять данные с 800 дисковНужно поднять данные не с одного диска, а с 800. И записать эти данные в тучу S3-бакетов (больше некуда было).Мы написали сложную bash-магию, которая вылилась в три скрипта: подготовка, запуск и watchdog.Блок-схема скрипта подготовкиСкрипт подготовки из нашего инвентори собирает информацию о серверах и примонтированных дисках, создает S3-бакеты, разливает пакеты и монтирует S3-бакеты через S3-fuse. Это не лучший метод, но какой был: быстро, просто, а на скорость записи тогда смотрели в последнюю очередь.Скрипт запуска xfs_undeleteСкрипт запуска собирал из inventory все точки монтирования для всех серверов, рассчитывал временные метки (он знал, когда я удалил данные, и отсчитывал от текущего момента разницу), собирал shell-однострочники для запуска xfs_undetele с нужными параметрами, раскладывал это на серверы и запускал. Ну и да, еще логировал свои действия.WatchdogТретий скрипт делал до четырех попыток перезапуска xfs_undelete и писал понятный лог, с которым можно было работать.В итоге мы восстановили некое количество бинарных блоков и не особо выбирали, что можем восстановить. У нас был таймфрейм с 16:00 до 17:00 11 января. Мы пытались восстановить данные, но в это время (в указанный таймфрейм, пока мы бегали и думали, что делать) работала еще куча процессов — и в итоге мы подняли 1,1 петабайта вместо 200 терабайт.Мы рассчитывали на 400 терабайт, потому что RF2: 200 удалили + 200 копия — 400 подняли. В итоге притащили кучу мусора и потеряли длину исходных файлов, потому что восстанавливались не начальные файлы, а блоки файловой системы. Блоки устроены так, что если записал чуть меньше блока, то в конце будут нули или вообще какой-то мусор.Теперь у нас был фарш и, кажется, можно было делать котлеты. Но задача была, наоборот, провернуть фарш назад и найти мясо.\xa0Кажется, это был хороший момент поднять продакшен, ведь мы подняли данные. Но это не так, потому что мы подняли не паркеты и вообще не доверяли тем блокам. В тот момент мы пока не знали, как восстанавливать паркеты. Если бы мы включили кластер, то гарантированно отрезали бы себе путь к перевыгрузке удаленных блоков или к возможности еще что-то сделать с данными, потому что их могли перетереть.Были и другие проблемыРасскажу, что у нас произошло из-за выключенного кластера. Пострадала аналитика звонков, охлаждение данных из нашего основного движка Greenplum, встала поставка данных из внешних источников NiFi и работа с А/В-тестами. Но главное, январь на дворе, а логистика — суровая штука. И у нас проблемы с подарками детям и сотрудникам из-за того, что доступа к нужным данным нет (они в том самом выключенном проде).Проблема: как спасти productionМаленького HDFS на все не хватало, и мы подняли еще один HDFS на 5 петабайт.\xa0И тут опять вопрос: отчего вы его раньше-то не подняли? А это были не наши серверы, нам их по доброте душевной дали коллеги, которые должны были там поднять для нас кое-что другое.\xa0Подняли большой кластер, благо у нас был довольно свежий дамп метаданных HDFS. При помощи Питона, напильника и простого советского мата научились выгружать данные из выключенного кластера HDFS во включенный.\xa0Мы перелили все самое критичное, что просили пользователи, на новый кластер и пошли дальше заниматься восстановлением.У нас было 800+ бакетов S3, и нужно было найти там что-нибудь полезное. Поднялись на уровень HDFS и взяли бэкап меты. Из него мы нашли список исходных файлов и для части файлов нашли оригинальное расположение, которое нам пригодилось позже.Проблема: как восстановить блоки HDFS и сделать из них parquet-файлыТребовалось поднять нужные блоки HDFS из фарша и очистить их от мусора. А потом разобраться, где там паркеты, и восстановить их.Структура parquet-файлаСверху — parquet одноблочный, который влез в блок HDFS. В нашем случае это 512 мегабайт, и нам очень повезло, что это parquet.Parquet — структурированный файл, у него есть четкая метка начала и метка конца: PAR1. При этом в конце файла есть метаданные, в которых указана структура файла, row-группы и их расположение и еще много чего полезного.Нюанс вот в чем: если файлы небольшие, они влезают в блоки HDFS, они неразрывные, есть начало и конец. Все счастливы, все классно.\xa0Но есть история, когда паркет не влез в один блок файловой системы и он занимает больше: два блока или триста — сколько угодно. Parquet где-то пилится, причем он может пилиться посередине, а может пилиться непонятно как.Мы попытались все это восстановить. Для начала нам надо было хотя бы отфильтровать и разметить данные.\xa0Алгоритм для одноблочных файлов:Проверяем PAR1 в начале файла.Проверяем PAR1 в конце файла.Восстанавливаем исходную длину файла и обрезаем нули в конце.Пытаемся прочитать.Если в конце PAR1, по смещению с конца достаем мету паркета.Считаем hash от файла для поиска дублей (RF2).Алгоритм восстановления примерно такой же:Проверяем PAR1 в начале файла.Проверяем PAR1 в конце файла.В метаданных находим правильное имя таблицы.Проверяем правильную схему паркета.Файл полностью читается (нет битых блоков внутри).Алгоритмы для одноблочных файлов выглядят довольно просто. А вот дальше началось еще одно веселье — многоблочные паркеты. Там оказалось немного черной магии.Конец паркета несложно найти, у него в конце PAR1 — читаем метку, это будет хвост.\xa0Мы нашли интересную закономерность: внутри parquet-файла, в той части, где данные, есть magic numbers, но они нефиксированные и зависят от того, чем и как мы записываем эти паркеты.Magic numbers в parquet-файлах (зависят от реализации записи)Алгоритм восстановления:\xa0Взять хвост паркета, там есть карта офсетов — расстояний между началами row groups.\xa0Найти magic numbers.Отсканировать все-все байты.Получить для всех файлов, похожих на то, что нам надо, карту офсетов внутри этих файлов.Наложить одно на другое и так собрать большие пакеты.Попытаться прочитать то, что получилось.Задача была не самая простая и не самая быстрая, но там, где это получилось, мы считали, что данные восстановились.У нас были собранные паркеты в S3, теперь очередь данных в HDFS. Вроде ничего сложного, но с нюансом: нужно было восстановить структуру партиций.Как выглядят партиции в HDFSНужно было восстановить партиции, потому что код обработки заточен под структуру папок. Иначе обработка была бы неоптимальной. Ну и в целом — откуда данные удалил, туда и верни.В данных обычно можно найти поле, по которому сделано партиционирование, но это не всегда так. Иногда внутри данных не остается полей, по которым разложены партиции, и это как раз наш случай.Довольно много времени занял разбор данных, чтобы понять, как синтезировать те поля, по которым все было разложено, или хотя бы близкие к ним. Получилась некая аналитическая работа.Например, в одной из таблиц были партиции по времени загрузки данных на сервер. Для большинства случаев это время очень близко к времени отправки данных клиентом, а оно у нас сохранилось внутри файлов.По таймлайну мы начали в феврале — и сделали только к концу апреля. Пусть долго, но хотя бы разложили.Проблема: нет половины данныхМы проверили итоги — и вроде бы 90% минимум было по объему. Но аналитики сказали: «Ребята, извините, 45% восстановлено». Нам показалось, что совпадение какое-то странное.\xa0Оказалось, что в эксельке, по которой ребята сверялись, всплыли неочевидные дубли. Строка Total подло закралась в середину файла, а не сидела себе в конце, как все остальные Total. И когда считали сумму нужных строк, данные фактически задвоились.Что у нас получилосьСначала о позитивном: у нас получилось поднять фарш и из фарша восстановить 90%. Какое-то время мы были счастливы: продакшен-процессы вернули, подарки детям и сотрудникам доехали — праздник не пострадал.В процессе мы подняли пару кластеров HDFS. Казалось бы, нужно что-то удалить и сломать — и у нас тут же появятся мощности. Не надо так делать.Но было много не очень хорошего:Считали систему неважной. Hadoop где-то там далеко и заброшен, эдакая дача для данных — кладите и не будем разбираться.Не было Governance и квотирования, поэтому у нас был RF2, и это нас спасло. Если бы был RF3, нам бы потребовалось 1,5 петабайта — и их точно некуда было девать.Удаление мимо корзины и без уведомления — плохое решение.Какие выводы сделалиТеперь поговорим о том, как этого можно было избежать. Тут я надеваю погоны капитана Очевидность:\xa0Удалять данные только через корзину. Да, это чуть дороже, но нервы всем еще пригодятся.Не делать на проде ничего без явных апрувов (лучше в git). Если есть важная система хранения, нужно стараться использовать инструменты управления данными, в которых нужны вторые руки для серьезных действий. Если нет готовых, то напишите. Это не панацея, но неплохой аварийный клапан.Что мы сделали у себя нового для избежания подобных ситуацийTTL для данных из коробки. Есть репозиторий, в который нам приносят yaml, в yaml указан путь владельца или группа, потому что владелец может уволиться или еще что-то с ним может произойти.Gitops для TTL данных на HDFSТри важных параметра:\xa0Наличие подпапок — это важно, потому что у нас вся эта история заточена на определенную структуру папок или подпапок.\xa0TTL — сколько дней хранить данные.Откуда считать TTL — суперважный флаг, который может выстрелить в ногу, если его не сделать.\xa0Почему это важно? Потому что вполне может быть картина, что грузили, грузили, грузили данные и потом перестали их грузить. И вот они год лежат без дела.\xa0Если считать TTL год от сегодня, когда уже прошел год — мы все удалим. Если надо хранить последний год, а это вполне бывает по регуляторным соображениям, то вот этот флаг вас может как раз спасти.\xa0Если yaml валидный, он проверяется на корректность того, что этот yaml правильный, yaml на схему. Прогоняется dry run при MR и пишет что-то вроде: «Я бы удалил такое, проверь, корректно или нет». Если корректно, выставляется в cron и по указанным правилам данные чистятся.Но на семь дней данные всегда помещаются в корзину и там маринуются. Если семь дней прошло и никто не пришел — можно удалять. Если больше семи дней — извините. Можно, конечно, держать данные дольше, но не всегда это оправданно. Нам пока вроде семи дней хватает. Квотирование — важная штука, которой у нас не было и которую мы очень хотели. В HDFS квотирование есть из коробки, можно по папочкам настроить квоты.\xa0Gitops для квотирования записи на HDFSКвоты работают изолированно: если кончилась квота на запись в папку A, тому, кто в нее пишет, придет ошибка. При этом в папку B все продолжит писаться.\xa0Но есть нюанс. Нам хотелось к этой штуке какого-то внятного управления (а не руками по консолям бегать), и мы написали gitops c yaml: путь, владелец, квота и какое-то описание.Напоследок скажу еще пару слов по поводу «как можно было бы избежать», но это уже про процессы и про подумать.\xa0Данные в дата-платформах растут, никаких исключений. Если данные в платформе не растут, что-то не так с платформой или с бизнесом.Если ваша система не под EOL, то озаботьтесь ее расширением. Или хотя бы такой возможностью. Если вы считаете ее EOL / legacy / как хотите называйте, то убедитесь, что все вокруг считают так же. Желательно, чтобы была какая-то замена, но это отдельный вопрос.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('Security Week 2521: Spectre-подобная уязвимость в процессорах Intel',), kwargs={}
Результат: security week 2521 spectreподобная уязвимость в процессорах intel
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: contains_keywords
Аргументы: args=('Security Week 2521: Spectre-подобная уязвимость в процессорах Intel', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:13 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('На прошлой неделе исследователи из Швейцарской высшей технической школы Цюриха (ETH Zurich) опубликовали детали новой аппаратной уязвимости, затрагивающей процессоры Intel шести поколений начиная с 2018 года. Новое исследование стало логическим продолжением предыдущей работы (мы писали о ней здесь), в которой была предложена атака Retbleed. Новая атака, получившая название Branch Privilege Injection, также нацелена на обход защитных механизмов, предложенных после обнаружения уязвимости Spectre v2 еще в 2017 году. \n\n\n\nSpectre v2 эксплуатирует «фичу» всех современных процессоров, обеспечивающую спекулятивное выполнение инструкций еще до того, как был получен результат предыдущих вычислений. Как выяснилось в 2017 году, это открывает возможность чтения данных из защищенных областей оперативной памяти. Механизм предсказания ветвлений можно натренировать так, что секретная (обычно недоступная атакующему) информация будет загружена в кэш-память процессора и считана оттуда «по стороннему каналу». Новая работа исследователей ETH Zurich демонстрирует, как можно обойти сразу два разных метода, направленных на защиту от Spectre-подобных атак, реализовав состояние гонки в работе предсказателя ветвлений.\n\nДля защиты от Spectre v2 в процессорах Intel были применены технологии Indirect Branch Restricted Speculation (IBRS) и Indirect Branch Prediction Barrier (IBPB). Обе разными методами направлены на решение общей задачи: запретить спекулятивный доступ к чувствительным областям оперативной памяти либо отменить результаты вычислений до того, как данные сможет прочитать потенциальный злоумышленник. Развивая успех Retbleed (где удалось обойти «программный» метод защиты, известный как Retpoline), исследователи обнаружили, что ограничения на работу системы спекулятивного выполнения инструкций накладываются асинхронно с собственно самим спекулятивным выполнением. При переключении между выполнением инструкций для разных пользователей, с высокими и низкими привилегиями в системе, возникает ситуация, при которой можно выполнить инструкции от процесса без привилегий, и на них не будут распространяться ограничения IBRS или IBPB.\n\nВ результате авторам работы удалось реализовать систему чтения произвольных участков оперативной памяти в ОС Ubuntu процессом без привилегий и с достаточно высокой для такого метода скоростью 5,6 килобайта в секунду. Точность считывания секретов также была высокой — до 98%. Исследователи нашли сразу три разных варианта организовать состояние гонки. Два из них реализуют разные сценарии обхода защиты IBRS, соответственно для приложения с привилегиями пользователя, способного выполнять чтение из памяти ядра ОС, и для гостевой ОС, способной читать данные, доступные только гипервизору. Отдельно был исследован метод обхода технологии IBPB.\n\nУязвимости подвержены процессоры Intel, выпускаемые с 2018 года, когда начали применяться технологии защиты от атак типа Spectre v2, и вплоть до поколения Raptor Cove 2023 года. Отдельно были исследованы процессоры AMD Zen 4 и Zen 5, а также процессоры на архитектуре ARM с ядрами Cortex X1 и A76. На AMD и ARM подобную атаку реализовать не удалось — из-за отличий в реализации технологии предсказания ветвлений. Более современные процессоры Intel также неуязвимы, так как имеют расширенную систему блокировки потенциально опасных спекулятивных вычислений. В подверженных уязвимости процессорах Intel проблема решается с помощью обновления микрокода.\n\nЧто еще произошло\n\nЭксперты «Лаборатории Касперского» делятся наблюдениями и прогнозами по эволюции шифровальщиков в 2025 году. Еще одна публикация анализирует ландшафт угроз для систем промышленной автоматизации в первом квартале этого года.\n\nКомпания Google анонсировала набор технологий Advanced Protection для устройств на базе Android, аналогичный Lockdown Mode в смартфонах Apple iPhone. Advanced Protection включает целый ряд защитных механизмов, включая, например, запрет на подключение к сетям 2G, ограничение передачи данных по кабелю, а также ведение расширенных логов, упрощающих выявление попыток взлома.\n\nАпдейт iOS/iPadOS до версии 18.5 закрывает ряд серьезных уязвимостей и одну досадную ошибку в мессенджере FaceTime — там в некоторых случаях во время звонков не работала кнопка Mute.',), kwargs={}
Результат: на прошлой неделе исследователи из швейцарской высшей технической школы цюриха eth zurich опубликовали детали новой аппаратной уязвимости затрагивающей процессоры intel шести поколений начиная с 2018 года новое исследование стало логическим продолжением предыдущей работы мы писали о ней здесь в которой была предложена атака retbleed новая атака получившая название branch privilege injection также нацелена на обход защитных механизмов предложенных после обнаружения уязвимости spectre v2 еще в 2017 году 



spectre v2 эксплуатирует фичу всех современных процессоров обеспечивающую спекулятивное выполнение инструкций еще до того как был получен результат предыдущих вычислений как выяснилось в 2017 году это открывает возможность чтения данных из защищенных областей оперативной памяти механизм предсказания ветвлений можно натренировать так что секретная обычно недоступная атакующему информация будет загружена в кэшпамять процессора и считана оттуда по стороннему каналу новая работа исследователей eth zurich демонстрирует как можно обойти сразу два разных метода направленных на защиту от spectreподобных атак реализовав состояние гонки в работе предсказателя ветвлений

для защиты от spectre v2 в процессорах intel были применены технологии indirect branch restricted speculation ibrs и indirect branch prediction barrier ibpb обе разными методами направлены на решение общей задачи запретить спекулятивный доступ к чувствительным областям оперативной памяти либо отменить результаты вычислений до того как данные сможет прочитать потенциальный злоумышленник развивая успех retbleed где удалось обойти программный метод защиты известный как retpoline исследователи обнаружили что ограничения на работу системы спекулятивного выполнения инструкций накладываются асинхронно с собственно самим спекулятивным выполнением при переключении между выполнением инструкций для разных пользователей с высокими и низкими привилегиями в системе возникает ситуация при которой можно выполнить инструкции от процесса без привилегий и на них не будут распространяться ограничения ibrs или ibpb

в результате авторам работы удалось реализовать систему чтения произвольных участков оперативной памяти в ос ubuntu процессом без привилегий и с достаточно высокой для такого метода скоростью 56 килобайта в секунду точность считывания секретов также была высокой  до 98 исследователи нашли сразу три разных варианта организовать состояние гонки два из них реализуют разные сценарии обхода защиты ibrs соответственно для приложения с привилегиями пользователя способного выполнять чтение из памяти ядра ос и для гостевой ос способной читать данные доступные только гипервизору отдельно был исследован метод обхода технологии ibpb

уязвимости подвержены процессоры intel выпускаемые с 2018 года когда начали применяться технологии защиты от атак типа spectre v2 и вплоть до поколения raptor cove 2023 года отдельно были исследованы процессоры amd zen 4 и zen 5 а также процессоры на архитектуре arm с ядрами cortex x1 и a76 на amd и arm подобную атаку реализовать не удалось  изза отличий в реализации технологии предсказания ветвлений более современные процессоры intel также неуязвимы так как имеют расширенную систему блокировки потенциально опасных спекулятивных вычислений в подверженных уязвимости процессорах intel проблема решается с помощью обновления микрокода

что еще произошло

эксперты лаборатории касперского делятся наблюдениями и прогнозами по эволюции шифровальщиков в 2025 году еще одна публикация анализирует ландшафт угроз для систем промышленной автоматизации в первом квартале этого года

компания google анонсировала набор технологий advanced protection для устройств на базе android аналогичный lockdown mode в смартфонах apple iphone advanced protection включает целый ряд защитных механизмов включая например запрет на подключение к сетям 2g ограничение передачи данных по кабелю а также ведение расширенных логов упрощающих выявление попыток взлома

апдейт iosipados до версии 185 закрывает ряд серьезных уязвимостей и одну досадную ошибку в мессенджере facetime  там в некоторых случаях во время звонков не работала кнопка mute
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: contains_keywords
Аргументы: args=('На прошлой неделе исследователи из Швейцарской высшей технической школы Цюриха (ETH Zurich) опубликовали детали новой аппаратной уязвимости, затрагивающей процессоры Intel шести поколений начиная с 2018 года. Новое исследование стало логическим продолжением предыдущей работы (мы писали о ней здесь), в которой была предложена атака Retbleed. Новая атака, получившая название Branch Privilege Injection, также нацелена на обход защитных механизмов, предложенных после обнаружения уязвимости Spectre v2 еще в 2017 году. \n\n\n\nSpectre v2 эксплуатирует «фичу» всех современных процессоров, обеспечивающую спекулятивное выполнение инструкций еще до того, как был получен результат предыдущих вычислений. Как выяснилось в 2017 году, это открывает возможность чтения данных из защищенных областей оперативной памяти. Механизм предсказания ветвлений можно натренировать так, что секретная (обычно недоступная атакующему) информация будет загружена в кэш-память процессора и считана оттуда «по стороннему каналу». Новая работа исследователей ETH Zurich демонстрирует, как можно обойти сразу два разных метода, направленных на защиту от Spectre-подобных атак, реализовав состояние гонки в работе предсказателя ветвлений.\n\nДля защиты от Spectre v2 в процессорах Intel были применены технологии Indirect Branch Restricted Speculation (IBRS) и Indirect Branch Prediction Barrier (IBPB). Обе разными методами направлены на решение общей задачи: запретить спекулятивный доступ к чувствительным областям оперативной памяти либо отменить результаты вычислений до того, как данные сможет прочитать потенциальный злоумышленник. Развивая успех Retbleed (где удалось обойти «программный» метод защиты, известный как Retpoline), исследователи обнаружили, что ограничения на работу системы спекулятивного выполнения инструкций накладываются асинхронно с собственно самим спекулятивным выполнением. При переключении между выполнением инструкций для разных пользователей, с высокими и низкими привилегиями в системе, возникает ситуация, при которой можно выполнить инструкции от процесса без привилегий, и на них не будут распространяться ограничения IBRS или IBPB.\n\nВ результате авторам работы удалось реализовать систему чтения произвольных участков оперативной памяти в ОС Ubuntu процессом без привилегий и с достаточно высокой для такого метода скоростью 5,6 килобайта в секунду. Точность считывания секретов также была высокой — до 98%. Исследователи нашли сразу три разных варианта организовать состояние гонки. Два из них реализуют разные сценарии обхода защиты IBRS, соответственно для приложения с привилегиями пользователя, способного выполнять чтение из памяти ядра ОС, и для гостевой ОС, способной читать данные, доступные только гипервизору. Отдельно был исследован метод обхода технологии IBPB.\n\nУязвимости подвержены процессоры Intel, выпускаемые с 2018 года, когда начали применяться технологии защиты от атак типа Spectre v2, и вплоть до поколения Raptor Cove 2023 года. Отдельно были исследованы процессоры AMD Zen 4 и Zen 5, а также процессоры на архитектуре ARM с ядрами Cortex X1 и A76. На AMD и ARM подобную атаку реализовать не удалось — из-за отличий в реализации технологии предсказания ветвлений. Более современные процессоры Intel также неуязвимы, так как имеют расширенную систему блокировки потенциально опасных спекулятивных вычислений. В подверженных уязвимости процессорах Intel проблема решается с помощью обновления микрокода.\n\nЧто еще произошло\n\nЭксперты «Лаборатории Касперского» делятся наблюдениями и прогнозами по эволюции шифровальщиков в 2025 году. Еще одна публикация анализирует ландшафт угроз для систем промышленной автоматизации в первом квартале этого года.\n\nКомпания Google анонсировала набор технологий Advanced Protection для устройств на базе Android, аналогичный Lockdown Mode в смартфонах Apple iPhone. Advanced Protection включает целый ряд защитных механизмов, включая, например, запрет на подключение к сетям 2G, ограничение передачи данных по кабелю, а также ведение расширенных логов, упрощающих выявление попыток взлома.\n\nАпдейт iOS/iPadOS до версии 18.5 закрывает ряд серьезных уязвимостей и одну досадную ошибку в мессенджере FaceTime — там в некоторых случаях во время звонков не работала кнопка Mute.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('Почему топовые UI-дизайнеры используют фракталы с D 1.3–1.7: научный подход к визуальной гармонии',), kwargs={}
Результат: почему топовые uiдизайнеры используют фракталы с d 1317 научный подход к визуальной гармонии
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: contains_keywords
Аргументы: args=('Почему топовые UI-дизайнеры используют фракталы с D 1.3–1.7: научный подход к визуальной гармонии', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('Кого ИИ уже уволил, а кто только ждёт своей очереди? Как ИИ меняет рынок труда — разбор мифов и фактов',), kwargs={}
Результат: кого ии уже уволил а кто только ждёт своей очереди как ии меняет рынок труда  разбор мифов и фактов
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: contains_keywords
Аргументы: args=('Кого ИИ уже уволил, а кто только ждёт своей очереди? Как ИИ меняет рынок труда — разбор мифов и фактов', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:14 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('Нейросети («ИИ») больше не инструмент будущего — это активный участник рынка труда. От HR-отделов до бухгалтерии, от школ до юридических фирм — машины не только помогают, а кое-где заменяют. Эта статья — о том, какие профессии исчезают, а какие трансформируются, и что делать, чтобы остаться на плаву в эпоху алгоритмов.Здесь и далее мы будем использовать термин ИИ (искусственный интеллект) в качестве описания, в основном, нейронных сетей.ИИ — очень широкое и объёмное понятие, включающее в себя множество технологий, методов и подходов. Кроме того, необходимо различать узкий искусственный интеллект, искусственный интеллект общего назначения и искусственный суперинтеллект.А ещё не следует путать всё это с машинным обучением, глубоким обучением, генеративным ИИ и так далее.Слова модные, тема хайповая, часто термины используются как синонимы, что создает путаницу.❯ ИИ начал действоватьКогда ChatGPT сгенерировал свой первый текст, а Midjourney — первую картинку, мир ещё смеялся: «Ну, ведь полное месиво! Что это за ерунда?!». Два года спустя смеха стало меньше. А в некоторых офисах уже некому смеяться — работодатели заменили сотрудников.А начиналось всё примерно вот так (и это в лучшем случае)ИИ перестал быть «будущим». Он внедрился в настоящее: редактирует статьи на новостных сайтах, проводит собеседования, пишет код, подбирает маркетинговые стратегии и рисует рекламу быстрее, чем успевает моргнуть человек. Его внедрение — не тренд, а тихая революция. Только эта революция не с баррикадами, а с письмами об увольнении и автоматизированными воркфлоу.Согласно\xa0отчёту\xa0McKinsey (за 2024 год), более 70% крупных компаний уже интегрировали генеративный ИИ в свои ключевые бизнес-процессы — от IT до продаж. IBM официально заявила о замене сотен сотрудников ИИ-решениями в HR-отделах. И даже если ИИ пока не увольняет напрямую, он замораживает рост зарплат в профессиях, где способен составить достойную конкуренцию.ИИ не стучит в дверь — он уже внутри. И самый главный вопрос теперь не «Заменит ли он нас?», а «Кого он заменит первым — и можно ли выжить в его эпоху?». Давайте разбираться.❯ На грани: профессии, вытесняемые ИИЕсли раньше автоматизация угрожала в основном производственным линиям, то сегодня под ударом оказались все офисные жители.В 2023 году IBM\xa0официально заявила\xa0о замене сотен сотрудников в отделах HR на ИИ-агентов, выполняющих задачи по анализу данных и составлению писем. Благодаря этому решению, кстати, удалось высвободить ресурсы для расширения штата программистов, продавцов и специалистов по маркетингу. То есть работу получило больше людей. За исключением уволенных сотрудников, разумеется.Где-то в офисе IBM 🙂В 2025 году крупные компании (в частности Morgan Stanley, UPS, Meta*, Wayfair, Salesforce, HP Enterprise и Workday) объявили или анонсировали массовые увольнения, часто ссылаясь на оптимизацию процессов и внедрение ИИ. Например, UPS\xa0планирует сократить\xa020 000 сотрудников, а Chevron — до 9 000 человек.37% компаний, использующих ИИ, ещё в 2023 году сообщили о сокращении персонала из-за внедрения новых технологий. А по прогнозу World Economic Forum, к 2027 году могут быть сокращены:7,5 млн операторов CRM и рутинного документооборота;5 млн офис-ассистентов и административных помощников;4,5 млн бухгалтеров и специалистов по учёту.Как видим, ИИ уже не просто инструмент — он становится полноценным участником рынка труда, весьма серьёзно изменяя его ландшафт и заставляя многих специалистов переосмысливать свою роль в новой реальности.❯ Профессии под очевидной угрозойКроме уже перечисленного, на очереди специалисты, чья работа требует не только знаний и механического труда, но и опыта, анализа, нюансов. Именно они становятся следующими кандидатами на оптимизацию.Юристы и юридические ассистенты.ИИ уже способен анализировать юридические документы, находить противоречия и предлагать правки. Например существует Harvey AI, который используют в крупных юридических фирмах: он умеет обрабатывать тысячи страниц сложных специфических и юридических текстов за минуты.Это серьёзная угроза младшим юристам и помощникам, чья работа как раз – готовить документы и анализировать кейсы.Кадр из мульсериала «Футурама»Бухгалтеры и аудиторы.Программы способны автоматически обрабатывать транзакции, составлять отчёты, считать налоги и выявлять кассовые разрывы с аномалиями. Это особенно удобно для малого и среднего бизнеса, которому выгоднее заплатить подписку за AI-сервис, чем держать в штате бухгалтера.Они копируют даже мимику в день начисления зарплат!Журналисты и редакторы.ИИ уже генерирует новости, пишет статьи и даже анализирует данные для сложных расследований. Платформы, использующие ИИ, способны создавать контент быстрее и дешевле, чем человек, притом только за последний год уровень написания статей стал на две головы выше, и тексты написанные нейросетями кажутся все более и более человеческими.Еще бы нейросеть-рукописца для врачей…Учителя и преподаватели.Да, существует онлайн-обучение с ИИ-репетиторами: таким уже занимается академия Хана, (Khan Academy), южнокорейская QANDA и некоторые другие платформы, которые предлагают персонализированные программы обучения, адаптированные под каждого ученика.Дети тянутся к знаниямНачинающие программисты.Как\xa0заявил\xa0CEO Microsoft, до 30% кода в компании уже генериует ИИ, и эта доля будет только расти. Это означает, что задачи, ранее выполняемые младшими разработчиками, теперь подлежат автоматизации. Компании всё чаще ищут специалистов, способных управлять ИИ-инструментами, а не писать код с нуля.❯ Масштаб трагедии: мифы и реальностьЕсли говорить коротко и начистоту — есть чего бояться. Но насколько оправданы эти опасения?Первое и самое распространённое заблуждение — ИИ массово уничтожает рабочие места.Прогнозы прогнозами, но пока что ИИ хорошо справляется с узкими задачами: сортировка и обработка данных, составление резюме, подбор ключевых слов, создание структуры текста и тому подобными. Но он далёк от того, чтобы полностью заменить человеческое мышление, эмоциональный интеллект и способность к принятию комплексных решений. На деле ИИ чаще всего дополняет человека-специалиста, снимая с него рутину и высвобождая время на то, что требует настоящего мышления и творческого подхода.Некоторые утверждают, что ИИ создаёт больше рабочих мест, чем уничтожает. Отчасти это правда. Всемирный экономический форум в 2020 году оценил, что в 2025 году ИИ может заменить 85 миллионов рабочих мест, но при этом создать около 97 миллионов новых. Ждём до конца года — проверим точность прогноза.Проблема в том, что новые рабочие места потребуют других навыков. И если человек не успеет адаптироваться — его место займёт кто-то более подготовленный или... ИИ.Есть и более тонкие последствия, о которых говорят реже. Например, ИИ действительно повышает производительность — но одновременно может увеличить нагрузку. Ожидания бизнеса растут: если раньше отчёт подготавливали день, теперь его требуют за час — потому что «у нас же есть ИИ». Это может привести к выгоранию, стрессу и ощущению, что человек теперь просто «надзиратель» за машиной, а не активный участник процесса.Вывод прост:\xa0ИИ — не катастрофа и не спасение. Он — катализатор изменений. Реакция на них и станет настоящей развилкой.❯ А кто выигрывает?Кроме автоматизации рутинных задач, ИИ также становится мощным инструментом, усиливающим определённые профессии, делая их более продуктивными и востребованными.В консалтинговой компании EY внедрение ИИ позволило не только сохранить, но и увеличить численность персонала. Генеральный директор EY, Джанет Транкейл,\xa0отметила, что ИИ помогает сотрудникам сосредоточиться на более сложных и интересных задачах, повышая общую ценность человеческого труда.Кого ИИ уже уволил, а кто только ждёт своей очереди? Как ИИ меняет рынок труда — разбор мифов и фактовВ IBM ИИ заменил сотни позиций в отделах кадров, выполняя задачи по анализу данных и составлению писем. Однако, это позволило компании расширить штат в области программирования и продаж, где требуются критическое мышление и навыки межличностного общения.Тем временем появляются и новые профессии, напрямую связанные с ИИ. Согласно данным Гарвардского университета, стремительно растёт спрос на специалистов по этике ИИ — именно они отвечают за то, чтобы алгоритмы работали прозрачно, не воспроизводили дискриминацию и соответствовали общественным и правовым нормам.Многим компаниям теперь необходимы инженеры по машинному обучению (ML-инженеры), сегодня они — одни из самых востребованных технических специалистов: они создают, обучают и оптимизируют ИИ-модели, которые лежат в основе рекомендательных систем, чат-ботов, предиктивной аналитики и других инструментов.Точно так же бизнесу требуются менеджеры по продуктам ИИ — они формируют видение продукта, определяют, где именно алгоритмы принесут наибольшую пользу, и следят за тем, чтобы решения были не только технологичны, но и полезны людям.Ниже мы разобрали тактики выживания в эпоху ИИ и типичные ошибки, которых стоит избегать.❯ Как выжить и не утонуть в эпоху ИИ: тактика и ловушкиИИ не угрожает рынку труда сам по себе — угрозу несёт привычка игнорировать перемены. Побеждают не самые опытные, а самые адаптивные. Сегодня знание технологий становится частью базовой грамотности, как когда-то — умение читать или пользоваться интернетом. Не освоить ИИ, значит — осознанно остаться в слепой зоне нового рынка.Я пришёл вывести вас из слепой зоны!\nКадр из фильма «Терминатор 2: Судный день»Первый шаг к выживанию — пересборка своей профессиональной идентичности. Задайте себе вопрос: какую уникальную ценность я создаю — ту, что алгоритмы пока не могут воспроизвести? Это может быть стратегическое мышление, живое общение, способность чувствовать контекст и «читать между строк». ИИ снимает рутину, но не избавляет от ответственности. Чем больше ваша роль опирается на глубокое понимание, тем труднее вас заменить.Второй шаг — освоение инструментов. Не обязательно быть IT-специалистом, но жизненно важно уметь пользоваться тем, что уже изменяет рынок: ChatGPT, Copilot, Midjourney, Notion AI и другими инструментами. Самая большая ошибка — надеяться, что «пронесёт» или «можно же обойтись без этого». Нет, уже нельзя!Остаться без навыков ИИ — это как выйти на рынок труда без знания языка, на котором все вокруг уже говорят. В общем, это уже hard skill.Нельзя также полагаться на ИИ как на некую волшебную палочку. Это не магия, а усилитель сильных сторон — или катализатор слабых. Если вы не умеете формулировать мысли, нейросеть не поймёт, что от неё требуют. Если боитесь принимать решения — алгоритм не возьмёт на себя ответственность. Одна из главных ошибок думать, что ИИ заменит усилия. Нет: он требует новых усилий, просто другого качества.И, пожалуй, самая опасная ловушка — выгореть на фоне неопределённости. Да, ритм ускорился. Да, нужно учиться почти постоянно. Но это не гонка на выживание — это смена модели. Кто начинает использовать ИИ как союзника, а не как врага или угрозу, — получает не только преимущество, но и ощущение контроля над происходящим. А это уже половина успеха.❯ Вместо эпилога: не про ИИ, а про нас, человековИИ — это не метеорит, который вот-вот упадёт с неба и все замерли в ожидании. Он уже здесь. И дело не в том, когда он что-то «отберёт» или «изменит», а в том, как мы научимся сосуществовать с новой реальностью. Машины не устраивают революций — это делают люди, которые либо отказываются меняться, либо оседлали волну.Сегодняшний рынок — это не деление на сильных и слабых, а на «включённых» и «отключённых». ИИ становится новым языком — рабочим, деловым, человеческим. Тот, кто научился на нём говорить, не просто эффективнее. Он — понятен. Он — в контексте. Он — конкурентоспособен.Самое важное — не обмануться в ожиданиях. ИИ не заменит человека. Но он может заменить того человека, который откажется им пользоваться. А между «заменит» и «усилит» — тонкая грань, и она сегодня проводится каждым из нас.ИИ не про технологии. Он про выбор. И этот выбор — каждый день. Не нужно ждать, пока мир поменяется, нужно менять его и меняться вместе с ним.Новости, обзоры продуктов и конкурсы от команды\xa0Timeweb.Cloud\xa0— в нашем Telegram-канале\xa0↩Опробовать ↩📚 Читайте также:➤\xa0Галлюцинации моделей текстовых ИИ, и как с ними бороться➤\xa0Нейро-дайджест: ключевые события мира AI за 5 – 12 мая 2025➤\xa0ИИ для веб-разработки➤\xa0Перешагивая через века. Rise of nations: Thrones & Patriots➤\xa0Самые безумные и неожиданные кроссоверы игровой индустрии. Сейчас такое уже не сделают',), kwargs={}
Результат: нейросети ии больше не инструмент будущего  это активный участник рынка труда от hrотделов до бухгалтерии от школ до юридических фирм  машины не только помогают а коегде заменяют эта статья  о том какие профессии исчезают а какие трансформируются и что делать чтобы остаться на плаву в эпоху алгоритмовздесь и далее мы будем использовать термин ии искусственный интеллект в качестве описания в основном нейронных сетейии  очень широкое и объёмное понятие включающее в себя множество технологий методов и подходов кроме того необходимо различать узкий искусственный интеллект искусственный интеллект общего назначения и искусственный суперинтеллекта ещё не следует путать всё это с машинным обучением глубоким обучением генеративным ии и так далееслова модные тема хайповая часто термины используются как синонимы что создает путаницу ии начал действоватькогда chatgpt сгенерировал свой первый текст а midjourney  первую картинку мир ещё смеялся ну ведь полное месиво что это за ерунда два года спустя смеха стало меньше а в некоторых офисах уже некому смеяться  работодатели заменили сотрудникова начиналось всё примерно вот так и это в лучшем случаеии перестал быть будущим он внедрился в настоящее редактирует статьи на новостных сайтах проводит собеседования пишет код подбирает маркетинговые стратегии и рисует рекламу быстрее чем успевает моргнуть человек его внедрение  не тренд а тихая революция только эта революция не с баррикадами а с письмами об увольнении и автоматизированными воркфлоусогласно отчёту mckinsey за 2024 год более 70 крупных компаний уже интегрировали генеративный ии в свои ключевые бизнеспроцессы  от it до продаж ibm официально заявила о замене сотен сотрудников иирешениями в hrотделах и даже если ии пока не увольняет напрямую он замораживает рост зарплат в профессиях где способен составить достойную конкуренциюии не стучит в дверь  он уже внутри и самый главный вопрос теперь не заменит ли он нас а кого он заменит первым  и можно ли выжить в его эпоху давайте разбираться на грани профессии вытесняемые ииесли раньше автоматизация угрожала в основном производственным линиям то сегодня под ударом оказались все офисные жителив 2023 году ibm официально заявила о замене сотен сотрудников в отделах hr на ииагентов выполняющих задачи по анализу данных и составлению писем благодаря этому решению кстати удалось высвободить ресурсы для расширения штата программистов продавцов и специалистов по маркетингу то есть работу получило больше людей за исключением уволенных сотрудников разумеетсягдето в офисе ibm в 2025 году крупные компании в частности morgan stanley ups meta wayfair salesforce hp enterprise и workday объявили или анонсировали массовые увольнения часто ссылаясь на оптимизацию процессов и внедрение ии например ups планирует сократить 20 000 сотрудников а chevron  до 9 000 человек37 компаний использующих ии ещё в 2023 году сообщили о сокращении персонала изза внедрения новых технологий а по прогнозу world economic forum к 2027 году могут быть сокращены75 млн операторов crm и рутинного документооборота5 млн офисассистентов и административных помощников45 млн бухгалтеров и специалистов по учётукак видим ии уже не просто инструмент  он становится полноценным участником рынка труда весьма серьёзно изменяя его ландшафт и заставляя многих специалистов переосмысливать свою роль в новой реальности профессии под очевидной угрозойкроме уже перечисленного на очереди специалисты чья работа требует не только знаний и механического труда но и опыта анализа нюансов именно они становятся следующими кандидатами на оптимизациююристы и юридические ассистентыии уже способен анализировать юридические документы находить противоречия и предлагать правки например существует harvey ai который используют в крупных юридических фирмах он умеет обрабатывать тысячи страниц сложных специфических и юридических текстов за минутыэто серьёзная угроза младшим юристам и помощникам чья работа как раз  готовить документы и анализировать кейсыкадр из мульсериала футурамабухгалтеры и аудиторыпрограммы способны автоматически обрабатывать транзакции составлять отчёты считать налоги и выявлять кассовые разрывы с аномалиями это особенно удобно для малого и среднего бизнеса которому выгоднее заплатить подписку за aiсервис чем держать в штате бухгалтераони копируют даже мимику в день начисления зарплатжурналисты и редакторыии уже генерирует новости пишет статьи и даже анализирует данные для сложных расследований платформы использующие ии способны создавать контент быстрее и дешевле чем человек притом только за последний год уровень написания статей стал на две головы выше и тексты написанные нейросетями кажутся все более и более человеческимиеще бы нейросетьрукописца для врачейучителя и преподавателида существует онлайнобучение с иирепетиторами таким уже занимается академия хана khan academy южнокорейская qanda и некоторые другие платформы которые предлагают персонализированные программы обучения адаптированные под каждого ученикадети тянутся к знаниямначинающие программистыкак заявил ceo microsoft до 30 кода в компании уже генериует ии и эта доля будет только расти это означает что задачи ранее выполняемые младшими разработчиками теперь подлежат автоматизации компании всё чаще ищут специалистов способных управлять ииинструментами а не писать код с нуля масштаб трагедии мифы и реальностьесли говорить коротко и начистоту  есть чего бояться но насколько оправданы эти опасенияпервое и самое распространённое заблуждение  ии массово уничтожает рабочие местапрогнозы прогнозами но пока что ии хорошо справляется с узкими задачами сортировка и обработка данных составление резюме подбор ключевых слов создание структуры текста и тому подобными но он далёк от того чтобы полностью заменить человеческое мышление эмоциональный интеллект и способность к принятию комплексных решений на деле ии чаще всего дополняет человекаспециалиста снимая с него рутину и высвобождая время на то что требует настоящего мышления и творческого подходанекоторые утверждают что ии создаёт больше рабочих мест чем уничтожает отчасти это правда всемирный экономический форум в 2020 году оценил что в 2025 году ии может заменить 85 миллионов рабочих мест но при этом создать около 97 миллионов новых ждём до конца года  проверим точность прогнозапроблема в том что новые рабочие места потребуют других навыков и если человек не успеет адаптироваться  его место займёт ктото более подготовленный или ииесть и более тонкие последствия о которых говорят реже например ии действительно повышает производительность  но одновременно может увеличить нагрузку ожидания бизнеса растут если раньше отчёт подготавливали день теперь его требуют за час  потому что у нас же есть ии это может привести к выгоранию стрессу и ощущению что человек теперь просто надзиратель за машиной а не активный участник процессавывод прост ии  не катастрофа и не спасение он  катализатор изменений реакция на них и станет настоящей развилкой а кто выигрываеткроме автоматизации рутинных задач ии также становится мощным инструментом усиливающим определённые профессии делая их более продуктивными и востребованнымив консалтинговой компании ey внедрение ии позволило не только сохранить но и увеличить численность персонала генеральный директор ey джанет транкейл отметила что ии помогает сотрудникам сосредоточиться на более сложных и интересных задачах повышая общую ценность человеческого трудакого ии уже уволил а кто только ждёт своей очереди как ии меняет рынок труда  разбор мифов и фактовв ibm ии заменил сотни позиций в отделах кадров выполняя задачи по анализу данных и составлению писем однако это позволило компании расширить штат в области программирования и продаж где требуются критическое мышление и навыки межличностного общениятем временем появляются и новые профессии напрямую связанные с ии согласно данным гарвардского университета стремительно растёт спрос на специалистов по этике ии  именно они отвечают за то чтобы алгоритмы работали прозрачно не воспроизводили дискриминацию и соответствовали общественным и правовым нормаммногим компаниям теперь необходимы инженеры по машинному обучению mlинженеры сегодня они  одни из самых востребованных технических специалистов они создают обучают и оптимизируют иимодели которые лежат в основе рекомендательных систем чатботов предиктивной аналитики и других инструментовточно так же бизнесу требуются менеджеры по продуктам ии  они формируют видение продукта определяют где именно алгоритмы принесут наибольшую пользу и следят за тем чтобы решения были не только технологичны но и полезны людямниже мы разобрали тактики выживания в эпоху ии и типичные ошибки которых стоит избегать как выжить и не утонуть в эпоху ии тактика и ловушкиии не угрожает рынку труда сам по себе  угрозу несёт привычка игнорировать перемены побеждают не самые опытные а самые адаптивные сегодня знание технологий становится частью базовой грамотности как когдато  умение читать или пользоваться интернетом не освоить ии значит  осознанно остаться в слепой зоне нового рынкая пришёл вывести вас из слепой зоны
кадр из фильма терминатор 2 судный деньпервый шаг к выживанию  пересборка своей профессиональной идентичности задайте себе вопрос какую уникальную ценность я создаю  ту что алгоритмы пока не могут воспроизвести это может быть стратегическое мышление живое общение способность чувствовать контекст и читать между строк ии снимает рутину но не избавляет от ответственности чем больше ваша роль опирается на глубокое понимание тем труднее вас заменитьвторой шаг  освоение инструментов не обязательно быть itспециалистом но жизненно важно уметь пользоваться тем что уже изменяет рынок chatgpt copilot midjourney notion ai и другими инструментами самая большая ошибка  надеяться что пронесёт или можно же обойтись без этого нет уже нельзяостаться без навыков ии  это как выйти на рынок труда без знания языка на котором все вокруг уже говорят в общем это уже hard skillнельзя также полагаться на ии как на некую волшебную палочку это не магия а усилитель сильных сторон  или катализатор слабых если вы не умеете формулировать мысли нейросеть не поймёт что от неё требуют если боитесь принимать решения  алгоритм не возьмёт на себя ответственность одна из главных ошибок думать что ии заменит усилия нет он требует новых усилий просто другого качестваи пожалуй самая опасная ловушка  выгореть на фоне неопределённости да ритм ускорился да нужно учиться почти постоянно но это не гонка на выживание  это смена модели кто начинает использовать ии как союзника а не как врага или угрозу  получает не только преимущество но и ощущение контроля над происходящим а это уже половина успеха вместо эпилога не про ии а про нас человековии  это не метеорит который вотвот упадёт с неба и все замерли в ожидании он уже здесь и дело не в том когда он чтото отберёт или изменит а в том как мы научимся сосуществовать с новой реальностью машины не устраивают революций  это делают люди которые либо отказываются меняться либо оседлали волнусегодняшний рынок  это не деление на сильных и слабых а на включённых и отключённых ии становится новым языком  рабочим деловым человеческим тот кто научился на нём говорить не просто эффективнее он  понятен он  в контексте он  конкурентоспособенсамое важное  не обмануться в ожиданиях ии не заменит человека но он может заменить того человека который откажется им пользоваться а между заменит и усилит  тонкая грань и она сегодня проводится каждым из насии не про технологии он про выбор и этот выбор  каждый день не нужно ждать пока мир поменяется нужно менять его и меняться вместе с нимновости обзоры продуктов и конкурсы от команды timewebcloud  в нашем telegramканале опробовать  читайте также галлюцинации моделей текстовых ии и как с ними бороться нейродайджест ключевые события мира ai за 5  12 мая 2025 ии для вебразработки перешагивая через века rise of nations thrones  patriots самые безумные и неожиданные кроссоверы игровой индустрии сейчас такое уже не сделают
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: contains_keywords
Аргументы: args=('Нейросети («ИИ») больше не инструмент будущего — это активный участник рынка труда. От HR-отделов до бухгалтерии, от школ до юридических фирм — машины не только помогают, а кое-где заменяют. Эта статья — о том, какие профессии исчезают, а какие трансформируются, и что делать, чтобы остаться на плаву в эпоху алгоритмов.Здесь и далее мы будем использовать термин ИИ (искусственный интеллект) в качестве описания, в основном, нейронных сетей.ИИ — очень широкое и объёмное понятие, включающее в себя множество технологий, методов и подходов. Кроме того, необходимо различать узкий искусственный интеллект, искусственный интеллект общего назначения и искусственный суперинтеллект.А ещё не следует путать всё это с машинным обучением, глубоким обучением, генеративным ИИ и так далее.Слова модные, тема хайповая, часто термины используются как синонимы, что создает путаницу.❯ ИИ начал действоватьКогда ChatGPT сгенерировал свой первый текст, а Midjourney — первую картинку, мир ещё смеялся: «Ну, ведь полное месиво! Что это за ерунда?!». Два года спустя смеха стало меньше. А в некоторых офисах уже некому смеяться — работодатели заменили сотрудников.А начиналось всё примерно вот так (и это в лучшем случае)ИИ перестал быть «будущим». Он внедрился в настоящее: редактирует статьи на новостных сайтах, проводит собеседования, пишет код, подбирает маркетинговые стратегии и рисует рекламу быстрее, чем успевает моргнуть человек. Его внедрение — не тренд, а тихая революция. Только эта революция не с баррикадами, а с письмами об увольнении и автоматизированными воркфлоу.Согласно\xa0отчёту\xa0McKinsey (за 2024 год), более 70% крупных компаний уже интегрировали генеративный ИИ в свои ключевые бизнес-процессы — от IT до продаж. IBM официально заявила о замене сотен сотрудников ИИ-решениями в HR-отделах. И даже если ИИ пока не увольняет напрямую, он замораживает рост зарплат в профессиях, где способен составить достойную конкуренцию.ИИ не стучит в дверь — он уже внутри. И самый главный вопрос теперь не «Заменит ли он нас?», а «Кого он заменит первым — и можно ли выжить в его эпоху?». Давайте разбираться.❯ На грани: профессии, вытесняемые ИИЕсли раньше автоматизация угрожала в основном производственным линиям, то сегодня под ударом оказались все офисные жители.В 2023 году IBM\xa0официально заявила\xa0о замене сотен сотрудников в отделах HR на ИИ-агентов, выполняющих задачи по анализу данных и составлению писем. Благодаря этому решению, кстати, удалось высвободить ресурсы для расширения штата программистов, продавцов и специалистов по маркетингу. То есть работу получило больше людей. За исключением уволенных сотрудников, разумеется.Где-то в офисе IBM 🙂В 2025 году крупные компании (в частности Morgan Stanley, UPS, Meta*, Wayfair, Salesforce, HP Enterprise и Workday) объявили или анонсировали массовые увольнения, часто ссылаясь на оптимизацию процессов и внедрение ИИ. Например, UPS\xa0планирует сократить\xa020 000 сотрудников, а Chevron — до 9 000 человек.37% компаний, использующих ИИ, ещё в 2023 году сообщили о сокращении персонала из-за внедрения новых технологий. А по прогнозу World Economic Forum, к 2027 году могут быть сокращены:7,5 млн операторов CRM и рутинного документооборота;5 млн офис-ассистентов и административных помощников;4,5 млн бухгалтеров и специалистов по учёту.Как видим, ИИ уже не просто инструмент — он становится полноценным участником рынка труда, весьма серьёзно изменяя его ландшафт и заставляя многих специалистов переосмысливать свою роль в новой реальности.❯ Профессии под очевидной угрозойКроме уже перечисленного, на очереди специалисты, чья работа требует не только знаний и механического труда, но и опыта, анализа, нюансов. Именно они становятся следующими кандидатами на оптимизацию.Юристы и юридические ассистенты.ИИ уже способен анализировать юридические документы, находить противоречия и предлагать правки. Например существует Harvey AI, который используют в крупных юридических фирмах: он умеет обрабатывать тысячи страниц сложных специфических и юридических текстов за минуты.Это серьёзная угроза младшим юристам и помощникам, чья работа как раз – готовить документы и анализировать кейсы.Кадр из мульсериала «Футурама»Бухгалтеры и аудиторы.Программы способны автоматически обрабатывать транзакции, составлять отчёты, считать налоги и выявлять кассовые разрывы с аномалиями. Это особенно удобно для малого и среднего бизнеса, которому выгоднее заплатить подписку за AI-сервис, чем держать в штате бухгалтера.Они копируют даже мимику в день начисления зарплат!Журналисты и редакторы.ИИ уже генерирует новости, пишет статьи и даже анализирует данные для сложных расследований. Платформы, использующие ИИ, способны создавать контент быстрее и дешевле, чем человек, притом только за последний год уровень написания статей стал на две головы выше, и тексты написанные нейросетями кажутся все более и более человеческими.Еще бы нейросеть-рукописца для врачей…Учителя и преподаватели.Да, существует онлайн-обучение с ИИ-репетиторами: таким уже занимается академия Хана, (Khan Academy), южнокорейская QANDA и некоторые другие платформы, которые предлагают персонализированные программы обучения, адаптированные под каждого ученика.Дети тянутся к знаниямНачинающие программисты.Как\xa0заявил\xa0CEO Microsoft, до 30% кода в компании уже генериует ИИ, и эта доля будет только расти. Это означает, что задачи, ранее выполняемые младшими разработчиками, теперь подлежат автоматизации. Компании всё чаще ищут специалистов, способных управлять ИИ-инструментами, а не писать код с нуля.❯ Масштаб трагедии: мифы и реальностьЕсли говорить коротко и начистоту — есть чего бояться. Но насколько оправданы эти опасения?Первое и самое распространённое заблуждение — ИИ массово уничтожает рабочие места.Прогнозы прогнозами, но пока что ИИ хорошо справляется с узкими задачами: сортировка и обработка данных, составление резюме, подбор ключевых слов, создание структуры текста и тому подобными. Но он далёк от того, чтобы полностью заменить человеческое мышление, эмоциональный интеллект и способность к принятию комплексных решений. На деле ИИ чаще всего дополняет человека-специалиста, снимая с него рутину и высвобождая время на то, что требует настоящего мышления и творческого подхода.Некоторые утверждают, что ИИ создаёт больше рабочих мест, чем уничтожает. Отчасти это правда. Всемирный экономический форум в 2020 году оценил, что в 2025 году ИИ может заменить 85 миллионов рабочих мест, но при этом создать около 97 миллионов новых. Ждём до конца года — проверим точность прогноза.Проблема в том, что новые рабочие места потребуют других навыков. И если человек не успеет адаптироваться — его место займёт кто-то более подготовленный или... ИИ.Есть и более тонкие последствия, о которых говорят реже. Например, ИИ действительно повышает производительность — но одновременно может увеличить нагрузку. Ожидания бизнеса растут: если раньше отчёт подготавливали день, теперь его требуют за час — потому что «у нас же есть ИИ». Это может привести к выгоранию, стрессу и ощущению, что человек теперь просто «надзиратель» за машиной, а не активный участник процесса.Вывод прост:\xa0ИИ — не катастрофа и не спасение. Он — катализатор изменений. Реакция на них и станет настоящей развилкой.❯ А кто выигрывает?Кроме автоматизации рутинных задач, ИИ также становится мощным инструментом, усиливающим определённые профессии, делая их более продуктивными и востребованными.В консалтинговой компании EY внедрение ИИ позволило не только сохранить, но и увеличить численность персонала. Генеральный директор EY, Джанет Транкейл,\xa0отметила, что ИИ помогает сотрудникам сосредоточиться на более сложных и интересных задачах, повышая общую ценность человеческого труда.Кого ИИ уже уволил, а кто только ждёт своей очереди? Как ИИ меняет рынок труда — разбор мифов и фактовВ IBM ИИ заменил сотни позиций в отделах кадров, выполняя задачи по анализу данных и составлению писем. Однако, это позволило компании расширить штат в области программирования и продаж, где требуются критическое мышление и навыки межличностного общения.Тем временем появляются и новые профессии, напрямую связанные с ИИ. Согласно данным Гарвардского университета, стремительно растёт спрос на специалистов по этике ИИ — именно они отвечают за то, чтобы алгоритмы работали прозрачно, не воспроизводили дискриминацию и соответствовали общественным и правовым нормам.Многим компаниям теперь необходимы инженеры по машинному обучению (ML-инженеры), сегодня они — одни из самых востребованных технических специалистов: они создают, обучают и оптимизируют ИИ-модели, которые лежат в основе рекомендательных систем, чат-ботов, предиктивной аналитики и других инструментов.Точно так же бизнесу требуются менеджеры по продуктам ИИ — они формируют видение продукта, определяют, где именно алгоритмы принесут наибольшую пользу, и следят за тем, чтобы решения были не только технологичны, но и полезны людям.Ниже мы разобрали тактики выживания в эпоху ИИ и типичные ошибки, которых стоит избегать.❯ Как выжить и не утонуть в эпоху ИИ: тактика и ловушкиИИ не угрожает рынку труда сам по себе — угрозу несёт привычка игнорировать перемены. Побеждают не самые опытные, а самые адаптивные. Сегодня знание технологий становится частью базовой грамотности, как когда-то — умение читать или пользоваться интернетом. Не освоить ИИ, значит — осознанно остаться в слепой зоне нового рынка.Я пришёл вывести вас из слепой зоны!\nКадр из фильма «Терминатор 2: Судный день»Первый шаг к выживанию — пересборка своей профессиональной идентичности. Задайте себе вопрос: какую уникальную ценность я создаю — ту, что алгоритмы пока не могут воспроизвести? Это может быть стратегическое мышление, живое общение, способность чувствовать контекст и «читать между строк». ИИ снимает рутину, но не избавляет от ответственности. Чем больше ваша роль опирается на глубокое понимание, тем труднее вас заменить.Второй шаг — освоение инструментов. Не обязательно быть IT-специалистом, но жизненно важно уметь пользоваться тем, что уже изменяет рынок: ChatGPT, Copilot, Midjourney, Notion AI и другими инструментами. Самая большая ошибка — надеяться, что «пронесёт» или «можно же обойтись без этого». Нет, уже нельзя!Остаться без навыков ИИ — это как выйти на рынок труда без знания языка, на котором все вокруг уже говорят. В общем, это уже hard skill.Нельзя также полагаться на ИИ как на некую волшебную палочку. Это не магия, а усилитель сильных сторон — или катализатор слабых. Если вы не умеете формулировать мысли, нейросеть не поймёт, что от неё требуют. Если боитесь принимать решения — алгоритм не возьмёт на себя ответственность. Одна из главных ошибок думать, что ИИ заменит усилия. Нет: он требует новых усилий, просто другого качества.И, пожалуй, самая опасная ловушка — выгореть на фоне неопределённости. Да, ритм ускорился. Да, нужно учиться почти постоянно. Но это не гонка на выживание — это смена модели. Кто начинает использовать ИИ как союзника, а не как врага или угрозу, — получает не только преимущество, но и ощущение контроля над происходящим. А это уже половина успеха.❯ Вместо эпилога: не про ИИ, а про нас, человековИИ — это не метеорит, который вот-вот упадёт с неба и все замерли в ожидании. Он уже здесь. И дело не в том, когда он что-то «отберёт» или «изменит», а в том, как мы научимся сосуществовать с новой реальностью. Машины не устраивают революций — это делают люди, которые либо отказываются меняться, либо оседлали волну.Сегодняшний рынок — это не деление на сильных и слабых, а на «включённых» и «отключённых». ИИ становится новым языком — рабочим, деловым, человеческим. Тот, кто научился на нём говорить, не просто эффективнее. Он — понятен. Он — в контексте. Он — конкурентоспособен.Самое важное — не обмануться в ожиданиях. ИИ не заменит человека. Но он может заменить того человека, который откажется им пользоваться. А между «заменит» и «усилит» — тонкая грань, и она сегодня проводится каждым из нас.ИИ не про технологии. Он про выбор. И этот выбор — каждый день. Не нужно ждать, пока мир поменяется, нужно менять его и меняться вместе с ним.Новости, обзоры продуктов и конкурсы от команды\xa0Timeweb.Cloud\xa0— в нашем Telegram-канале\xa0↩Опробовать ↩📚 Читайте также:➤\xa0Галлюцинации моделей текстовых ИИ, и как с ними бороться➤\xa0Нейро-дайджест: ключевые события мира AI за 5 – 12 мая 2025➤\xa0ИИ для веб-разработки➤\xa0Перешагивая через века. Rise of nations: Thrones & Patriots➤\xa0Самые безумные и неожиданные кроссоверы игровой индустрии. Сейчас такое уже не сделают', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('Оборачиваем обработчики событий коробки Битрикс24 в стандартный модуль',), kwargs={}
Результат: оборачиваем обработчики событий коробки битрикс24 в стандартный модуль
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: contains_keywords
Аргументы: args=('Оборачиваем обработчики событий коробки Битрикс24 в стандартный модуль', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:15 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('Привет, Хабр. Недавно я написал целый цикл статей по\xa0работе со смарт‑процессами, помогающий погрузить «непосвященного» человека в\xa0азы API коробочной версии, реализующего возможности управления смарт‑процессами и связанными с\xa0ними элементами. В\xa0рамках последней статьи, разъясняющей применение обработчиков события, от\xa0слушателей и интересующихся получил в\xa0личку много вопросов, связанных в\xa0целом с\xa0применением обработчиков событий в\xa0Битрикс24. В\xa0сегодняшней статье рассмотрим один из\xa0популярных практических кейсов\xa0— реализовать возможность управлять какими‑либо настройками обработчиков события из\xa0стандартной панели администратора Битрикс24. Я понимаю, что\xa0руководств по\xa0сборке модулей Битрикс и на\xa0Хабре и в\xa0официальной документации достаточно много. Но\xa0на\xa0мой взгляд основная проблема таких руководств\xa0— это их объем (автор руководства пытается расписать все возможные файлы в\xa0составе модуля), что\xa0для\xa0начинающего неподготовленного пользователя (вспоминаю тут себя в\xa0начале карьеры Битрикс разработчика) может\xa0быть трудным к\xa0пониманию. Я ни в\xa0коем случае не\xa0утверждаю, что\xa0авторы данных материалов написали их плохо, на\xa0определенном этапе развития специалистам нужны и полные материалы целиком, поэтому своих читателей такие материалы конечно\xa0же найдут. Мои\xa0же статьи в\xa0данном цикле рассчитаны на\xa0аудиторию, только начинающую делать первые шаги в\xa0Битрикс разработке, потому упрощение пойдет им определенно на\xa0пользу.Если что, основная статья начинается отсюда :)В\xa0сегодняшней статье‑туториале мы соберем модуль для\xa0Битрикс24, реализующий добавление и удаление обработчиков события, а\xa0также страницу настроек, позволяющую включать и отключать эти обработчики для\xa0определенных воронок сделки. Многоязычность пока для\xa0простоты понимания реализовывать не\xa0будем. Может, разберем данный вопрос в\xa0следующих статьях. Пишите в\xa0комментариях, если хотите что‑то разобрать в\xa0следующих статьях цикла.Если обратиться к\xa0принятым стандартам разработки BitrixFramework, системные модули и модули, загружаемые из 1С‑Битрикс: Маркетплейс, располагаются в\xa0папке /bitrix/modules/. У\xa0нас\xa0же модуль полностью кастомный, его структуру мы будем создавать в\xa0папке /local/modules/.Начинаем создание модуляКак\xa0корабль назовешь\xa0— так он и поплывет пойдет, говорят моряки. Перед тем как\xa0собирать вместе файлы модуля, нам нужно определиться с\xa0его техническим названием, которое будет его однозначно идентифицировать в\xa0системе. Раз основная задача\xa0— научиться оперировать обработчиками события через модуль\xa0— назовем его learnevents.Соответственно создаем папку для\xa0нашего модуля по\xa0пути /local/modules/learnevents.Разбирать полный состав файлов модуля мы не\xa0будем, писал выше почему. Далее будем создавать минимальный набор файлов, который нам понадобится для\xa0решения нашей задачи.Папка installПервой создаем папку /local/modules/learnevents/install. В\xa0ней будут находиться файлы, отвечающие за\xa0установку и удаление нашего модуля.Первым в\xa0папке создаем файл /local/modules/learnevents/install/version.php следующего содержания:<?php\n$arModuleVersion = [\n\t\'VERSION\' => \'1.0.0\',\n\t\'VERSION_DATE\' => \'2025-05-13\',\n];Нетрудно догадаться, что\xa0в\xa0данном файле мы указываем текущую версию модуля и дату его выпуска. Можно указать в\xa0принципе любые подходящие по\xa0формату данные.Далее создаем основной файл установщика модуля /local/modules/learnevents/install/index.php. В\xa0коде будут поясняющие комментарии:<?php\n\nuse Bitrix\\Main\\ModuleManager;\n\n//Основной класс установщика модуля, должен наследоваться от системного класса CModule\nclass learnevents extends CModule\n{\n    //Системный идентификатор модуля, должен совпадать с названием класса\n    public $MODULE_ID = \'learnevents\';\n    //Версия модуля и дата. Оставляем пустыми так как подгрузим нужные в конструкторе\n    public $MODULE_VERSION;\n    public $MODULE_VERSION_DATE;\n    //Название модуля, выводимое в админ панели\n    public $MODULE_NAME = \'Управляемые обработчики\';\n    //Описание модуля, выводимое в админ панели\n    public $MODULE_DESCRIPTION = \'Тестовый модуль, показывающий возможности управления обработчиками события\';\n    //Адрес сайта разработчика модуля\n    public $PARTNER_URI = \'https://site.ru\';\n    //Не использовать права доступа к модулю на основе групп пользователей\n    public $MODULE_GROUP_RIGHTS = \'N\';\n\n    //Основной конструктор класса, в котором мы читаем файл version.php и берем оттуда версию модуля и дату релиза\n    public function __construct()\n    {\n        $arModuleVersion = [];\n\n        include __DIR__ . \'/version.php\';\n\n        if (is_array($arModuleVersion) && array_key_exists(\'VERSION\', $arModuleVersion)) {\n            $this->MODULE_VERSION = $arModuleVersion[\'VERSION\'];\n            $this->MODULE_VERSION_DATE = $arModuleVersion[\'VERSION_DATE\'];\n        }\n    }\n\n    //Метод, устанавливающий обработчики события при установке модуля\n    public function InstallEvents()\n    {\n        $eventManager = \\Bitrix\\Main\\EventManager::getInstance();\n        $eventManager->registerEventHandler("crm",\n            "OnBeforeCrmDealAdd",//Событие, на которое вешаем обработчик\n            $this->MODULE_ID,//Идентификатор модуля, берем текущий\n            "Learn\\\\Event\\\\Main",//PHP Класс с неймспейсом, в котором реализован метод обработчика\n            "RunEvent"//Название метода-обработчика\n        );\n        //Далее код других обработчиков\n        return true;\n    }\n\n    //Метод, удаляющий обработчики события при удалении модуля\n    public function UnInstallEvents()\n    {\n        $eventManager = \\Bitrix\\Main\\EventManager::getInstance();\n        $eventManager->unRegisterEventHandler("crm",\n            "OnBeforeCrmDealAdd",//Событие, на которое вешаем обработчик\n            $this->MODULE_ID,//Идентификатор модуля, берем текущий\n            "Learn\\\\Event\\\\Main",//PHP Класс с неймспейсом, в котором реализован метод обработчика\n            "RunEvent"//Название метода-обработчика\n        );\n        //Далее код других обработчиков\n        return true;\n    }\n\n    //Метод, запускающийся при установке модуля\n    public function DoInstall()\n    {\n        $this->InstallEvents();//Запускаем установку обработчиков\n        ModuleManager::registerModule($this->MODULE_ID);//Регистрируем модуль в системе как установленный\n    }\n\n\n    //Метод, запускающийся при удалении модуля\n    public function DoUninstall()\n    {\n        $this->UnInstallEvents();//Запускаем удаление обработчиков\n        ModuleManager::unRegisterModule($this->MODULE_ID);//Снимаем регистрацию модуля в системе\n    }\n\n\n}Далее добавляем файл /local/modules/learnevent/install/unstep1.php. Он будет отвечать за\xa0страничку, которая появляется перед удалением модуля в\xa0панели администратора:<?\n//Если пользователь не авторизован, прерываем метод\nif(!check_bitrix_sessid()) return;\necho CAdminMessage::ShowNote(\'Управляемые обработчики\');\n?>\n<form action="<?=$APPLICATION->GetCurPage(); ?>">\n\t<?=bitrix_sessid_post(); ?>\n\t<input type="hidden" name="step" value="2">\n\t<input type="hidden" name="id" value="learnevent">\n\t<input type="hidden" name="uninstall" value="Y">\n\t<input type="submit" name="nextstep" value="Далее">\n\t<input type="submit" name="cancel" value="Отменить">\n</form>Часто на\xa0данную страничку добавляют сообщения для\xa0тех, кто собирается удалить модуль, например «Пожалуйста, не\xa0удаляйте! Мы еще можем\xa0быть полезны».:)Папка libВ\xa0данной папке традиционно размещаются классы модуля, кототорые будут автоматически подключены при\xa0его установке. В\xa0нашем случае создаем файл /local/modules/learnevent/lib/main.php:namespace Learn\\Event;\n\nuse Bitrix\\Main\\Config\\Option;\n\nclass Main\n{\n     /**\n     * @return array|false Массив направлений сделки\n     * @description Возвращает массим текущих направлений сделок, поднадобится в админке\n     */\n    public static function getDealFunnels()\n    {\n        //Проверяем активен ли модуль CRM. Без него никакие Сделки доступны не будут\n        if (\\Bitrix\\Main\\Loader::includeModule(\'crm\')) {\n            //Получаем ООП Фабрику работы со сделками\n            $factory = \\Bitrix\\Crm\\Service\\Container::getInstance()->getFactory(\n                \\CCrmOwnerType ::Deal\n            );\n            //Получаем массив всех объектов направлений и делаем перебор\n            $categories = $factory->getCategories();\n            $arCategories = [];\n            foreach ($categories as $category) {\n                //Получаем данные каждого направления и записываем в массив\n                $arCategories[] = $category->getData();\n            }\n            return $arCategories;\n        } else {\n            return false;\n        }\n    }\n\n     /**\n     * @return array|false Результат обработчика\n     * @description Обработчик, который мы подключаем через модуля\n     */\n    public static function RunEvent(&$arFields)\n    {\n        //Проверяем, установлен ли флажок "Активно" в админке\n        if (Option::get("learnevent", "ACTIVE") == "Y") {\n            global $USER;\n            //Получаем список пользователей\n            $userExeptions = unserialize(Option::get("learnevent", "USER_EXEPTIONS"));\n            $pipeline = Option::get("learnevent", "PIPELINE");\n            if ((is_array($userExeptions) && in_array($USER->GetID(), $userExeptions)) || $userExeptions == $USER->GetID()) {                \n                    if (isset($arFields[\'CATEGORY_ID\']) && !empty($arFields[\'CATEGORY_ID\']) && ($arFields[\'CATEGORY_ID\'] == $pipeline)) {\n                        //Какие-то действия, если наше условие сработало. Например прерываем создание Сделки\n                        $arFields[\'RESULT_MESSAGE\'] = "Извините, данному пользователю запрещено создавать Сделку в данной воронке!";\n                        return false;\n                    }             \n            }\n\n        }\n    }\n}В\xa0данном файле можно разместить методы для\xa0других обработчиков. Также никто не\xa0запрещает повесить несколько разных методов на\xa0одно событие.Корневая папка модуляТеперь перейдем к\xa0одному из\xa0важнейших файлов, который реализует окно настроек модуля в\xa0панели администрирования Битрикс24. Этот файл по\xa0стандарту лежит в\xa0папке модуля и носит название options.php. В\xa0нашем случае создаем его по\xa0пути /local/modules/learnevent/options.php и добавляем туда код:<?php\n//Подключаем нужные нам неймспейсы и скрипты\nuse \\Bitrix\\Main\\Loader,\n    \\Bitrix\\Main\\Config\\Option;\n\nrequire_once $_SERVER[\'DOCUMENT_ROOT\'] . \'/bitrix/modules/main/include/prolog_admin_before.php\';\n\nrequire_once $_SERVER[\'DOCUMENT_ROOT\'] . \'/bitrix/modules/main/include/prolog_admin_after.php\';\n\nglobal $APPLICATION;\n\n$moduleName = \'learnevent\';\nif (!Loader::IncludeModule($moduleName)) {\n    return;\n}\n\n//Проверяем права доступа, если их нет - перекидываем на форму авторизации\n$POST_RIGHT = $APPLICATION->GetGroupRight($moduleName);\nif ($POST_RIGHT == "D")\n    $APPLICATION->AuthForm(GetMessage("ACCESS_DENIED"));\n\n//Получаем данные POST Запроса если настройки изменены, проводим фильтрацию данных для безопасности\n$request = Bitrix\\Main\\Application::getInstance()->getContext()->getRequest();\n$request->addFilter(new \\Bitrix\\Main\\Web\\PostDecodeFilter);\n\n//Сохраняем настройки модуля в системные опции (таблица b_option в БД)\nif ($POST_RIGHT == "W" && check_bitrix_sessid() && $request->isPost()) {\n    COption::SetOptionString($moduleName, \'ACTIVE\', $request->get(\'ACTIVE\'));\n    COption::SetOptionString($moduleName, \'PIPELINE\', $request->get(\'PIPELINE\'));\n    \n    //Так как у нас может быть множественное значение а база можно хранить только единицное - делаем сериализацию массива в строку\n    COption::SetOptionString($moduleName, \'USER_EXEPTIONS\', serialize($request->get(\'USER_EXEPTIONS\')));\n}\n\n//Инициализируем табы админки, у нас таб будет один\n$tabs = [\n    [\n        \'DIV\' => \'main\',\n        \'TAB\' => \'Настройки\',\n        \'ICON\' => \'\',\n    ]\n];\n$tabControl = new \\CAdminTabControl(\'tabControl\', $tabs);\n//Далее добавляем форму с полями настроек, которые будут выводиться в админке\n?>\n\n    <form method="POST"\n          action="<? echo $APPLICATION->GetCurPage() ?>?mid=<?= urlencode($mid) ?>&lang=<? echo LANGUAGE_ID ?>"\n          ENCTYPE="multipart/form-data" name="post_form">\n        <?= bitrix_sessid_post() ?>\n        <?php\n        $tabControl->Begin();\n        $tabControl->BeginNextTab();\n        ?>\n        <?//Поле "Обработчик активен"?>\n        <tr>\n            <td>Обработчик активен</td>\n            <td><input type="checkbox" name="ACTIVE"\n                       value="Y" <?php if (Option::get($moduleName, \'ACTIVE\') == "Y") echo \'checked\'; ?>/></td>\n        </tr>\n        <?//Поле "Воронка Сделки". Далее получаем массив воронок и текущую настройку?>\n        <tr>\n            <?php $allCategories = \\Learn\\Event\\Main::getDealFunnels(); ?>\n            <?php $currentCategory = Option::get($moduleName, \'PIPELINE\'); ?>\n            <td>Воронка Сделки</td>\n            <td>\n                <select name="PIPELINE">\n                    <?php foreach ($allCategories as $allCategory) { ?>\n                        <option value="<?= $allCategory[\'ID\'] ?>"<?php if ($allCategory[\'ID\'] == $currentCategory) echo \' selected\'; ?>><?= $allCategory[\'NAME\'] ?></option>\n                    <?php } ?>\n                </select>\n            </td>\n        </tr>\n        <?//Поле "Для пользователей". Множественный выбор пользователей для которых будет срабатывать обработчик.?>\n        <tr>\n            <?php $userCurId = unserialize(Option::get($moduleName, \'USER_EXEPTIONS\')); ?>\n            <?php $order = array(\'sort\' => \'asc\');\n            $tmp = \'sort\'; // параметр проигнорируется методом, но обязан быть\n            $rsUsers = \\CUser::GetList($order, $tmp);\n            $allUsers = [];\n            while ($arUser = $rsUsers->Fetch()) {\n                $allUsers[$arUser["ID"]] = "[" . $arUser["ID"] . "] " . $arUser["NAME"] . " " . $arUser["LAST_NAME"];\n            } ?>\n            <td>Для пользователей</td>\n            <td>\n                <select name="USER_EXEPTIONS[]" multiple>\n                    <?php foreach ($allUsers as $userID => $userName) { ?>\n                        <option value="<?= $userID ?>"<?php if ((is_array($userCurId) && in_array($userID, $userCurId)) || $userCurId == $userID) echo \' selected\'; ?>><?= $userName ?></option>\n                    <?php } ?>\n                </select>\n            </td>\n        </tr>\n        <? $tabControl->End(); ?>\n        <input type="submit" value="Сохранить">\n    </form>\n<?php\nrequire_once $_SERVER[\'DOCUMENT_ROOT\'] . \'/bitrix/modules/main/include/epilog_admin.php\';\n?>Данный файл реализует стандартную страницу настроек нашего модуля в\xa0разделе панели администратора Битрикс (Настройки\xa0— Настройки продукта\xa0— Настройки модулей\xa0— Управляемые обработчики). Вместо заключенияВыше мы разобрали минимально необходимый набор файлов, реализующих модуль для\xa0Битрикс24, устанавливающий обработчики события, и хранящий настройки для\xa0них. Модуль содержит минимальный набор системных методов для\xa0того, чтобы Битрикс воспринимал его именно как\xa0модуль, а\xa0не\xa0как\xa0набор скриптов непонятного назначения. Всем спасибо за\xa0внимание и жду нашей встречи в\xa0следующих статьях!Если вы работаете с коробочной версией Битрикс24 и хотите глубже разобраться в механике событий — их типах, регистрации и возможностях для управления сущностями, обратите внимание на предстоящий открытый урок «События в Битрикс24: Путеводитель по изменениям». Разберёмся в архитектуре событийной модели и обсудим, как эффективно внедрять собственные сценарии обработки изменений. Старт 21 мая в 20:00 — участие бесплатное, нужно только зарегистрироваться.А в календаре мероприятий можно записаться на открытые уроки по другим ИТ-направлениям.',), kwargs={}
Результат: привет хабр недавно я написал целый цикл статей по работе со смартпроцессами помогающий погрузить непосвященного человека в азы api коробочной версии реализующего возможности управления смартпроцессами и связанными с ними элементами в рамках последней статьи разъясняющей применение обработчиков события от слушателей и интересующихся получил в личку много вопросов связанных в целом с применением обработчиков событий в битрикс24 в сегодняшней статье рассмотрим один из популярных практических кейсов  реализовать возможность управлять какимилибо настройками обработчиков события из стандартной панели администратора битрикс24 я понимаю что руководств по сборке модулей битрикс и на хабре и в официальной документации достаточно много но на мой взгляд основная проблема таких руководств  это их объем автор руководства пытается расписать все возможные файлы в составе модуля что для начинающего неподготовленного пользователя вспоминаю тут себя в начале карьеры битрикс разработчика может быть трудным к пониманию я ни в коем случае не утверждаю что авторы данных материалов написали их плохо на определенном этапе развития специалистам нужны и полные материалы целиком поэтому своих читателей такие материалы конечно же найдут мои же статьи в данном цикле рассчитаны на аудиторию только начинающую делать первые шаги в битрикс разработке потому упрощение пойдет им определенно на пользуесли что основная статья начинается отсюда в сегодняшней статьетуториале мы соберем модуль для битрикс24 реализующий добавление и удаление обработчиков события а также страницу настроек позволяющую включать и отключать эти обработчики для определенных воронок сделки многоязычность пока для простоты понимания реализовывать не будем может разберем данный вопрос в следующих статьях пишите в комментариях если хотите чтото разобрать в следующих статьях циклаесли обратиться к принятым стандартам разработки bitrixframework системные модули и модули загружаемые из 1сбитрикс маркетплейс располагаются в папке bitrixmodules у нас же модуль полностью кастомный его структуру мы будем создавать в папке localmodulesначинаем создание модулякак корабль назовешь  так он и поплывет пойдет говорят моряки перед тем как собирать вместе файлы модуля нам нужно определиться с его техническим названием которое будет его однозначно идентифицировать в системе раз основная задача  научиться оперировать обработчиками события через модуль  назовем его learneventsсоответственно создаем папку для нашего модуля по пути localmoduleslearneventsразбирать полный состав файлов модуля мы не будем писал выше почему далее будем создавать минимальный набор файлов который нам понадобится для решения нашей задачипапка installпервой создаем папку localmoduleslearneventsinstall в ней будут находиться файлы отвечающие за установку и удаление нашего модуляпервым в папке создаем файл localmoduleslearneventsinstallversionphp следующего содержанияphp
armoduleversion  
	version  100
	version_date  20250513
нетрудно догадаться что в данном файле мы указываем текущую версию модуля и дату его выпуска можно указать в принципе любые подходящие по формату данныедалее создаем основной файл установщика модуля localmoduleslearneventsinstallindexphp в коде будут поясняющие комментарииphp

use bitrixmainmodulemanager

основной класс установщика модуля должен наследоваться от системного класса cmodule
class learnevents extends cmodule

    системный идентификатор модуля должен совпадать с названием класса
    public module_id  learnevents
    версия модуля и дата оставляем пустыми так как подгрузим нужные в конструкторе
    public module_version
    public module_version_date
    название модуля выводимое в админ панели
    public module_name  управляемые обработчики
    описание модуля выводимое в админ панели
    public module_description  тестовый модуль показывающий возможности управления обработчиками события
    адрес сайта разработчика модуля
    public partner_uri  httpssiteru
    не использовать права доступа к модулю на основе групп пользователей
    public module_group_rights  n

    основной конструктор класса в котором мы читаем файл versionphp и берем оттуда версию модуля и дату релиза
    public function __construct
    
        armoduleversion  

        include __dir__  versionphp

        if is_arrayarmoduleversion  array_key_existsversion armoduleversion 
            thismodule_version  armoduleversionversion
            thismodule_version_date  armoduleversionversion_date
        
    

    метод устанавливающий обработчики события при установке модуля
    public function installevents
    
        eventmanager  bitrixmaineventmanagergetinstance
        eventmanagerregistereventhandlercrm
            onbeforecrmdealaddсобытие на которое вешаем обработчик
            thismodule_idидентификатор модуля берем текущий
            learneventmainphp класс с неймспейсом в котором реализован метод обработчика
            runeventназвание методаобработчика
        
        далее код других обработчиков
        return true
    

    метод удаляющий обработчики события при удалении модуля
    public function uninstallevents
    
        eventmanager  bitrixmaineventmanagergetinstance
        eventmanagerunregistereventhandlercrm
            onbeforecrmdealaddсобытие на которое вешаем обработчик
            thismodule_idидентификатор модуля берем текущий
            learneventmainphp класс с неймспейсом в котором реализован метод обработчика
            runeventназвание методаобработчика
        
        далее код других обработчиков
        return true
    

    метод запускающийся при установке модуля
    public function doinstall
    
        thisinstalleventsзапускаем установку обработчиков
        modulemanagerregistermodulethismodule_idрегистрируем модуль в системе как установленный
    


    метод запускающийся при удалении модуля
    public function douninstall
    
        thisuninstalleventsзапускаем удаление обработчиков
        modulemanagerunregistermodulethismodule_idснимаем регистрацию модуля в системе
    


далее добавляем файл localmoduleslearneventinstallunstep1php он будет отвечать за страничку которая появляется перед удалением модуля в панели администратора
если пользователь не авторизован прерываем метод
ifcheck_bitrix_sessid return
echo cadminmessageshownoteуправляемые обработчики

form actionapplicationgetcurpage 
	bitrix_sessid_post 
	input typehidden namestep value2
	input typehidden nameid valuelearnevent
	input typehidden nameuninstall valuey
	input typesubmit namenextstep valueдалее
	input typesubmit namecancel valueотменить
formчасто на данную страничку добавляют сообщения для тех кто собирается удалить модуль например пожалуйста не удаляйте мы еще можем быть полезныпапка libв данной папке традиционно размещаются классы модуля кототорые будут автоматически подключены при его установке в нашем случае создаем файл localmoduleslearneventlibmainphpnamespace learnevent

use bitrixmainconfigoption

class main

     
      return arrayfalse массив направлений сделки
      description возвращает массим текущих направлений сделок поднадобится в админке
     
    public static function getdealfunnels
    
        проверяем активен ли модуль crm без него никакие сделки доступны не будут
        if bitrixmainloaderincludemodulecrm 
            получаем ооп фабрику работы со сделками
            factory  bitrixcrmservicecontainergetinstancegetfactory
                ccrmownertype deal
            
            получаем массив всех объектов направлений и делаем перебор
            categories  factorygetcategories
            arcategories  
            foreach categories as category 
                получаем данные каждого направления и записываем в массив
                arcategories  categorygetdata
            
            return arcategories
         else 
            return false
        
    

     
      return arrayfalse результат обработчика
      description обработчик который мы подключаем через модуля
     
    public static function runeventarfields
    
        проверяем установлен ли флажок активно в админке
        if optiongetlearnevent active  y 
            global user
            получаем список пользователей
            userexeptions  unserializeoptiongetlearnevent user_exeptions
            pipeline  optiongetlearnevent pipeline
            if is_arrayuserexeptions  in_arrayusergetid userexeptions  userexeptions  usergetid                 
                    if issetarfieldscategory_id  emptyarfieldscategory_id  arfieldscategory_id  pipeline 
                        какието действия если наше условие сработало например прерываем создание сделки
                        arfieldsresult_message  извините данному пользователю запрещено создавать сделку в данной воронке
                        return false
                                 
            

        
    
в данном файле можно разместить методы для других обработчиков также никто не запрещает повесить несколько разных методов на одно событиекорневая папка модулятеперь перейдем к одному из важнейших файлов который реализует окно настроек модуля в панели администрирования битрикс24 этот файл по стандарту лежит в папке модуля и носит название optionsphp в нашем случае создаем его по пути localmoduleslearneventoptionsphp и добавляем туда кодphp
подключаем нужные нам неймспейсы и скрипты
use bitrixmainloader
    bitrixmainconfigoption

require_once _serverdocument_root  bitrixmodulesmainincludeprolog_admin_beforephp

require_once _serverdocument_root  bitrixmodulesmainincludeprolog_admin_afterphp

global application

modulename  learnevent
if loaderincludemodulemodulename 
    return


проверяем права доступа если их нет  перекидываем на форму авторизации
post_right  applicationgetgrouprightmodulename
if post_right  d
    applicationauthformgetmessageaccess_denied

получаем данные post запроса если настройки изменены проводим фильтрацию данных для безопасности
request  bitrixmainapplicationgetinstancegetcontextgetrequest
requestaddfilternew bitrixmainwebpostdecodefilter

сохраняем настройки модуля в системные опции таблица b_option в бд
if post_right  w  check_bitrix_sessid  requestispost 
    coptionsetoptionstringmodulename active requestgetactive
    coptionsetoptionstringmodulename pipeline requestgetpipeline
    
    так как у нас может быть множественное значение а база можно хранить только единицное  делаем сериализацию массива в строку
    coptionsetoptionstringmodulename user_exeptions serializerequestgetuser_exeptions


инициализируем табы админки у нас таб будет один
tabs  
    
        div  main
        tab  настройки
        icon  
    

tabcontrol  new cadmintabcontroltabcontrol tabs
далее добавляем форму с полями настроек которые будут выводиться в админке


    form methodpost
          action echo applicationgetcurpage mid urlencodemid lang echo language_id 
          enctypemultipartformdata namepost_form
         bitrix_sessid_post 
        php
        tabcontrolbegin
        tabcontrolbeginnexttab
        
        поле обработчик активен
        tr
            tdобработчик активенtd
            tdinput typecheckbox nameactive
                       valuey php if optiongetmodulename active  y echo checked td
        tr
        поле воронка сделки далее получаем массив воронок и текущую настройку
        tr
            php allcategories  learneventmaingetdealfunnels 
            php currentcategory  optiongetmodulename pipeline 
            tdворонка сделкиtd
            td
                select namepipeline
                    php foreach allcategories as allcategory  
                        option value allcategoryid php if allcategoryid  currentcategory echo  selected  allcategoryname option
                    php  
                select
            td
        tr
        поле для пользователей множественный выбор пользователей для которых будет срабатывать обработчик
        tr
            php usercurid  unserializeoptiongetmodulename user_exeptions 
            php order  arraysort  asc
            tmp  sort  параметр проигнорируется методом но обязан быть
            rsusers  cusergetlistorder tmp
            allusers  
            while aruser  rsusersfetch 
                allusersaruserid    aruserid     arusername     aruserlast_name
             
            tdдля пользователейtd
            td
                select nameuser_exeptions multiple
                    php foreach allusers as userid  username  
                        option value userid php if is_arrayusercurid  in_arrayuserid usercurid  usercurid  userid echo  selected  username option
                    php  
                select
            td
        tr
         tabcontrolend 
        input typesubmit valueсохранить
    form
php
require_once _serverdocument_root  bitrixmodulesmainincludeepilog_adminphp
данный файл реализует стандартную страницу настроек нашего модуля в разделе панели администратора битрикс настройки  настройки продукта  настройки модулей  управляемые обработчики вместо заключениявыше мы разобрали минимально необходимый набор файлов реализующих модуль для битрикс24 устанавливающий обработчики события и хранящий настройки для них модуль содержит минимальный набор системных методов для того чтобы битрикс воспринимал его именно как модуль а не как набор скриптов непонятного назначения всем спасибо за внимание и жду нашей встречи в следующих статьяхесли вы работаете с коробочной версией битрикс24 и хотите глубже разобраться в механике событий  их типах регистрации и возможностях для управления сущностями обратите внимание на предстоящий открытый урок события в битрикс24 путеводитель по изменениям разберёмся в архитектуре событийной модели и обсудим как эффективно внедрять собственные сценарии обработки изменений старт 21 мая в 2000  участие бесплатное нужно только зарегистрироватьсяа в календаре мероприятий можно записаться на открытые уроки по другим итнаправлениям
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: contains_keywords
Аргументы: args=('Привет, Хабр. Недавно я написал целый цикл статей по\xa0работе со смарт‑процессами, помогающий погрузить «непосвященного» человека в\xa0азы API коробочной версии, реализующего возможности управления смарт‑процессами и связанными с\xa0ними элементами. В\xa0рамках последней статьи, разъясняющей применение обработчиков события, от\xa0слушателей и интересующихся получил в\xa0личку много вопросов, связанных в\xa0целом с\xa0применением обработчиков событий в\xa0Битрикс24. В\xa0сегодняшней статье рассмотрим один из\xa0популярных практических кейсов\xa0— реализовать возможность управлять какими‑либо настройками обработчиков события из\xa0стандартной панели администратора Битрикс24. Я понимаю, что\xa0руководств по\xa0сборке модулей Битрикс и на\xa0Хабре и в\xa0официальной документации достаточно много. Но\xa0на\xa0мой взгляд основная проблема таких руководств\xa0— это их объем (автор руководства пытается расписать все возможные файлы в\xa0составе модуля), что\xa0для\xa0начинающего неподготовленного пользователя (вспоминаю тут себя в\xa0начале карьеры Битрикс разработчика) может\xa0быть трудным к\xa0пониманию. Я ни в\xa0коем случае не\xa0утверждаю, что\xa0авторы данных материалов написали их плохо, на\xa0определенном этапе развития специалистам нужны и полные материалы целиком, поэтому своих читателей такие материалы конечно\xa0же найдут. Мои\xa0же статьи в\xa0данном цикле рассчитаны на\xa0аудиторию, только начинающую делать первые шаги в\xa0Битрикс разработке, потому упрощение пойдет им определенно на\xa0пользу.Если что, основная статья начинается отсюда :)В\xa0сегодняшней статье‑туториале мы соберем модуль для\xa0Битрикс24, реализующий добавление и удаление обработчиков события, а\xa0также страницу настроек, позволяющую включать и отключать эти обработчики для\xa0определенных воронок сделки. Многоязычность пока для\xa0простоты понимания реализовывать не\xa0будем. Может, разберем данный вопрос в\xa0следующих статьях. Пишите в\xa0комментариях, если хотите что‑то разобрать в\xa0следующих статьях цикла.Если обратиться к\xa0принятым стандартам разработки BitrixFramework, системные модули и модули, загружаемые из 1С‑Битрикс: Маркетплейс, располагаются в\xa0папке /bitrix/modules/. У\xa0нас\xa0же модуль полностью кастомный, его структуру мы будем создавать в\xa0папке /local/modules/.Начинаем создание модуляКак\xa0корабль назовешь\xa0— так он и поплывет пойдет, говорят моряки. Перед тем как\xa0собирать вместе файлы модуля, нам нужно определиться с\xa0его техническим названием, которое будет его однозначно идентифицировать в\xa0системе. Раз основная задача\xa0— научиться оперировать обработчиками события через модуль\xa0— назовем его learnevents.Соответственно создаем папку для\xa0нашего модуля по\xa0пути /local/modules/learnevents.Разбирать полный состав файлов модуля мы не\xa0будем, писал выше почему. Далее будем создавать минимальный набор файлов, который нам понадобится для\xa0решения нашей задачи.Папка installПервой создаем папку /local/modules/learnevents/install. В\xa0ней будут находиться файлы, отвечающие за\xa0установку и удаление нашего модуля.Первым в\xa0папке создаем файл /local/modules/learnevents/install/version.php следующего содержания:<?php\n$arModuleVersion = [\n\t\'VERSION\' => \'1.0.0\',\n\t\'VERSION_DATE\' => \'2025-05-13\',\n];Нетрудно догадаться, что\xa0в\xa0данном файле мы указываем текущую версию модуля и дату его выпуска. Можно указать в\xa0принципе любые подходящие по\xa0формату данные.Далее создаем основной файл установщика модуля /local/modules/learnevents/install/index.php. В\xa0коде будут поясняющие комментарии:<?php\n\nuse Bitrix\\Main\\ModuleManager;\n\n//Основной класс установщика модуля, должен наследоваться от системного класса CModule\nclass learnevents extends CModule\n{\n    //Системный идентификатор модуля, должен совпадать с названием класса\n    public $MODULE_ID = \'learnevents\';\n    //Версия модуля и дата. Оставляем пустыми так как подгрузим нужные в конструкторе\n    public $MODULE_VERSION;\n    public $MODULE_VERSION_DATE;\n    //Название модуля, выводимое в админ панели\n    public $MODULE_NAME = \'Управляемые обработчики\';\n    //Описание модуля, выводимое в админ панели\n    public $MODULE_DESCRIPTION = \'Тестовый модуль, показывающий возможности управления обработчиками события\';\n    //Адрес сайта разработчика модуля\n    public $PARTNER_URI = \'https://site.ru\';\n    //Не использовать права доступа к модулю на основе групп пользователей\n    public $MODULE_GROUP_RIGHTS = \'N\';\n\n    //Основной конструктор класса, в котором мы читаем файл version.php и берем оттуда версию модуля и дату релиза\n    public function __construct()\n    {\n        $arModuleVersion = [];\n\n        include __DIR__ . \'/version.php\';\n\n        if (is_array($arModuleVersion) && array_key_exists(\'VERSION\', $arModuleVersion)) {\n            $this->MODULE_VERSION = $arModuleVersion[\'VERSION\'];\n            $this->MODULE_VERSION_DATE = $arModuleVersion[\'VERSION_DATE\'];\n        }\n    }\n\n    //Метод, устанавливающий обработчики события при установке модуля\n    public function InstallEvents()\n    {\n        $eventManager = \\Bitrix\\Main\\EventManager::getInstance();\n        $eventManager->registerEventHandler("crm",\n            "OnBeforeCrmDealAdd",//Событие, на которое вешаем обработчик\n            $this->MODULE_ID,//Идентификатор модуля, берем текущий\n            "Learn\\\\Event\\\\Main",//PHP Класс с неймспейсом, в котором реализован метод обработчика\n            "RunEvent"//Название метода-обработчика\n        );\n        //Далее код других обработчиков\n        return true;\n    }\n\n    //Метод, удаляющий обработчики события при удалении модуля\n    public function UnInstallEvents()\n    {\n        $eventManager = \\Bitrix\\Main\\EventManager::getInstance();\n        $eventManager->unRegisterEventHandler("crm",\n            "OnBeforeCrmDealAdd",//Событие, на которое вешаем обработчик\n            $this->MODULE_ID,//Идентификатор модуля, берем текущий\n            "Learn\\\\Event\\\\Main",//PHP Класс с неймспейсом, в котором реализован метод обработчика\n            "RunEvent"//Название метода-обработчика\n        );\n        //Далее код других обработчиков\n        return true;\n    }\n\n    //Метод, запускающийся при установке модуля\n    public function DoInstall()\n    {\n        $this->InstallEvents();//Запускаем установку обработчиков\n        ModuleManager::registerModule($this->MODULE_ID);//Регистрируем модуль в системе как установленный\n    }\n\n\n    //Метод, запускающийся при удалении модуля\n    public function DoUninstall()\n    {\n        $this->UnInstallEvents();//Запускаем удаление обработчиков\n        ModuleManager::unRegisterModule($this->MODULE_ID);//Снимаем регистрацию модуля в системе\n    }\n\n\n}Далее добавляем файл /local/modules/learnevent/install/unstep1.php. Он будет отвечать за\xa0страничку, которая появляется перед удалением модуля в\xa0панели администратора:<?\n//Если пользователь не авторизован, прерываем метод\nif(!check_bitrix_sessid()) return;\necho CAdminMessage::ShowNote(\'Управляемые обработчики\');\n?>\n<form action="<?=$APPLICATION->GetCurPage(); ?>">\n\t<?=bitrix_sessid_post(); ?>\n\t<input type="hidden" name="step" value="2">\n\t<input type="hidden" name="id" value="learnevent">\n\t<input type="hidden" name="uninstall" value="Y">\n\t<input type="submit" name="nextstep" value="Далее">\n\t<input type="submit" name="cancel" value="Отменить">\n</form>Часто на\xa0данную страничку добавляют сообщения для\xa0тех, кто собирается удалить модуль, например «Пожалуйста, не\xa0удаляйте! Мы еще можем\xa0быть полезны».:)Папка libВ\xa0данной папке традиционно размещаются классы модуля, кототорые будут автоматически подключены при\xa0его установке. В\xa0нашем случае создаем файл /local/modules/learnevent/lib/main.php:namespace Learn\\Event;\n\nuse Bitrix\\Main\\Config\\Option;\n\nclass Main\n{\n     /**\n     * @return array|false Массив направлений сделки\n     * @description Возвращает массим текущих направлений сделок, поднадобится в админке\n     */\n    public static function getDealFunnels()\n    {\n        //Проверяем активен ли модуль CRM. Без него никакие Сделки доступны не будут\n        if (\\Bitrix\\Main\\Loader::includeModule(\'crm\')) {\n            //Получаем ООП Фабрику работы со сделками\n            $factory = \\Bitrix\\Crm\\Service\\Container::getInstance()->getFactory(\n                \\CCrmOwnerType ::Deal\n            );\n            //Получаем массив всех объектов направлений и делаем перебор\n            $categories = $factory->getCategories();\n            $arCategories = [];\n            foreach ($categories as $category) {\n                //Получаем данные каждого направления и записываем в массив\n                $arCategories[] = $category->getData();\n            }\n            return $arCategories;\n        } else {\n            return false;\n        }\n    }\n\n     /**\n     * @return array|false Результат обработчика\n     * @description Обработчик, который мы подключаем через модуля\n     */\n    public static function RunEvent(&$arFields)\n    {\n        //Проверяем, установлен ли флажок "Активно" в админке\n        if (Option::get("learnevent", "ACTIVE") == "Y") {\n            global $USER;\n            //Получаем список пользователей\n            $userExeptions = unserialize(Option::get("learnevent", "USER_EXEPTIONS"));\n            $pipeline = Option::get("learnevent", "PIPELINE");\n            if ((is_array($userExeptions) && in_array($USER->GetID(), $userExeptions)) || $userExeptions == $USER->GetID()) {                \n                    if (isset($arFields[\'CATEGORY_ID\']) && !empty($arFields[\'CATEGORY_ID\']) && ($arFields[\'CATEGORY_ID\'] == $pipeline)) {\n                        //Какие-то действия, если наше условие сработало. Например прерываем создание Сделки\n                        $arFields[\'RESULT_MESSAGE\'] = "Извините, данному пользователю запрещено создавать Сделку в данной воронке!";\n                        return false;\n                    }             \n            }\n\n        }\n    }\n}В\xa0данном файле можно разместить методы для\xa0других обработчиков. Также никто не\xa0запрещает повесить несколько разных методов на\xa0одно событие.Корневая папка модуляТеперь перейдем к\xa0одному из\xa0важнейших файлов, который реализует окно настроек модуля в\xa0панели администрирования Битрикс24. Этот файл по\xa0стандарту лежит в\xa0папке модуля и носит название options.php. В\xa0нашем случае создаем его по\xa0пути /local/modules/learnevent/options.php и добавляем туда код:<?php\n//Подключаем нужные нам неймспейсы и скрипты\nuse \\Bitrix\\Main\\Loader,\n    \\Bitrix\\Main\\Config\\Option;\n\nrequire_once $_SERVER[\'DOCUMENT_ROOT\'] . \'/bitrix/modules/main/include/prolog_admin_before.php\';\n\nrequire_once $_SERVER[\'DOCUMENT_ROOT\'] . \'/bitrix/modules/main/include/prolog_admin_after.php\';\n\nglobal $APPLICATION;\n\n$moduleName = \'learnevent\';\nif (!Loader::IncludeModule($moduleName)) {\n    return;\n}\n\n//Проверяем права доступа, если их нет - перекидываем на форму авторизации\n$POST_RIGHT = $APPLICATION->GetGroupRight($moduleName);\nif ($POST_RIGHT == "D")\n    $APPLICATION->AuthForm(GetMessage("ACCESS_DENIED"));\n\n//Получаем данные POST Запроса если настройки изменены, проводим фильтрацию данных для безопасности\n$request = Bitrix\\Main\\Application::getInstance()->getContext()->getRequest();\n$request->addFilter(new \\Bitrix\\Main\\Web\\PostDecodeFilter);\n\n//Сохраняем настройки модуля в системные опции (таблица b_option в БД)\nif ($POST_RIGHT == "W" && check_bitrix_sessid() && $request->isPost()) {\n    COption::SetOptionString($moduleName, \'ACTIVE\', $request->get(\'ACTIVE\'));\n    COption::SetOptionString($moduleName, \'PIPELINE\', $request->get(\'PIPELINE\'));\n    \n    //Так как у нас может быть множественное значение а база можно хранить только единицное - делаем сериализацию массива в строку\n    COption::SetOptionString($moduleName, \'USER_EXEPTIONS\', serialize($request->get(\'USER_EXEPTIONS\')));\n}\n\n//Инициализируем табы админки, у нас таб будет один\n$tabs = [\n    [\n        \'DIV\' => \'main\',\n        \'TAB\' => \'Настройки\',\n        \'ICON\' => \'\',\n    ]\n];\n$tabControl = new \\CAdminTabControl(\'tabControl\', $tabs);\n//Далее добавляем форму с полями настроек, которые будут выводиться в админке\n?>\n\n    <form method="POST"\n          action="<? echo $APPLICATION->GetCurPage() ?>?mid=<?= urlencode($mid) ?>&lang=<? echo LANGUAGE_ID ?>"\n          ENCTYPE="multipart/form-data" name="post_form">\n        <?= bitrix_sessid_post() ?>\n        <?php\n        $tabControl->Begin();\n        $tabControl->BeginNextTab();\n        ?>\n        <?//Поле "Обработчик активен"?>\n        <tr>\n            <td>Обработчик активен</td>\n            <td><input type="checkbox" name="ACTIVE"\n                       value="Y" <?php if (Option::get($moduleName, \'ACTIVE\') == "Y") echo \'checked\'; ?>/></td>\n        </tr>\n        <?//Поле "Воронка Сделки". Далее получаем массив воронок и текущую настройку?>\n        <tr>\n            <?php $allCategories = \\Learn\\Event\\Main::getDealFunnels(); ?>\n            <?php $currentCategory = Option::get($moduleName, \'PIPELINE\'); ?>\n            <td>Воронка Сделки</td>\n            <td>\n                <select name="PIPELINE">\n                    <?php foreach ($allCategories as $allCategory) { ?>\n                        <option value="<?= $allCategory[\'ID\'] ?>"<?php if ($allCategory[\'ID\'] == $currentCategory) echo \' selected\'; ?>><?= $allCategory[\'NAME\'] ?></option>\n                    <?php } ?>\n                </select>\n            </td>\n        </tr>\n        <?//Поле "Для пользователей". Множественный выбор пользователей для которых будет срабатывать обработчик.?>\n        <tr>\n            <?php $userCurId = unserialize(Option::get($moduleName, \'USER_EXEPTIONS\')); ?>\n            <?php $order = array(\'sort\' => \'asc\');\n            $tmp = \'sort\'; // параметр проигнорируется методом, но обязан быть\n            $rsUsers = \\CUser::GetList($order, $tmp);\n            $allUsers = [];\n            while ($arUser = $rsUsers->Fetch()) {\n                $allUsers[$arUser["ID"]] = "[" . $arUser["ID"] . "] " . $arUser["NAME"] . " " . $arUser["LAST_NAME"];\n            } ?>\n            <td>Для пользователей</td>\n            <td>\n                <select name="USER_EXEPTIONS[]" multiple>\n                    <?php foreach ($allUsers as $userID => $userName) { ?>\n                        <option value="<?= $userID ?>"<?php if ((is_array($userCurId) && in_array($userID, $userCurId)) || $userCurId == $userID) echo \' selected\'; ?>><?= $userName ?></option>\n                    <?php } ?>\n                </select>\n            </td>\n        </tr>\n        <? $tabControl->End(); ?>\n        <input type="submit" value="Сохранить">\n    </form>\n<?php\nrequire_once $_SERVER[\'DOCUMENT_ROOT\'] . \'/bitrix/modules/main/include/epilog_admin.php\';\n?>Данный файл реализует стандартную страницу настроек нашего модуля в\xa0разделе панели администратора Битрикс (Настройки\xa0— Настройки продукта\xa0— Настройки модулей\xa0— Управляемые обработчики). Вместо заключенияВыше мы разобрали минимально необходимый набор файлов, реализующих модуль для\xa0Битрикс24, устанавливающий обработчики события, и хранящий настройки для\xa0них. Модуль содержит минимальный набор системных методов для\xa0того, чтобы Битрикс воспринимал его именно как\xa0модуль, а\xa0не\xa0как\xa0набор скриптов непонятного назначения. Всем спасибо за\xa0внимание и жду нашей встречи в\xa0следующих статьях!Если вы работаете с коробочной версией Битрикс24 и хотите глубже разобраться в механике событий — их типах, регистрации и возможностях для управления сущностями, обратите внимание на предстоящий открытый урок «События в Битрикс24: Путеводитель по изменениям». Разберёмся в архитектуре событийной модели и обсудим, как эффективно внедрять собственные сценарии обработки изменений. Старт 21 мая в 20:00 — участие бесплатное, нужно только зарегистрироваться.А в календаре мероприятий можно записаться на открытые уроки по другим ИТ-направлениям.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('Моя логистическая компания продает на 453 млн в год, но купить себе Лексус я все еще не могу, и вот почему',), kwargs={}
Результат: моя логистическая компания продает на 453 млн в год но купить себе лексус я все еще не могу и вот почему
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: contains_keywords
Аргументы: args=('Моя логистическая компания продает на 453 млн в год, но купить себе Лексус я все еще не могу, и вот почему', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:16 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('ДИСКЛЕЙМЕР: Статья написана автором блога\xa0на основе интервью с Л. Сулиным, сооснователем логистической компании.По образованию я учитель географии. Что в современном мире привело меня в продажи.Я всегда хотел заниматься бизнесом, но не получалось. Начал, как все мечтают с пассивного дохода и вложился в вендинговые автоматы. Прогорел, начал делать сайты.В 2012 мой знакомый полетел в Китай и решил заняться продажей оборудования. А ко мне пришел, чтобы заказать сайт.Тогда меня поразила мысль, что бизнес может быть глобальным и не ограничен только Россией.– Там же везти надо, таможить ты знаешь как это?– Конечно, нет. Но ничего, разберемся.А когда делаешь сайт, тебе надо подробно расспросить заказчика, что продаешь, как устроен бизнес, и в итоге я так увлекся, что сказал:Я хочу с тобой в этот бизнес.Все русские на фото – это я и мой партнерПосвящается всем, кто везет, разгружает, загружает, оформляет грузы, и, конечно же, всем нам – логистам-экспедиторам.  Бизнес шел, а в 2014 мы попали на курсовой скачок, помните, когда доллар был 37, а потом резко стал 75. А у нас был заказ на гостендер. Мы пошли к заказчикам передоговариваться, но нам сказали:Ребят, раз взялись, уже везите.Тогда потеряли много денег и закрыли бизнес.Транспортная компания с нуляС другом мы уже сработались, был опыт в перевозках из Китая, и мы решили, что можем попробовать себя в качестве транспортной компании. Тогда все возили грузы из Европы, и Китай не был популярным направлением.Отношение к Китаю было:Вот ржавая труба, тут все гнилое, все низкого качества.А мы знали, что европейцы заказывали оборудование в Китае, вешали шильдики и продавали нам в Россию, типо итальянское качество. Я был на производстве и видел все эти заказы в Европу и все те шильдики.Сначала мы решили заняться контейнерными перевозками по морю, и был опыт негабаритных перевозок тралами.Негабаритные грузы – это когда нужно привезти что-то, не укладывающееся в обычные размеры стандартных контейнеров и фур, по весу или размерамМы сделали сайт, запустили контекстную рекламу, и заявки почти сразу пошли. Но заказы были на контейнерную перевозку, а на ней мы особо ничего не зарабатывали. И тут мне позвонил знакомый:Вы же из Китая возите? А можете мне сборный груз привезти?Сборный груз – это когда фуру или контейнер грузят несколько грузов для разных грузополучателей, обычно 7–10 клиентов.Сборные грузы из Китая тогда возили, но «в серую» – через карго.Карго перевозки или каргуха, как мы ее любя называем – это способ доставки грузов, в обход официальной доставки. Для небольших грузов это чаще всего выгоднее, чем официально и не особо сложно – вот тебе ставка за килограмм и погнали.Официальная доставка из-за границыВезем на склад временного хранения (СВХ) в стране отправителя, там оформляем груз для таможенного транзита, перевозим груз, доставляем на склад СВХ в стране назначения, подаем документы для таможенного выпуска товаров, рассчитываем и оплачиваем пошлины, НДС 20%, готовим декларации соответствия, сертификаты на продукцию и т.д. Получаем грузовую таможенную декларацию (ГТД), везем получателю.Карго доставка из-за границыЕсть страны (не будем их называть) где НДС не 20%, а меньше, и пошлины на некоторые товары сильны ниже.Поэтому каргушники везут груз из Китая через третью страну, а оттуда отправляют груз как будто на физлиц в Россию. А чтобы еще и не платить пошлину, например, автозапчасти таможатся как металлические изделия.В 90-е мне рассказывали, что карго просто гоняли через границу за определенную цифру на погранпереходе.Так вот. Если у вас компания с госучастием или госконтракт, вам обязательно надо везти в белую, там слово карго, даже рядом звучать не может. В карго никаких нормальных бумаг вам не дадут.И вот официальной сборной доставки из Китая на рынке почти не было. Если нужно привезти, например, 200 кг обуви все грузили в контейнер и по морю везли во Владивосток или в Питер. А мы нашли нужных китайцев и стали предлагать привести железной дорогой.По морю груз ехал 45-60 дней, еще пока разберут, пока соберут – все 70 дней. А наши поезда доезжали за 30-35 дней. То есть в 2 раза быстрее, а по цене чуть дороже, что было вау. Направление так зашло, что мы просто звонили по базе и когда находили компании, которые возят из Китая, мы говорили у нас есть сборка.Ничего себе, у вас есть официальная сборка?! 30 дней? Конечно, давайте!Так мы набрали пул клиентов и взлетели. Мы попали в промежуток времени, когда спрос есть, а предложения еще было недостаточно. Потом подключили авиадоставку.У рынка появляется осознание, что Китай – это нормально. Когда в 2017 я говорил, что скоро мы будем ходить с Хуавеями и Сяоми, все смеялись.Самсунг – знаю, Эппл – знаю, Хуавей, Сяоми – не слышал.Рынок автозапчастей уже сильно переехал на Китай. Не буду упоминать имена автосалонов, которые массово везли оригинальные японские/американские/корейские запчасти из Китая.Уже тогда было понятно, что Китай, делая по контракту запчасти для европейцев, набирается опыта и рано или поздно он этот опыт переложит дальше на свои машины. И в 2021 я уже говорил, что все будут ездить на китайских автомобилях.В 2018 санкции уже были, но глобально они никого не волновали. Но к нам уже приходили компании из госсектора с запросом купите, пожалуйста, для нас, у нас санкции.И мы начали погружаться в тему доставки санкционных грузов. Когда есть груз, есть заказ, но просто погрузить на самолет ты не можешь. И мы начинаем обрастать контактами в других странах, которые помогают доставлять санкционные товары. В основном нефтегаз.Наши клиенты в основном – заводы и производства.В 2020 случается первый жесткий удар по логистике – пандемия, перекрытие рынка, локдаун, ничего не привезти. Локдаун ломает логистику просто через колено.В 2018 морской контейнер плавал по тарифам за 500-800 долларов за ящик, и перевозчики говорили, что рынок перегрет и за такие ставки везти означает убыток. В ковид цена на тот же самый фрахт взлетает до 8 000 долларов в течение 2 месяцев (в 10 раз).Большинство говорило:Я подожду, я что дурак за 8 000 долларов плыть.А кто-то понял, что это надолго и сказал:Я плыву сейчас, зато у меня будет товарТогда многим было наплевать на цену, вопрос был в другом:Ребят, у вас вообще есть контейнера, вы вывезти сможете?А у нас уже накопились связи, были контакты с контейнерными перевозчиками, у кого были контейнеры на стоке в Китае. И за счет этого сильно выросли.В 2021 наш оборот составил 145 млн ₽.В 2022 локдаун закончился, начинается спецоперация. В логистике случается полное сумасшествие. Мне звонили знакомые знакомых, их дяди и тети.Вы же с Китаем работаете? Мы в Европе, нам надо аналоги, можете купить/привезти?Я тогда отключил всю рекламу, потому что у меня телефон просто не замолкал.В 2022 оборот нашей компании составил 204 млн ₽.Мы и дальше росли по восходящей.Проблемы логистики в 2025Сейчас у нас в логистике происходит следующее.КризисРынок находится в ситуации жесточайшей конкуренции, грузопоток упал. С Нового года мы чувствуем серьезную просадку у всех клиентов, мне честно это напоминает 2018 год, когда была просадка перед локдауном. Ставки упали, появились желающие работать чуть ли не в минус.Китайцы наступаютРаньше китайцы никогда не ползали на наш рынок напрямую, они работали через российские компании. Сейчас, если посмотреть даже по последней выставке 50-60% стендов – это китайцы. Они напрямую открывают свои филиалы.А логистику китайцы хотят делать со своими китайцами, не с русскими.В Америке и Европе китайцы привыкли работать с маленькой комиссией, но на больших объемах. Ту же модель они принесли на российский рынок, но проблема, что у нас не такой большой рынок, чтобы хватало работать в прибыль на 2-3% комиссии.Сколько ни демпингуй, рынок не станет больше, но ценники они всем роняют и всех выжигают. Маленькие компании не выдерживают и просто закрываются.Осталось одно направлениеМногие логистические компании, которые раньше занимались Европой и Америкой, после санкций перешли на Китай, и, конечно, лучше они ничего не придумали, кроме как:А давайте лупанем ценники вниз!Раньше рынок рос, и всем хватало. А сейчас все перестроились на одно направление, а грузопоток упал и так мы оказались даже не в красном, а в бордовом океане.Как открыть логистическую компания с нуляВ логистике есть проблемы курицы или яйца. Пока у тебя нет хороших ставок на перевозку, у тебя нет объема грузов, а пока у тебя нет объема грузов, у тебя нет хороших ставок. Решил эту задачу – молодец, не решил – ты вне игры.Когда мы начинали в 2015, нам понадобилось 100 000 ₽ и телефонная книжка. Раньше ты сел дома, взял телефон, открыл почту, и вот ты уже работник международной логистики. Сейчас из-за дикой конкуренции такое сложно представить.Откуда прибыль в логистикеМногие думают, что логисты – это такие кровопийцы, которые сидят на спине у несчастного перевозчика, сосут кровь и ничего не делают. Вроде риелторов. И многие говорят:А давайте напрямую покупать ставки у перевозчиков.Гуглишь «купить билет Пекин – Москва» и тебе дадут варианты, где можно купить билеты. Эйрчайна, Аэрофлот и др. И ты думаешь: сейчас я зайду на сайт Аэрофлота в раздел грузоперевозки и зачем мне какой-то там экспедитор. Звучит логично.А вот как оно работает на самом деле, если везут груз в пассажирском самолете. Самолет прилетает в аэропорт, и у него есть час-два, чтобы быстренько заправиться, загрузить багаж, пассажиров, грузы и быстро улететь, потому что пока самолет летит в воздухе – он зарабатывает деньги, а пока стоит на земле – он деньги тратит.При этом никто не знает, сколько точно будет пассажиров на каждом рейсе, сколько у них будет багажа, есть только примерные расчеты. И когда регистрация пройдена, авиакомпания сообщает агенту:У нас осталось 8 тонн свободных емкостей, можем взять 8 тонн груза.А к тому времени груз должен быть промаркирован, упакован по правилам: что за груз, что за тип груза, пройдена таможня, оформлены документы и т.д.К моменту погрузки на борт, груз уже должен стоять на перроне. Это фото погрузки во времена ковид, груз грузили прямо в салон вместо пассажиров.Бывает, груз забронирован на 4 мая, груз привозят, он стоит «под хвостом», но пришло много пассажиров и много багажа, и груз не берут, хоть ты его и бронировал. Это называется off load, то есть не влезло и разгрузили. В итоге груз летит только 5 мая.Заниматься всеми этими проблемами с грузами авиакомпания не хочет, и всю подготовку и бронирование мест поручает так называемым GSA – Дженерал сейлз эджент, то есть генеральным агентам по продажам.Таких агентов у авиакомпании несколько и бывает, что 1 самолет выкупает несколько разных агентов. Чтобы точно быть уверенными, что все грузовое место у авиакомпании купят, они используют модель – блок спейс агримент BSA. То есть когда агент вперед платит за определенный объем.Блок спейс – забронировать пространство в самолете.Как если бы риелтор сначала покупал квартиру и только потом бы ее продавал. Дальше генеральный агент распределяет выкупленные емкости между своими агентами: одному 5 тонн, другому 3 и нам 2 тонны, к примеру.Авиакомпания распределяет рейсы между агентами. Кто дает больше грузов, тот и получает больше рейсов (не всегда по самой низкой цене), чем больше грузов, тем лучше цену получает агент. Следовательно, чем больше объем грузов, тем лучше условия можно получить от авиакомпании.Дальше у генеральных агентов появляются помощники-консолидаторы, которые помогают им выкупать этот объем. Здесь они накручивают свои проценты и продают свои 5 тонн груза пятерым крупным помошникам-консолидаторам по 1 тонне. А тарифная сетка напрямую зависит от веса, который агент готов выкупить.Разберу на примере Аэрофлота, рейс – Пекин – Москва.Тот кто купит 45 кг груза – заплатит 45 юаней за 1 кгТот кто купит 100 кг груза – заплатит 26 юаней за 1 кгТот кто купит 300 кг груза – заплатит 23 юаней за 1 кгТот кто купит 500 кг груза – заплатит 21 юаней за 1 кгА тот, кто купит 1 000 кг груза – заплатит 18 юаней за 1 кгЭто тариф генерального агента, он взял себе примерно 5 тонн от 12 до 16 юаней напрямую у авиакомпании и получает свои 20-35% наценки.То есть тот, кто купит у генерального агента место под тонну груза за 18 юаней, сможет перепродать ее десятерым клиентам с объемами по 100 кг за 26 юаней. То есть накрутить свои 45% прибыли.В реальности, конечно, все не так прекрасно и из-за того, что другие игроки тоже хотят перепродать как можно больше, наценка в среднем по рынку – 7-15%. И как минимум тебе нужно поставить ценник дешевле, чем у GSA, потому что за 26 юаней клиент проще сходит напрямую.Отсюда видно, что наиболее выгодно продавать кусочки от 45 до 100 кг. Тогда ты вообще можешь демпингануть, предложить 30-35 юаней (вместо 45) и все равно получить наценку в 70%.Но если ты будешь сильно ломать рынок, тебе могут просто в следующий раз не дать сделать блок спейс, то есть не продать. Скажут, что ты в прошлый раз нам всем бизнес испортил, до свидания.И ты постоянно должен попробовать заработать побольше, но и не злить остальных. И вот ты звонишь клиенту, говоришь хорошую ставку, просишь никому не говорить, что у него такая цена. Ему звонят конкуренты, предлагают, он говорит: а у меня дешевле.И все такие:Как так-то, да нет же таких тарифов!А бывает, что купил 1000 кг, а из них продал только 300 кг, и в итоге поехал в минус. Потому что нельзя просто пообещать, что купишь, надо подписать блок спейс, что каждую неделю берешь объем груза.Поэтому наивно полагать, что компания, у которой есть 100 кг груза, получит цены лучше, чем я, как экспедитор, который ему перепродаю, даже если у меня есть хотя бы тонна груза в неделю.В итоге те, кто берут у генеральных агентов авиакомпании напрямую, получают самую высокую цену, которую можно получить на рынке. Сама авиакомпания вообще не продает грузовые емкости напрямую, только через GSA.Помимо веса на стоимость перевозки влияет объем груза.Например, 1 фура может взять 21 тонну и 89 кубов. И вот тебе привозят груз, а там 20 кубов весит 1 тонна. В этот момент, ты не знаешь, какую ставку давать, в тоннах или в кубах? Поэтому логисты придумали плотность. Например, для автоперевозок стандарт: 1 куб – 250 кг.На каждый сборный груз в фуре или контейнере делаем предварительную схему погрузки. Ма называем это «поиграть в тетрис».Если разделить идеальными кубиками фуру, влезет 89 кубиков весом 250 кг.А если груз меньше куба, но тяжелый, например, станок под 800 кг и ты:О, здорово у нас в этой партии много легкого груза, нам тяжелый надо. Надо забирать и даешь ставку 150 USD на куб, когда обычная ставка 200 USD.Например, у тебя уже есть 30 кубов обуви и тебе выгодно продать место под тяжелый груз и тогда и вес, и плотность будут хорошими, а значит, хорошая ставка. Так экспедитор играется, старается подвести под идеальную плотность 1 куб/250 кгПо похожей схеме строится все ценообразование в логистике. А помимо этого, экспедитор должен много всего выяснить:Груз на паллете, в коробке, что за груз, опасный? Батарейки Температурный или нет? Кто растамаживает, кто встречает? Куда вывозить? Что с документами на груз?Часто игрушки продают без батареек, потому что доставка без батарейки – 3 доллара, а с батарейкой – 8 долларов.А еще надо забрать в Китае, довезти до аэропорта, затаможить, вылезет магнитный контроль, потому что клиент не знал, что стоял вентилятор или редуктор какой, а документа нет. Все это проходишь, а тут агент сообщает, что самолет загружен и ты уже не влезешь со своим грузом, у тебя перенос на следующий рейс.И клиент звонит:Ты же обещал 4 мая какого черта? Ну вот, туда-сюда, вот такая ситуация…Я звоню:Ребят я столько груза у вас беру, мне очень важно, чтобы именно 4 мая у ребят было оборудование, там госконтракт, 5 мая – последний день.И если много возишь тебе и правда идут на встречу, кого-то выкидывают, кому-то офф лоуд ставят, кто редко летает. И тебе звонят:Все мы тебя загрузили!То есть на объеме можешь и ставку дать дешевле и пропихнуть можешь вперед. А когда у клиента большой груз, то работает, наоборот, клиент тоже не дурачок, будет тендерить, сталкивать лбами, то есть ставки озвучивать разным компаниям, и кто даст цену ниже, тому груз и отдадут.У меня тут 5 тонн груза, давай будем по ценнику демпинговаться.Но в конце года начинается другое: все хотят лететь, все перегружено и тебя спрашивают:– А можешь мне 5 тонн за раз увезти?– Специально для тебя есть цена. Для всех – 19 юаней, но если хочешь 5 тонн за раз, можем за 25 юаней полететь.– О супер, летим!Иногда у генеральных агентов недоборы и они звонят:Давайте грузов, а мы вам спецтариф.И тебе дают 12 юаней за кг, когда по рынку 18 юаней за кг, и ты хоп-хоп быстро обзвонил клиентов, блок спейс сделал, заработал.🔔 Работа формата зависит от вашей поддержки, чтобы поддержать автора статьи,\xa0подпишитесь на канал "Упал, поднялся".Доходы логистической компанииВсе поступления в кассу распишу на примере 2024 года. Общие поступления в этом году – 453 млн ₽.Технический импортер – 271,5 млн ₽Если компания с госучастием не может купить товар у Китайского завода, например, из-за санкций, она ищет себе технического импортера, вроде нас.Это когда какая-то компания не покупает напрямую товар в Китае, а поручает это нам.Вот поставщик, возьмите у него. Мы туда съездили, проверили, но на тендер напрямую завести не можем.Основные причины такого явления – политические ситуации. Иногда таким образом таможенные риски перекладывают на тебя, иногда просто кредитуются через тебя таким образом.Здесь проблема, что кто импортировал, тот и несет гарантийные и финансовые обязательства.Авиаперевозки – 108 млн ₽Тут есть 2 варианта:1. Пассажирскими самолетамиЭто когда самолет берет пассажиров и на оставшуюся грузоподъемность берет коммерческие грузы. Мы называем это – берет под хвостом.2. Грузовые самолетыКогда самолет предназначен именно для перевозки груза. В том числе опасные грузы или большого объема.3. Авиаконсолидация -–сервис для доставки небольших грузов от 1 кг до 40 кг.Железная дорога (сборный груз) – 19,7 млнПроблема этого направление в 2025 – не совсем честная конкуренция.В международных перевозках груз должен приехать строго в определенную точку. От склада временного хранения (СВХ) одной страны к СВХ другой, и не важно, как ты едешь морем, железной дорогой или авто.Когда ты везешь сборный груз у тебя в одном контейнере, например, 10 разных товаров и все они будут таможиться раздельно. И если 1 из 10 таможню не пройдет, остальные 9 грузов будут его ждать.И вот тут появились склады временного хранение (СВХ). Ты разделяешь груз и таможишь раздельно. Если какой-то груз не прошел таможню, он лежит на складе временного хранения, ты платишь за каждый день склада, и просто перевыставялешь это клиенту, это его риски, что у товара возникли проблемы с таможней.Но если склад временного хранения не использовать, то за все 10 грузов нужно платить за простой, и тут грузополучатели, у которых было все хорошо с таможней уже тебя не поймут, почему это им надо платить за простой, если у них все хорошо. То есть эти расходы – мои расходы как перевозчика.Один раз мы проводили досмотр несколько дней с 4 сотрудниками от нас и 3 от склада СВХТак за неделю можно попасть и на 200, и на 300 000 ₽. А перевыставить клиенту за весь груз не можешь, потому что он скажет:Так размещал бы меня на СВХ, что за дела?Тут фокус в том, что таможенный склад или склад временного хранения (СВХ), где грузы ждут растаможки – это частная организация.СВХ – как правило принадлежат частным перевозчикам или являются их дочками. И для железной дороги, на некоторых станциях попасть на СВХ со свой сборкой становится проблемой, так как нет емкостей СВХ для принятия твоего груза. Возникает что-то вроде монополии, для своих грузов емкости есть, для твоих – нет.А в среднем по всем направлениям наши комиссионные – 7-15%. Бывает 30%, а бывает и в минус съездишь.ВыручкаВ 2024 при выручке в 453 млн ₽ осталось 44,9 млн ₽ комиссионных.А дальше начинается.Расходы логистической компанииРаспишу расходы на примере 2024 года, где получилось 44,9 млн ₽ комиссионных. Теперь из них нужно вычесть.Банковские комиссии – 1,45 млн ₽Конвертация и комиссия за переводы – 7,5 млн ₽Потому что Напрямую в Китай не можешь отправить.Зарплаты офис за 13 человек – около 14,5 млн ₽ с налогами.Логисты (70–100 000 ₽), менеджеры по продажам (80–120 000 ₽), аккаунт-менеджер, который работает с клиентами (90–120 000 ₽), служба безопасности.За продавцов конкурировать сложно, профессионал охотнее идут в крупные компании, где 3 этажа офис, и могут давать спецтарифы, с помощью которых можно лучше продавать, а значит, и получать больше комиссионных.В итоге все больше нанимаю людей без опыта в ВЭД (внешнеэкономическая деятельность). Учу с нуля, примерно через полгода человек начинает понимать, что тут у нас вообще происходит, то есть 3-4 месяца платишь стипендию.А за 30 000 руб сейчас люди работать не идут. По крайней мере, в офис на полный день.Бухгалтерия после сдачи квартальной отчетности, сидела до 4 утра и осталась на работе спать.Бухгалтерия, телемаркетинг (40–60 000 за человека), оптимизация сайта, помощь с битриксом – аутсорсинг. Всего 5,28 млн ₽ за год.На рекламу потратили 690 000 ₽. Обзваниваем базы, платим за SEO, все еще делаем контекстную рекламу в Яндексе, хотя иногда клик может стоит по 1000 ₽. Основной канал, конечно – сарафан.И партнерский канал, чаще всего таможенный брокер. Мы оказываем разные услуги и друг другу приводим заказчиков.Еще внедряем нейросети.Обучили их распознавать документы и теперь так можем проводить расчетыИтого в 2024 постоянные расходы составили 30,4 млн ₽.Сколько зарабатывает логистическая компания?Всего при полученной комиссии в 44,9 млн ₽, постоянных расходах в 30,4 млн ₽, и налогах на прибыль в 2,9 млн ₽ осталось 11,6 млн ₽ прибыли за 2024 год.Но это не значит, что мы с партнером за год забрали по 5,8 млн ₽. Много денег идет обратно в бизнес.Ты вроде заработал и думаешь:Вот сейчас-то и построю дачку лямов за 12.Но тут приходит крупный клиент и просит привезти тебе большой груз. А крупные платят с отсрочкой, и чтобы ты смог им привезти, нужны оборотные деньги. Иногда это заморозка денег на 3-4 месяца. Но часть клиента поэтому и обращается к тебе, так как свою оборотку морозить не хочет.Еще когда тебе дают груз на 150 млн, к тебе приезжает служба безопасности, смотрит твою оборотку, потому что тебе не доверят груз, если не поймут, что смогут с тебя забрать компенсацию. Поэтому оборотка – это возможность работать с крупными клиентами.Поэтому либо живешь здесь и сейчас, либо вкладываешься, растешь и стабилизируешь бизнес. Крупные работают с крупными, тебе никто не отдаст груз большой стоимостью, если с тебя нечего взять. Взамен ты можешь давать цену выше рынка. Они таким образом платят за безопасность.Иногда думаешь, если все посчитать, кажется, что на депозит под 20% положить будет выгоднее. Немного прибыль берем, но не то чтобы я вывел себе дивиденды прям. Нам говорят: я при таких оборотах ездил бы на лексусе, но у нас не такая рентабельность.А еще всегда нужно иметь запас денег на форс-мажоры. С одной машины заработал 300 000 ₽, а с другой потерял 300 000 ₽ или попал на миллион.Форс-мажоры в логистикеНи разу с 2015 года не помню случая, когда отдал груз и пришли деньги. Всегда какие-то проблемы. Самолет сломался, машина не зашла, с документами накосячили, груз разбили.Декабрь 2023, китайские новости: ту-204 заходит на посадку с горящим двигателем... В нем в том числе наш груз на пару сотен тысяч долларов.Авиаперевозки все берут за скорость и на задержки реагируют чувствительно.А у тебя самолет стоит в ремонте неделю, клиент звонит:Почему так долго? Мы вроде авиаперевозку покупали, а не морскую.В логистике ты постоянно на стрессе.– ой, у нас груз не готов– оплата не прошла– пакет документов не готов– груз в Китае застрял– машина не зашла, и в последний момент ее перекупили по другой ценеТут всегда что-то происходит.Проблемы идутУ меня погрузили оборудование за 300 000 $ в деревянный ящик и погрузчик вилами в аэропортуТыдыщ!Я клиенту скидываю фотку, он говорит:Вези, но если он заехал в микросхему, нам хана.Мы 2 мес делали, потом 3 мес везли эту микросхему из Японии на заказ в Китай, а у нас уже тендер закрывать, только это ждем, там линия на 200 млн контракт.Чуть что всех по цепочке будут вылавливать. И вот ты сидишь седой, звонят:2 мм вилка прошла рядом, сейчас быстро подрихтуем и сдаем!В этот раз пронесло.А бывает не прокатывает. Везли оборудование, говорили сделать деревянный контейнер.Оборудование стоило 250 000 $. Они к заводу, завод просит 10 000 $ за упаковку в деревянный ящик.10 000 $ хотели за такой ящикЗаказчики решили, что это перебор.– Да так доедет– Мы не доедем, надо делать.– Это не укладывается в цифры, которые мы закладывали в перевозку.Повезли.На складе крановщик начинает подцеплять, кран срывается, и крюк попадает прямо в сенсорный сименсовский монитор за несколько тыс долларов.Нет чтобы рядом в металл, попал прямо в монитор.А потом проблема с таможней, в итоге груз должен был приехать летом, а приехал зимой, нападал снег, и оборудование уже просто не включилось.Вы же сами от упаковки отказались.Но они пошли в суд и нам присудили полную стоимость и так попали на 5 млн. На скане договора было, что мы отвечаем за упаковку, хотя я помню, что мы такое не писали, оригиналов они не предоставили, но суд присудил по скану.В итоге такая неблагодарная работа: перевозчик косячит – ты платишь, клиент косячит – ты платишь.Авиакомпания застрахована, она по международному праву может везти груз 21 день, а мы-то клиенту обещаем конкретные сроки, у меня заявка подписана, и меня потом таскают в суды.Суд спрашивает подтверждение о задержке от авиакомпании, мы к авиакомпании, а они вообще ни в чем не хотят участвовать, говорят идите к генеральным агентам.Суд говорит: покажите всю цепочку взаимодействия, кто с кем работал. То есть ты должен весь свой бизнес спалить в суде, и ты думаешь:Да проще уж страховую премию заплатить, чем все это палить.Еще бывает в понедельник увез груз, забронировал место, по курсу клиенту выставил, а курс бац, на 3 рубля за день вырос и всю прибыль, что наработал – потерял.Вот эта фотка года 2 прошло, но я до сих пор помню звонок водителя... Мол, вы че в меня грузить собрались. Я уезжаю.Хотя груз иногда выглядит и более зловещеСейчас все ждут, что государство прижмет карго, но к слову ждут это все года, сколько работаю. И смотрим на Африку, есть ощущение, что это направление будет сильно расти.Спасибо, что прочитали, получайте и отправляйте грузы, а мы вам поможем.Уже больше года я раз в неделю беру интервью у предпринимателей про реальный бизнес, а не этот ваш успешный успех.Может показаться, что\xa0«Упал, поднялся»\xa0– это весёлые истории о том, как пожарить косточки, насушить листья, склеить картон, чтобы заработать миллионы на маркетплейсах. Но на самом деле в блоге уже больше 50 статей из разных ниш с подробными выкладками по цифрам.Подписывайтесь на блог «Упал, поднялся – интервью про бизнес».',), kwargs={}
Результат: дисклеймер статья написана автором блога на основе интервью с л сулиным сооснователем логистической компаниипо образованию я учитель географии что в современном мире привело меня в продажия всегда хотел заниматься бизнесом но не получалось начал как все мечтают с пассивного дохода и вложился в вендинговые автоматы прогорел начал делать сайтыв 2012 мой знакомый полетел в китай и решил заняться продажей оборудования а ко мне пришел чтобы заказать сайттогда меня поразила мысль что бизнес может быть глобальным и не ограничен только россией там же везти надо таможить ты знаешь как это конечно нет но ничего разберемсяа когда делаешь сайт тебе надо подробно расспросить заказчика что продаешь как устроен бизнес и в итоге я так увлекся что сказаля хочу с тобой в этот бизнесвсе русские на фото  это я и мой партнерпосвящается всем кто везет разгружает загружает оформляет грузы и конечно же всем нам  логистамэкспедиторам  бизнес шел а в 2014 мы попали на курсовой скачок помните когда доллар был 37 а потом резко стал 75 а у нас был заказ на гостендер мы пошли к заказчикам передоговариваться но нам сказалиребят раз взялись уже везитетогда потеряли много денег и закрыли бизнестранспортная компания с нуляс другом мы уже сработались был опыт в перевозках из китая и мы решили что можем попробовать себя в качестве транспортной компании тогда все возили грузы из европы и китай не был популярным направлениемотношение к китаю быловот ржавая труба тут все гнилое все низкого качестваа мы знали что европейцы заказывали оборудование в китае вешали шильдики и продавали нам в россию типо итальянское качество я был на производстве и видел все эти заказы в европу и все те шильдикисначала мы решили заняться контейнерными перевозками по морю и был опыт негабаритных перевозок траламинегабаритные грузы  это когда нужно привезти чтото не укладывающееся в обычные размеры стандартных контейнеров и фур по весу или размераммы сделали сайт запустили контекстную рекламу и заявки почти сразу пошли но заказы были на контейнерную перевозку а на ней мы особо ничего не зарабатывали и тут мне позвонил знакомыйвы же из китая возите а можете мне сборный груз привезтисборный груз  это когда фуру или контейнер грузят несколько грузов для разных грузополучателей обычно 710 клиентовсборные грузы из китая тогда возили но в серую  через каргокарго перевозки или каргуха как мы ее любя называем  это способ доставки грузов в обход официальной доставки для небольших грузов это чаще всего выгоднее чем официально и не особо сложно  вот тебе ставка за килограмм и погналиофициальная доставка изза границывезем на склад временного хранения свх в стране отправителя там оформляем груз для таможенного транзита перевозим груз доставляем на склад свх в стране назначения подаем документы для таможенного выпуска товаров рассчитываем и оплачиваем пошлины ндс 20 готовим декларации соответствия сертификаты на продукцию и тд получаем грузовую таможенную декларацию гтд везем получателюкарго доставка изза границыесть страны не будем их называть где ндс не 20 а меньше и пошлины на некоторые товары сильны нижепоэтому каргушники везут груз из китая через третью страну а оттуда отправляют груз как будто на физлиц в россию а чтобы еще и не платить пошлину например автозапчасти таможатся как металлические изделияв 90е мне рассказывали что карго просто гоняли через границу за определенную цифру на погранпереходетак вот если у вас компания с госучастием или госконтракт вам обязательно надо везти в белую там слово карго даже рядом звучать не может в карго никаких нормальных бумаг вам не дадути вот официальной сборной доставки из китая на рынке почти не было если нужно привезти например 200 кг обуви все грузили в контейнер и по морю везли во владивосток или в питер а мы нашли нужных китайцев и стали предлагать привести железной дорогойпо морю груз ехал 4560 дней еще пока разберут пока соберут  все 70 дней а наши поезда доезжали за 3035 дней то есть в 2 раза быстрее а по цене чуть дороже что было вау направление так зашло что мы просто звонили по базе и когда находили компании которые возят из китая мы говорили у нас есть сборканичего себе у вас есть официальная сборка 30 дней конечно давайтетак мы набрали пул клиентов и взлетели мы попали в промежуток времени когда спрос есть а предложения еще было недостаточно потом подключили авиадоставкуу рынка появляется осознание что китай  это нормально когда в 2017 я говорил что скоро мы будем ходить с хуавеями и сяоми все смеялисьсамсунг  знаю эппл  знаю хуавей сяоми  не слышалрынок автозапчастей уже сильно переехал на китай не буду упоминать имена автосалонов которые массово везли оригинальные японскиеамериканскиекорейские запчасти из китаяуже тогда было понятно что китай делая по контракту запчасти для европейцев набирается опыта и рано или поздно он этот опыт переложит дальше на свои машины и в 2021 я уже говорил что все будут ездить на китайских автомобиляхв 2018 санкции уже были но глобально они никого не волновали но к нам уже приходили компании из госсектора с запросом купите пожалуйста для нас у нас санкциии мы начали погружаться в тему доставки санкционных грузов когда есть груз есть заказ но просто погрузить на самолет ты не можешь и мы начинаем обрастать контактами в других странах которые помогают доставлять санкционные товары в основном нефтегазнаши клиенты в основном  заводы и производствав 2020 случается первый жесткий удар по логистике  пандемия перекрытие рынка локдаун ничего не привезти локдаун ломает логистику просто через коленов 2018 морской контейнер плавал по тарифам за 500800 долларов за ящик и перевозчики говорили что рынок перегрет и за такие ставки везти означает убыток в ковид цена на тот же самый фрахт взлетает до 8 000 долларов в течение 2 месяцев в 10 разбольшинство говорилоя подожду я что дурак за 8 000 долларов плытьа ктото понял что это надолго и сказаля плыву сейчас зато у меня будет товартогда многим было наплевать на цену вопрос был в другомребят у вас вообще есть контейнера вы вывезти сможетеа у нас уже накопились связи были контакты с контейнерными перевозчиками у кого были контейнеры на стоке в китае и за счет этого сильно вырослив 2021 наш оборот составил 145 млн в 2022 локдаун закончился начинается спецоперация в логистике случается полное сумасшествие мне звонили знакомые знакомых их дяди и тетивы же с китаем работаете мы в европе нам надо аналоги можете купитьпривезтия тогда отключил всю рекламу потому что у меня телефон просто не замолкалв 2022 оборот нашей компании составил 204 млн мы и дальше росли по восходящейпроблемы логистики в 2025сейчас у нас в логистике происходит следующеекризисрынок находится в ситуации жесточайшей конкуренции грузопоток упал с нового года мы чувствуем серьезную просадку у всех клиентов мне честно это напоминает 2018 год когда была просадка перед локдауном ставки упали появились желающие работать чуть ли не в минускитайцы наступаютраньше китайцы никогда не ползали на наш рынок напрямую они работали через российские компании сейчас если посмотреть даже по последней выставке 5060 стендов  это китайцы они напрямую открывают свои филиалыа логистику китайцы хотят делать со своими китайцами не с русскимив америке и европе китайцы привыкли работать с маленькой комиссией но на больших объемах ту же модель они принесли на российский рынок но проблема что у нас не такой большой рынок чтобы хватало работать в прибыль на 23 комиссиисколько ни демпингуй рынок не станет больше но ценники они всем роняют и всех выжигают маленькие компании не выдерживают и просто закрываютсяосталось одно направлениемногие логистические компании которые раньше занимались европой и америкой после санкций перешли на китай и конечно лучше они ничего не придумали кроме кака давайте лупанем ценники внизраньше рынок рос и всем хватало а сейчас все перестроились на одно направление а грузопоток упал и так мы оказались даже не в красном а в бордовом океанекак открыть логистическую компания с нуляв логистике есть проблемы курицы или яйца пока у тебя нет хороших ставок на перевозку у тебя нет объема грузов а пока у тебя нет объема грузов у тебя нет хороших ставок решил эту задачу  молодец не решил  ты вне игрыкогда мы начинали в 2015 нам понадобилось 100 000  и телефонная книжка раньше ты сел дома взял телефон открыл почту и вот ты уже работник международной логистики сейчас изза дикой конкуренции такое сложно представитьоткуда прибыль в логистикемногие думают что логисты  это такие кровопийцы которые сидят на спине у несчастного перевозчика сосут кровь и ничего не делают вроде риелторов и многие говорята давайте напрямую покупать ставки у перевозчиковгуглишь купить билет пекин  москва и тебе дадут варианты где можно купить билеты эйрчайна аэрофлот и др и ты думаешь сейчас я зайду на сайт аэрофлота в раздел грузоперевозки и зачем мне какойто там экспедитор звучит логичноа вот как оно работает на самом деле если везут груз в пассажирском самолете самолет прилетает в аэропорт и у него есть часдва чтобы быстренько заправиться загрузить багаж пассажиров грузы и быстро улететь потому что пока самолет летит в воздухе  он зарабатывает деньги а пока стоит на земле  он деньги тратитпри этом никто не знает сколько точно будет пассажиров на каждом рейсе сколько у них будет багажа есть только примерные расчеты и когда регистрация пройдена авиакомпания сообщает агентуу нас осталось 8 тонн свободных емкостей можем взять 8 тонн грузаа к тому времени груз должен быть промаркирован упакован по правилам что за груз что за тип груза пройдена таможня оформлены документы и тдк моменту погрузки на борт груз уже должен стоять на перроне это фото погрузки во времена ковид груз грузили прямо в салон вместо пассажировбывает груз забронирован на 4 мая груз привозят он стоит под хвостом но пришло много пассажиров и много багажа и груз не берут хоть ты его и бронировал это называется off load то есть не влезло и разгрузили в итоге груз летит только 5 маязаниматься всеми этими проблемами с грузами авиакомпания не хочет и всю подготовку и бронирование мест поручает так называемым gsa  дженерал сейлз эджент то есть генеральным агентам по продажамтаких агентов у авиакомпании несколько и бывает что 1 самолет выкупает несколько разных агентов чтобы точно быть уверенными что все грузовое место у авиакомпании купят они используют модель  блок спейс агримент bsa то есть когда агент вперед платит за определенный объемблок спейс  забронировать пространство в самолетекак если бы риелтор сначала покупал квартиру и только потом бы ее продавал дальше генеральный агент распределяет выкупленные емкости между своими агентами одному 5 тонн другому 3 и нам 2 тонны к примеруавиакомпания распределяет рейсы между агентами кто дает больше грузов тот и получает больше рейсов не всегда по самой низкой цене чем больше грузов тем лучше цену получает агент следовательно чем больше объем грузов тем лучше условия можно получить от авиакомпаниидальше у генеральных агентов появляются помощникиконсолидаторы которые помогают им выкупать этот объем здесь они накручивают свои проценты и продают свои 5 тонн груза пятерым крупным помошникамконсолидаторам по 1 тонне а тарифная сетка напрямую зависит от веса который агент готов выкупитьразберу на примере аэрофлота рейс  пекин  москватот кто купит 45 кг груза  заплатит 45 юаней за 1 кгтот кто купит 100 кг груза  заплатит 26 юаней за 1 кгтот кто купит 300 кг груза  заплатит 23 юаней за 1 кгтот кто купит 500 кг груза  заплатит 21 юаней за 1 кга тот кто купит 1 000 кг груза  заплатит 18 юаней за 1 кгэто тариф генерального агента он взял себе примерно 5 тонн от 12 до 16 юаней напрямую у авиакомпании и получает свои 2035 наценкито есть тот кто купит у генерального агента место под тонну груза за 18 юаней сможет перепродать ее десятерым клиентам с объемами по 100 кг за 26 юаней то есть накрутить свои 45 прибылив реальности конечно все не так прекрасно и изза того что другие игроки тоже хотят перепродать как можно больше наценка в среднем по рынку  715 и как минимум тебе нужно поставить ценник дешевле чем у gsa потому что за 26 юаней клиент проще сходит напрямуюотсюда видно что наиболее выгодно продавать кусочки от 45 до 100 кг тогда ты вообще можешь демпингануть предложить 3035 юаней вместо 45 и все равно получить наценку в 70но если ты будешь сильно ломать рынок тебе могут просто в следующий раз не дать сделать блок спейс то есть не продать скажут что ты в прошлый раз нам всем бизнес испортил до свиданияи ты постоянно должен попробовать заработать побольше но и не злить остальных и вот ты звонишь клиенту говоришь хорошую ставку просишь никому не говорить что у него такая цена ему звонят конкуренты предлагают он говорит а у меня дешевлеи все такиекак такто да нет же таких тарифова бывает что купил 1000 кг а из них продал только 300 кг и в итоге поехал в минус потому что нельзя просто пообещать что купишь надо подписать блок спейс что каждую неделю берешь объем грузапоэтому наивно полагать что компания у которой есть 100 кг груза получит цены лучше чем я как экспедитор который ему перепродаю даже если у меня есть хотя бы тонна груза в неделюв итоге те кто берут у генеральных агентов авиакомпании напрямую получают самую высокую цену которую можно получить на рынке сама авиакомпания вообще не продает грузовые емкости напрямую только через gsaпомимо веса на стоимость перевозки влияет объем грузанапример 1 фура может взять 21 тонну и 89 кубов и вот тебе привозят груз а там 20 кубов весит 1 тонна в этот момент ты не знаешь какую ставку давать в тоннах или в кубах поэтому логисты придумали плотность например для автоперевозок стандарт 1 куб  250 кгна каждый сборный груз в фуре или контейнере делаем предварительную схему погрузки ма называем это поиграть в тетрисесли разделить идеальными кубиками фуру влезет 89 кубиков весом 250 кга если груз меньше куба но тяжелый например станок под 800 кг и тыо здорово у нас в этой партии много легкого груза нам тяжелый надо надо забирать и даешь ставку 150 usd на куб когда обычная ставка 200 usdнапример у тебя уже есть 30 кубов обуви и тебе выгодно продать место под тяжелый груз и тогда и вес и плотность будут хорошими а значит хорошая ставка так экспедитор играется старается подвести под идеальную плотность 1 куб250 кгпо похожей схеме строится все ценообразование в логистике а помимо этого экспедитор должен много всего выяснитьгруз на паллете в коробке что за груз опасный батарейки температурный или нет кто растамаживает кто встречает куда вывозить что с документами на грузчасто игрушки продают без батареек потому что доставка без батарейки  3 доллара а с батарейкой  8 долларова еще надо забрать в китае довезти до аэропорта затаможить вылезет магнитный контроль потому что клиент не знал что стоял вентилятор или редуктор какой а документа нет все это проходишь а тут агент сообщает что самолет загружен и ты уже не влезешь со своим грузом у тебя перенос на следующий рейси клиент звонитты же обещал 4 мая какого черта ну вот тудасюда вот такая ситуацияя звонюребят я столько груза у вас беру мне очень важно чтобы именно 4 мая у ребят было оборудование там госконтракт 5 мая  последний деньи если много возишь тебе и правда идут на встречу когото выкидывают комуто офф лоуд ставят кто редко летает и тебе звонятвсе мы тебя загрузилито есть на объеме можешь и ставку дать дешевле и пропихнуть можешь вперед а когда у клиента большой груз то работает наоборот клиент тоже не дурачок будет тендерить сталкивать лбами то есть ставки озвучивать разным компаниям и кто даст цену ниже тому груз и отдадуту меня тут 5 тонн груза давай будем по ценнику демпинговатьсяно в конце года начинается другое все хотят лететь все перегружено и тебя спрашивают а можешь мне 5 тонн за раз увезти специально для тебя есть цена для всех  19 юаней но если хочешь 5 тонн за раз можем за 25 юаней полететь о супер летиминогда у генеральных агентов недоборы и они звонятдавайте грузов а мы вам спецтарифи тебе дают 12 юаней за кг когда по рынку 18 юаней за кг и ты хопхоп быстро обзвонил клиентов блок спейс сделал заработал работа формата зависит от вашей поддержки чтобы поддержать автора статьи подпишитесь на канал упал поднялсядоходы логистической компаниивсе поступления в кассу распишу на примере 2024 года общие поступления в этом году  453 млн технический импортер  2715 млн если компания с госучастием не может купить товар у китайского завода например изза санкций она ищет себе технического импортера вроде насэто когда какаято компания не покупает напрямую товар в китае а поручает это намвот поставщик возьмите у него мы туда съездили проверили но на тендер напрямую завести не можемосновные причины такого явления  политические ситуации иногда таким образом таможенные риски перекладывают на тебя иногда просто кредитуются через тебя таким образомздесь проблема что кто импортировал тот и несет гарантийные и финансовые обязательстваавиаперевозки  108 млн тут есть 2 варианта1 пассажирскими самолетамиэто когда самолет берет пассажиров и на оставшуюся грузоподъемность берет коммерческие грузы мы называем это  берет под хвостом2 грузовые самолетыкогда самолет предназначен именно для перевозки груза в том числе опасные грузы или большого объема3 авиаконсолидация сервис для доставки небольших грузов от 1 кг до 40 кгжелезная дорога сборный груз  197 млнпроблема этого направление в 2025  не совсем честная конкуренцияв международных перевозках груз должен приехать строго в определенную точку от склада временного хранения свх одной страны к свх другой и не важно как ты едешь морем железной дорогой или автокогда ты везешь сборный груз у тебя в одном контейнере например 10 разных товаров и все они будут таможиться раздельно и если 1 из 10 таможню не пройдет остальные 9 грузов будут его ждатьи вот тут появились склады временного хранение свх ты разделяешь груз и таможишь раздельно если какойто груз не прошел таможню он лежит на складе временного хранения ты платишь за каждый день склада и просто перевыставялешь это клиенту это его риски что у товара возникли проблемы с таможнейно если склад временного хранения не использовать то за все 10 грузов нужно платить за простой и тут грузополучатели у которых было все хорошо с таможней уже тебя не поймут почему это им надо платить за простой если у них все хорошо то есть эти расходы  мои расходы как перевозчикаодин раз мы проводили досмотр несколько дней с 4 сотрудниками от нас и 3 от склада свхтак за неделю можно попасть и на 200 и на 300 000  а перевыставить клиенту за весь груз не можешь потому что он скажеттак размещал бы меня на свх что за делатут фокус в том что таможенный склад или склад временного хранения свх где грузы ждут растаможки  это частная организациясвх  как правило принадлежат частным перевозчикам или являются их дочками и для железной дороги на некоторых станциях попасть на свх со свой сборкой становится проблемой так как нет емкостей свх для принятия твоего груза возникает чтото вроде монополии для своих грузов емкости есть для твоих  нета в среднем по всем направлениям наши комиссионные  715 бывает 30 а бывает и в минус съездишьвыручкав 2024 при выручке в 453 млн  осталось 449 млн  комиссионныха дальше начинаетсярасходы логистической компаниираспишу расходы на примере 2024 года где получилось 449 млн  комиссионных теперь из них нужно вычестьбанковские комиссии  145 млн конвертация и комиссия за переводы  75 млн потому что напрямую в китай не можешь отправитьзарплаты офис за 13 человек  около 145 млн  с налогамилогисты 70100 000  менеджеры по продажам 80120 000  аккаунтменеджер который работает с клиентами 90120 000  служба безопасностиза продавцов конкурировать сложно профессионал охотнее идут в крупные компании где 3 этажа офис и могут давать спецтарифы с помощью которых можно лучше продавать а значит и получать больше комиссионныхв итоге все больше нанимаю людей без опыта в вэд внешнеэкономическая деятельность учу с нуля примерно через полгода человек начинает понимать что тут у нас вообще происходит то есть 34 месяца платишь стипендиюа за 30 000 руб сейчас люди работать не идут по крайней мере в офис на полный деньбухгалтерия после сдачи квартальной отчетности сидела до 4 утра и осталась на работе спатьбухгалтерия телемаркетинг 4060 000 за человека оптимизация сайта помощь с битриксом  аутсорсинг всего 528 млн  за годна рекламу потратили 690 000  обзваниваем базы платим за seo все еще делаем контекстную рекламу в яндексе хотя иногда клик может стоит по 1000  основной канал конечно  сарафани партнерский канал чаще всего таможенный брокер мы оказываем разные услуги и друг другу приводим заказчиковеще внедряем нейросетиобучили их распознавать документы и теперь так можем проводить расчетыитого в 2024 постоянные расходы составили 304 млн сколько зарабатывает логистическая компаниявсего при полученной комиссии в 449 млн  постоянных расходах в 304 млн  и налогах на прибыль в 29 млн  осталось 116 млн  прибыли за 2024 годно это не значит что мы с партнером за год забрали по 58 млн  много денег идет обратно в бизнесты вроде заработал и думаешьвот сейчасто и построю дачку лямов за 12но тут приходит крупный клиент и просит привезти тебе большой груз а крупные платят с отсрочкой и чтобы ты смог им привезти нужны оборотные деньги иногда это заморозка денег на 34 месяца но часть клиента поэтому и обращается к тебе так как свою оборотку морозить не хочетеще когда тебе дают груз на 150 млн к тебе приезжает служба безопасности смотрит твою оборотку потому что тебе не доверят груз если не поймут что смогут с тебя забрать компенсацию поэтому оборотка  это возможность работать с крупными клиентамипоэтому либо живешь здесь и сейчас либо вкладываешься растешь и стабилизируешь бизнес крупные работают с крупными тебе никто не отдаст груз большой стоимостью если с тебя нечего взять взамен ты можешь давать цену выше рынка они таким образом платят за безопасностьиногда думаешь если все посчитать кажется что на депозит под 20 положить будет выгоднее немного прибыль берем но не то чтобы я вывел себе дивиденды прям нам говорят я при таких оборотах ездил бы на лексусе но у нас не такая рентабельностьа еще всегда нужно иметь запас денег на форсмажоры с одной машины заработал 300 000  а с другой потерял 300 000  или попал на миллионфорсмажоры в логистикени разу с 2015 года не помню случая когда отдал груз и пришли деньги всегда какието проблемы самолет сломался машина не зашла с документами накосячили груз разбилидекабрь 2023 китайские новости ту204 заходит на посадку с горящим двигателем в нем в том числе наш груз на пару сотен тысяч долларовавиаперевозки все берут за скорость и на задержки реагируют чувствительноа у тебя самолет стоит в ремонте неделю клиент звонитпочему так долго мы вроде авиаперевозку покупали а не морскуюв логистике ты постоянно на стрессе ой у нас груз не готов оплата не прошла пакет документов не готов груз в китае застрял машина не зашла и в последний момент ее перекупили по другой ценетут всегда чтото происходитпроблемы идуту меня погрузили оборудование за 300 000  в деревянный ящик и погрузчик вилами в аэропортутыдыщя клиенту скидываю фотку он говоритвези но если он заехал в микросхему нам ханамы 2 мес делали потом 3 мес везли эту микросхему из японии на заказ в китай а у нас уже тендер закрывать только это ждем там линия на 200 млн контрактчуть что всех по цепочке будут вылавливать и вот ты сидишь седой звонят2 мм вилка прошла рядом сейчас быстро подрихтуем и сдаемв этот раз пронеслоа бывает не прокатывает везли оборудование говорили сделать деревянный контейнероборудование стоило 250 000  они к заводу завод просит 10 000  за упаковку в деревянный ящик10 000  хотели за такой ящикзаказчики решили что это перебор да так доедет мы не доедем надо делать это не укладывается в цифры которые мы закладывали в перевозкуповезлина складе крановщик начинает подцеплять кран срывается и крюк попадает прямо в сенсорный сименсовский монитор за несколько тыс долларовнет чтобы рядом в металл попал прямо в монитора потом проблема с таможней в итоге груз должен был приехать летом а приехал зимой нападал снег и оборудование уже просто не включилосьвы же сами от упаковки отказалисьно они пошли в суд и нам присудили полную стоимость и так попали на 5 млн на скане договора было что мы отвечаем за упаковку хотя я помню что мы такое не писали оригиналов они не предоставили но суд присудил по сканув итоге такая неблагодарная работа перевозчик косячит  ты платишь клиент косячит  ты платишьавиакомпания застрахована она по международному праву может везти груз 21 день а мыто клиенту обещаем конкретные сроки у меня заявка подписана и меня потом таскают в судысуд спрашивает подтверждение о задержке от авиакомпании мы к авиакомпании а они вообще ни в чем не хотят участвовать говорят идите к генеральным агентамсуд говорит покажите всю цепочку взаимодействия кто с кем работал то есть ты должен весь свой бизнес спалить в суде и ты думаешьда проще уж страховую премию заплатить чем все это палитьеще бывает в понедельник увез груз забронировал место по курсу клиенту выставил а курс бац на 3 рубля за день вырос и всю прибыль что наработал  потерялвот эта фотка года 2 прошло но я до сих пор помню звонок водителя мол вы че в меня грузить собрались я уезжаюхотя груз иногда выглядит и более зловещесейчас все ждут что государство прижмет карго но к слову ждут это все года сколько работаю и смотрим на африку есть ощущение что это направление будет сильно растиспасибо что прочитали получайте и отправляйте грузы а мы вам поможемуже больше года я раз в неделю беру интервью у предпринимателей про реальный бизнес а не этот ваш успешный успехможет показаться что упал поднялся  это весёлые истории о том как пожарить косточки насушить листья склеить картон чтобы заработать миллионы на маркетплейсах но на самом деле в блоге уже больше 50 статей из разных ниш с подробными выкладками по цифрамподписывайтесь на блог упал поднялся  интервью про бизнес
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: contains_keywords
Аргументы: args=('ДИСКЛЕЙМЕР: Статья написана автором блога\xa0на основе интервью с Л. Сулиным, сооснователем логистической компании.По образованию я учитель географии. Что в современном мире привело меня в продажи.Я всегда хотел заниматься бизнесом, но не получалось. Начал, как все мечтают с пассивного дохода и вложился в вендинговые автоматы. Прогорел, начал делать сайты.В 2012 мой знакомый полетел в Китай и решил заняться продажей оборудования. А ко мне пришел, чтобы заказать сайт.Тогда меня поразила мысль, что бизнес может быть глобальным и не ограничен только Россией.– Там же везти надо, таможить ты знаешь как это?– Конечно, нет. Но ничего, разберемся.А когда делаешь сайт, тебе надо подробно расспросить заказчика, что продаешь, как устроен бизнес, и в итоге я так увлекся, что сказал:Я хочу с тобой в этот бизнес.Все русские на фото – это я и мой партнерПосвящается всем, кто везет, разгружает, загружает, оформляет грузы, и, конечно же, всем нам – логистам-экспедиторам.  Бизнес шел, а в 2014 мы попали на курсовой скачок, помните, когда доллар был 37, а потом резко стал 75. А у нас был заказ на гостендер. Мы пошли к заказчикам передоговариваться, но нам сказали:Ребят, раз взялись, уже везите.Тогда потеряли много денег и закрыли бизнес.Транспортная компания с нуляС другом мы уже сработались, был опыт в перевозках из Китая, и мы решили, что можем попробовать себя в качестве транспортной компании. Тогда все возили грузы из Европы, и Китай не был популярным направлением.Отношение к Китаю было:Вот ржавая труба, тут все гнилое, все низкого качества.А мы знали, что европейцы заказывали оборудование в Китае, вешали шильдики и продавали нам в Россию, типо итальянское качество. Я был на производстве и видел все эти заказы в Европу и все те шильдики.Сначала мы решили заняться контейнерными перевозками по морю, и был опыт негабаритных перевозок тралами.Негабаритные грузы – это когда нужно привезти что-то, не укладывающееся в обычные размеры стандартных контейнеров и фур, по весу или размерамМы сделали сайт, запустили контекстную рекламу, и заявки почти сразу пошли. Но заказы были на контейнерную перевозку, а на ней мы особо ничего не зарабатывали. И тут мне позвонил знакомый:Вы же из Китая возите? А можете мне сборный груз привезти?Сборный груз – это когда фуру или контейнер грузят несколько грузов для разных грузополучателей, обычно 7–10 клиентов.Сборные грузы из Китая тогда возили, но «в серую» – через карго.Карго перевозки или каргуха, как мы ее любя называем – это способ доставки грузов, в обход официальной доставки. Для небольших грузов это чаще всего выгоднее, чем официально и не особо сложно – вот тебе ставка за килограмм и погнали.Официальная доставка из-за границыВезем на склад временного хранения (СВХ) в стране отправителя, там оформляем груз для таможенного транзита, перевозим груз, доставляем на склад СВХ в стране назначения, подаем документы для таможенного выпуска товаров, рассчитываем и оплачиваем пошлины, НДС 20%, готовим декларации соответствия, сертификаты на продукцию и т.д. Получаем грузовую таможенную декларацию (ГТД), везем получателю.Карго доставка из-за границыЕсть страны (не будем их называть) где НДС не 20%, а меньше, и пошлины на некоторые товары сильны ниже.Поэтому каргушники везут груз из Китая через третью страну, а оттуда отправляют груз как будто на физлиц в Россию. А чтобы еще и не платить пошлину, например, автозапчасти таможатся как металлические изделия.В 90-е мне рассказывали, что карго просто гоняли через границу за определенную цифру на погранпереходе.Так вот. Если у вас компания с госучастием или госконтракт, вам обязательно надо везти в белую, там слово карго, даже рядом звучать не может. В карго никаких нормальных бумаг вам не дадут.И вот официальной сборной доставки из Китая на рынке почти не было. Если нужно привезти, например, 200 кг обуви все грузили в контейнер и по морю везли во Владивосток или в Питер. А мы нашли нужных китайцев и стали предлагать привести железной дорогой.По морю груз ехал 45-60 дней, еще пока разберут, пока соберут – все 70 дней. А наши поезда доезжали за 30-35 дней. То есть в 2 раза быстрее, а по цене чуть дороже, что было вау. Направление так зашло, что мы просто звонили по базе и когда находили компании, которые возят из Китая, мы говорили у нас есть сборка.Ничего себе, у вас есть официальная сборка?! 30 дней? Конечно, давайте!Так мы набрали пул клиентов и взлетели. Мы попали в промежуток времени, когда спрос есть, а предложения еще было недостаточно. Потом подключили авиадоставку.У рынка появляется осознание, что Китай – это нормально. Когда в 2017 я говорил, что скоро мы будем ходить с Хуавеями и Сяоми, все смеялись.Самсунг – знаю, Эппл – знаю, Хуавей, Сяоми – не слышал.Рынок автозапчастей уже сильно переехал на Китай. Не буду упоминать имена автосалонов, которые массово везли оригинальные японские/американские/корейские запчасти из Китая.Уже тогда было понятно, что Китай, делая по контракту запчасти для европейцев, набирается опыта и рано или поздно он этот опыт переложит дальше на свои машины. И в 2021 я уже говорил, что все будут ездить на китайских автомобилях.В 2018 санкции уже были, но глобально они никого не волновали. Но к нам уже приходили компании из госсектора с запросом купите, пожалуйста, для нас, у нас санкции.И мы начали погружаться в тему доставки санкционных грузов. Когда есть груз, есть заказ, но просто погрузить на самолет ты не можешь. И мы начинаем обрастать контактами в других странах, которые помогают доставлять санкционные товары. В основном нефтегаз.Наши клиенты в основном – заводы и производства.В 2020 случается первый жесткий удар по логистике – пандемия, перекрытие рынка, локдаун, ничего не привезти. Локдаун ломает логистику просто через колено.В 2018 морской контейнер плавал по тарифам за 500-800 долларов за ящик, и перевозчики говорили, что рынок перегрет и за такие ставки везти означает убыток. В ковид цена на тот же самый фрахт взлетает до 8 000 долларов в течение 2 месяцев (в 10 раз).Большинство говорило:Я подожду, я что дурак за 8 000 долларов плыть.А кто-то понял, что это надолго и сказал:Я плыву сейчас, зато у меня будет товарТогда многим было наплевать на цену, вопрос был в другом:Ребят, у вас вообще есть контейнера, вы вывезти сможете?А у нас уже накопились связи, были контакты с контейнерными перевозчиками, у кого были контейнеры на стоке в Китае. И за счет этого сильно выросли.В 2021 наш оборот составил 145 млн ₽.В 2022 локдаун закончился, начинается спецоперация. В логистике случается полное сумасшествие. Мне звонили знакомые знакомых, их дяди и тети.Вы же с Китаем работаете? Мы в Европе, нам надо аналоги, можете купить/привезти?Я тогда отключил всю рекламу, потому что у меня телефон просто не замолкал.В 2022 оборот нашей компании составил 204 млн ₽.Мы и дальше росли по восходящей.Проблемы логистики в 2025Сейчас у нас в логистике происходит следующее.КризисРынок находится в ситуации жесточайшей конкуренции, грузопоток упал. С Нового года мы чувствуем серьезную просадку у всех клиентов, мне честно это напоминает 2018 год, когда была просадка перед локдауном. Ставки упали, появились желающие работать чуть ли не в минус.Китайцы наступаютРаньше китайцы никогда не ползали на наш рынок напрямую, они работали через российские компании. Сейчас, если посмотреть даже по последней выставке 50-60% стендов – это китайцы. Они напрямую открывают свои филиалы.А логистику китайцы хотят делать со своими китайцами, не с русскими.В Америке и Европе китайцы привыкли работать с маленькой комиссией, но на больших объемах. Ту же модель они принесли на российский рынок, но проблема, что у нас не такой большой рынок, чтобы хватало работать в прибыль на 2-3% комиссии.Сколько ни демпингуй, рынок не станет больше, но ценники они всем роняют и всех выжигают. Маленькие компании не выдерживают и просто закрываются.Осталось одно направлениеМногие логистические компании, которые раньше занимались Европой и Америкой, после санкций перешли на Китай, и, конечно, лучше они ничего не придумали, кроме как:А давайте лупанем ценники вниз!Раньше рынок рос, и всем хватало. А сейчас все перестроились на одно направление, а грузопоток упал и так мы оказались даже не в красном, а в бордовом океане.Как открыть логистическую компания с нуляВ логистике есть проблемы курицы или яйца. Пока у тебя нет хороших ставок на перевозку, у тебя нет объема грузов, а пока у тебя нет объема грузов, у тебя нет хороших ставок. Решил эту задачу – молодец, не решил – ты вне игры.Когда мы начинали в 2015, нам понадобилось 100 000 ₽ и телефонная книжка. Раньше ты сел дома, взял телефон, открыл почту, и вот ты уже работник международной логистики. Сейчас из-за дикой конкуренции такое сложно представить.Откуда прибыль в логистикеМногие думают, что логисты – это такие кровопийцы, которые сидят на спине у несчастного перевозчика, сосут кровь и ничего не делают. Вроде риелторов. И многие говорят:А давайте напрямую покупать ставки у перевозчиков.Гуглишь «купить билет Пекин – Москва» и тебе дадут варианты, где можно купить билеты. Эйрчайна, Аэрофлот и др. И ты думаешь: сейчас я зайду на сайт Аэрофлота в раздел грузоперевозки и зачем мне какой-то там экспедитор. Звучит логично.А вот как оно работает на самом деле, если везут груз в пассажирском самолете. Самолет прилетает в аэропорт, и у него есть час-два, чтобы быстренько заправиться, загрузить багаж, пассажиров, грузы и быстро улететь, потому что пока самолет летит в воздухе – он зарабатывает деньги, а пока стоит на земле – он деньги тратит.При этом никто не знает, сколько точно будет пассажиров на каждом рейсе, сколько у них будет багажа, есть только примерные расчеты. И когда регистрация пройдена, авиакомпания сообщает агенту:У нас осталось 8 тонн свободных емкостей, можем взять 8 тонн груза.А к тому времени груз должен быть промаркирован, упакован по правилам: что за груз, что за тип груза, пройдена таможня, оформлены документы и т.д.К моменту погрузки на борт, груз уже должен стоять на перроне. Это фото погрузки во времена ковид, груз грузили прямо в салон вместо пассажиров.Бывает, груз забронирован на 4 мая, груз привозят, он стоит «под хвостом», но пришло много пассажиров и много багажа, и груз не берут, хоть ты его и бронировал. Это называется off load, то есть не влезло и разгрузили. В итоге груз летит только 5 мая.Заниматься всеми этими проблемами с грузами авиакомпания не хочет, и всю подготовку и бронирование мест поручает так называемым GSA – Дженерал сейлз эджент, то есть генеральным агентам по продажам.Таких агентов у авиакомпании несколько и бывает, что 1 самолет выкупает несколько разных агентов. Чтобы точно быть уверенными, что все грузовое место у авиакомпании купят, они используют модель – блок спейс агримент BSA. То есть когда агент вперед платит за определенный объем.Блок спейс – забронировать пространство в самолете.Как если бы риелтор сначала покупал квартиру и только потом бы ее продавал. Дальше генеральный агент распределяет выкупленные емкости между своими агентами: одному 5 тонн, другому 3 и нам 2 тонны, к примеру.Авиакомпания распределяет рейсы между агентами. Кто дает больше грузов, тот и получает больше рейсов (не всегда по самой низкой цене), чем больше грузов, тем лучше цену получает агент. Следовательно, чем больше объем грузов, тем лучше условия можно получить от авиакомпании.Дальше у генеральных агентов появляются помощники-консолидаторы, которые помогают им выкупать этот объем. Здесь они накручивают свои проценты и продают свои 5 тонн груза пятерым крупным помошникам-консолидаторам по 1 тонне. А тарифная сетка напрямую зависит от веса, который агент готов выкупить.Разберу на примере Аэрофлота, рейс – Пекин – Москва.Тот кто купит 45 кг груза – заплатит 45 юаней за 1 кгТот кто купит 100 кг груза – заплатит 26 юаней за 1 кгТот кто купит 300 кг груза – заплатит 23 юаней за 1 кгТот кто купит 500 кг груза – заплатит 21 юаней за 1 кгА тот, кто купит 1 000 кг груза – заплатит 18 юаней за 1 кгЭто тариф генерального агента, он взял себе примерно 5 тонн от 12 до 16 юаней напрямую у авиакомпании и получает свои 20-35% наценки.То есть тот, кто купит у генерального агента место под тонну груза за 18 юаней, сможет перепродать ее десятерым клиентам с объемами по 100 кг за 26 юаней. То есть накрутить свои 45% прибыли.В реальности, конечно, все не так прекрасно и из-за того, что другие игроки тоже хотят перепродать как можно больше, наценка в среднем по рынку – 7-15%. И как минимум тебе нужно поставить ценник дешевле, чем у GSA, потому что за 26 юаней клиент проще сходит напрямую.Отсюда видно, что наиболее выгодно продавать кусочки от 45 до 100 кг. Тогда ты вообще можешь демпингануть, предложить 30-35 юаней (вместо 45) и все равно получить наценку в 70%.Но если ты будешь сильно ломать рынок, тебе могут просто в следующий раз не дать сделать блок спейс, то есть не продать. Скажут, что ты в прошлый раз нам всем бизнес испортил, до свидания.И ты постоянно должен попробовать заработать побольше, но и не злить остальных. И вот ты звонишь клиенту, говоришь хорошую ставку, просишь никому не говорить, что у него такая цена. Ему звонят конкуренты, предлагают, он говорит: а у меня дешевле.И все такие:Как так-то, да нет же таких тарифов!А бывает, что купил 1000 кг, а из них продал только 300 кг, и в итоге поехал в минус. Потому что нельзя просто пообещать, что купишь, надо подписать блок спейс, что каждую неделю берешь объем груза.Поэтому наивно полагать, что компания, у которой есть 100 кг груза, получит цены лучше, чем я, как экспедитор, который ему перепродаю, даже если у меня есть хотя бы тонна груза в неделю.В итоге те, кто берут у генеральных агентов авиакомпании напрямую, получают самую высокую цену, которую можно получить на рынке. Сама авиакомпания вообще не продает грузовые емкости напрямую, только через GSA.Помимо веса на стоимость перевозки влияет объем груза.Например, 1 фура может взять 21 тонну и 89 кубов. И вот тебе привозят груз, а там 20 кубов весит 1 тонна. В этот момент, ты не знаешь, какую ставку давать, в тоннах или в кубах? Поэтому логисты придумали плотность. Например, для автоперевозок стандарт: 1 куб – 250 кг.На каждый сборный груз в фуре или контейнере делаем предварительную схему погрузки. Ма называем это «поиграть в тетрис».Если разделить идеальными кубиками фуру, влезет 89 кубиков весом 250 кг.А если груз меньше куба, но тяжелый, например, станок под 800 кг и ты:О, здорово у нас в этой партии много легкого груза, нам тяжелый надо. Надо забирать и даешь ставку 150 USD на куб, когда обычная ставка 200 USD.Например, у тебя уже есть 30 кубов обуви и тебе выгодно продать место под тяжелый груз и тогда и вес, и плотность будут хорошими, а значит, хорошая ставка. Так экспедитор играется, старается подвести под идеальную плотность 1 куб/250 кгПо похожей схеме строится все ценообразование в логистике. А помимо этого, экспедитор должен много всего выяснить:Груз на паллете, в коробке, что за груз, опасный? Батарейки Температурный или нет? Кто растамаживает, кто встречает? Куда вывозить? Что с документами на груз?Часто игрушки продают без батареек, потому что доставка без батарейки – 3 доллара, а с батарейкой – 8 долларов.А еще надо забрать в Китае, довезти до аэропорта, затаможить, вылезет магнитный контроль, потому что клиент не знал, что стоял вентилятор или редуктор какой, а документа нет. Все это проходишь, а тут агент сообщает, что самолет загружен и ты уже не влезешь со своим грузом, у тебя перенос на следующий рейс.И клиент звонит:Ты же обещал 4 мая какого черта? Ну вот, туда-сюда, вот такая ситуация…Я звоню:Ребят я столько груза у вас беру, мне очень важно, чтобы именно 4 мая у ребят было оборудование, там госконтракт, 5 мая – последний день.И если много возишь тебе и правда идут на встречу, кого-то выкидывают, кому-то офф лоуд ставят, кто редко летает. И тебе звонят:Все мы тебя загрузили!То есть на объеме можешь и ставку дать дешевле и пропихнуть можешь вперед. А когда у клиента большой груз, то работает, наоборот, клиент тоже не дурачок, будет тендерить, сталкивать лбами, то есть ставки озвучивать разным компаниям, и кто даст цену ниже, тому груз и отдадут.У меня тут 5 тонн груза, давай будем по ценнику демпинговаться.Но в конце года начинается другое: все хотят лететь, все перегружено и тебя спрашивают:– А можешь мне 5 тонн за раз увезти?– Специально для тебя есть цена. Для всех – 19 юаней, но если хочешь 5 тонн за раз, можем за 25 юаней полететь.– О супер, летим!Иногда у генеральных агентов недоборы и они звонят:Давайте грузов, а мы вам спецтариф.И тебе дают 12 юаней за кг, когда по рынку 18 юаней за кг, и ты хоп-хоп быстро обзвонил клиентов, блок спейс сделал, заработал.🔔 Работа формата зависит от вашей поддержки, чтобы поддержать автора статьи,\xa0подпишитесь на канал "Упал, поднялся".Доходы логистической компанииВсе поступления в кассу распишу на примере 2024 года. Общие поступления в этом году – 453 млн ₽.Технический импортер – 271,5 млн ₽Если компания с госучастием не может купить товар у Китайского завода, например, из-за санкций, она ищет себе технического импортера, вроде нас.Это когда какая-то компания не покупает напрямую товар в Китае, а поручает это нам.Вот поставщик, возьмите у него. Мы туда съездили, проверили, но на тендер напрямую завести не можем.Основные причины такого явления – политические ситуации. Иногда таким образом таможенные риски перекладывают на тебя, иногда просто кредитуются через тебя таким образом.Здесь проблема, что кто импортировал, тот и несет гарантийные и финансовые обязательства.Авиаперевозки – 108 млн ₽Тут есть 2 варианта:1. Пассажирскими самолетамиЭто когда самолет берет пассажиров и на оставшуюся грузоподъемность берет коммерческие грузы. Мы называем это – берет под хвостом.2. Грузовые самолетыКогда самолет предназначен именно для перевозки груза. В том числе опасные грузы или большого объема.3. Авиаконсолидация -–сервис для доставки небольших грузов от 1 кг до 40 кг.Железная дорога (сборный груз) – 19,7 млнПроблема этого направление в 2025 – не совсем честная конкуренция.В международных перевозках груз должен приехать строго в определенную точку. От склада временного хранения (СВХ) одной страны к СВХ другой, и не важно, как ты едешь морем, железной дорогой или авто.Когда ты везешь сборный груз у тебя в одном контейнере, например, 10 разных товаров и все они будут таможиться раздельно. И если 1 из 10 таможню не пройдет, остальные 9 грузов будут его ждать.И вот тут появились склады временного хранение (СВХ). Ты разделяешь груз и таможишь раздельно. Если какой-то груз не прошел таможню, он лежит на складе временного хранения, ты платишь за каждый день склада, и просто перевыставялешь это клиенту, это его риски, что у товара возникли проблемы с таможней.Но если склад временного хранения не использовать, то за все 10 грузов нужно платить за простой, и тут грузополучатели, у которых было все хорошо с таможней уже тебя не поймут, почему это им надо платить за простой, если у них все хорошо. То есть эти расходы – мои расходы как перевозчика.Один раз мы проводили досмотр несколько дней с 4 сотрудниками от нас и 3 от склада СВХТак за неделю можно попасть и на 200, и на 300 000 ₽. А перевыставить клиенту за весь груз не можешь, потому что он скажет:Так размещал бы меня на СВХ, что за дела?Тут фокус в том, что таможенный склад или склад временного хранения (СВХ), где грузы ждут растаможки – это частная организация.СВХ – как правило принадлежат частным перевозчикам или являются их дочками. И для железной дороги, на некоторых станциях попасть на СВХ со свой сборкой становится проблемой, так как нет емкостей СВХ для принятия твоего груза. Возникает что-то вроде монополии, для своих грузов емкости есть, для твоих – нет.А в среднем по всем направлениям наши комиссионные – 7-15%. Бывает 30%, а бывает и в минус съездишь.ВыручкаВ 2024 при выручке в 453 млн ₽ осталось 44,9 млн ₽ комиссионных.А дальше начинается.Расходы логистической компанииРаспишу расходы на примере 2024 года, где получилось 44,9 млн ₽ комиссионных. Теперь из них нужно вычесть.Банковские комиссии – 1,45 млн ₽Конвертация и комиссия за переводы – 7,5 млн ₽Потому что Напрямую в Китай не можешь отправить.Зарплаты офис за 13 человек – около 14,5 млн ₽ с налогами.Логисты (70–100 000 ₽), менеджеры по продажам (80–120 000 ₽), аккаунт-менеджер, который работает с клиентами (90–120 000 ₽), служба безопасности.За продавцов конкурировать сложно, профессионал охотнее идут в крупные компании, где 3 этажа офис, и могут давать спецтарифы, с помощью которых можно лучше продавать, а значит, и получать больше комиссионных.В итоге все больше нанимаю людей без опыта в ВЭД (внешнеэкономическая деятельность). Учу с нуля, примерно через полгода человек начинает понимать, что тут у нас вообще происходит, то есть 3-4 месяца платишь стипендию.А за 30 000 руб сейчас люди работать не идут. По крайней мере, в офис на полный день.Бухгалтерия после сдачи квартальной отчетности, сидела до 4 утра и осталась на работе спать.Бухгалтерия, телемаркетинг (40–60 000 за человека), оптимизация сайта, помощь с битриксом – аутсорсинг. Всего 5,28 млн ₽ за год.На рекламу потратили 690 000 ₽. Обзваниваем базы, платим за SEO, все еще делаем контекстную рекламу в Яндексе, хотя иногда клик может стоит по 1000 ₽. Основной канал, конечно – сарафан.И партнерский канал, чаще всего таможенный брокер. Мы оказываем разные услуги и друг другу приводим заказчиков.Еще внедряем нейросети.Обучили их распознавать документы и теперь так можем проводить расчетыИтого в 2024 постоянные расходы составили 30,4 млн ₽.Сколько зарабатывает логистическая компания?Всего при полученной комиссии в 44,9 млн ₽, постоянных расходах в 30,4 млн ₽, и налогах на прибыль в 2,9 млн ₽ осталось 11,6 млн ₽ прибыли за 2024 год.Но это не значит, что мы с партнером за год забрали по 5,8 млн ₽. Много денег идет обратно в бизнес.Ты вроде заработал и думаешь:Вот сейчас-то и построю дачку лямов за 12.Но тут приходит крупный клиент и просит привезти тебе большой груз. А крупные платят с отсрочкой, и чтобы ты смог им привезти, нужны оборотные деньги. Иногда это заморозка денег на 3-4 месяца. Но часть клиента поэтому и обращается к тебе, так как свою оборотку морозить не хочет.Еще когда тебе дают груз на 150 млн, к тебе приезжает служба безопасности, смотрит твою оборотку, потому что тебе не доверят груз, если не поймут, что смогут с тебя забрать компенсацию. Поэтому оборотка – это возможность работать с крупными клиентами.Поэтому либо живешь здесь и сейчас, либо вкладываешься, растешь и стабилизируешь бизнес. Крупные работают с крупными, тебе никто не отдаст груз большой стоимостью, если с тебя нечего взять. Взамен ты можешь давать цену выше рынка. Они таким образом платят за безопасность.Иногда думаешь, если все посчитать, кажется, что на депозит под 20% положить будет выгоднее. Немного прибыль берем, но не то чтобы я вывел себе дивиденды прям. Нам говорят: я при таких оборотах ездил бы на лексусе, но у нас не такая рентабельность.А еще всегда нужно иметь запас денег на форс-мажоры. С одной машины заработал 300 000 ₽, а с другой потерял 300 000 ₽ или попал на миллион.Форс-мажоры в логистикеНи разу с 2015 года не помню случая, когда отдал груз и пришли деньги. Всегда какие-то проблемы. Самолет сломался, машина не зашла, с документами накосячили, груз разбили.Декабрь 2023, китайские новости: ту-204 заходит на посадку с горящим двигателем... В нем в том числе наш груз на пару сотен тысяч долларов.Авиаперевозки все берут за скорость и на задержки реагируют чувствительно.А у тебя самолет стоит в ремонте неделю, клиент звонит:Почему так долго? Мы вроде авиаперевозку покупали, а не морскую.В логистике ты постоянно на стрессе.– ой, у нас груз не готов– оплата не прошла– пакет документов не готов– груз в Китае застрял– машина не зашла, и в последний момент ее перекупили по другой ценеТут всегда что-то происходит.Проблемы идутУ меня погрузили оборудование за 300 000 $ в деревянный ящик и погрузчик вилами в аэропортуТыдыщ!Я клиенту скидываю фотку, он говорит:Вези, но если он заехал в микросхему, нам хана.Мы 2 мес делали, потом 3 мес везли эту микросхему из Японии на заказ в Китай, а у нас уже тендер закрывать, только это ждем, там линия на 200 млн контракт.Чуть что всех по цепочке будут вылавливать. И вот ты сидишь седой, звонят:2 мм вилка прошла рядом, сейчас быстро подрихтуем и сдаем!В этот раз пронесло.А бывает не прокатывает. Везли оборудование, говорили сделать деревянный контейнер.Оборудование стоило 250 000 $. Они к заводу, завод просит 10 000 $ за упаковку в деревянный ящик.10 000 $ хотели за такой ящикЗаказчики решили, что это перебор.– Да так доедет– Мы не доедем, надо делать.– Это не укладывается в цифры, которые мы закладывали в перевозку.Повезли.На складе крановщик начинает подцеплять, кран срывается, и крюк попадает прямо в сенсорный сименсовский монитор за несколько тыс долларов.Нет чтобы рядом в металл, попал прямо в монитор.А потом проблема с таможней, в итоге груз должен был приехать летом, а приехал зимой, нападал снег, и оборудование уже просто не включилось.Вы же сами от упаковки отказались.Но они пошли в суд и нам присудили полную стоимость и так попали на 5 млн. На скане договора было, что мы отвечаем за упаковку, хотя я помню, что мы такое не писали, оригиналов они не предоставили, но суд присудил по скану.В итоге такая неблагодарная работа: перевозчик косячит – ты платишь, клиент косячит – ты платишь.Авиакомпания застрахована, она по международному праву может везти груз 21 день, а мы-то клиенту обещаем конкретные сроки, у меня заявка подписана, и меня потом таскают в суды.Суд спрашивает подтверждение о задержке от авиакомпании, мы к авиакомпании, а они вообще ни в чем не хотят участвовать, говорят идите к генеральным агентам.Суд говорит: покажите всю цепочку взаимодействия, кто с кем работал. То есть ты должен весь свой бизнес спалить в суде, и ты думаешь:Да проще уж страховую премию заплатить, чем все это палить.Еще бывает в понедельник увез груз, забронировал место, по курсу клиенту выставил, а курс бац, на 3 рубля за день вырос и всю прибыль, что наработал – потерял.Вот эта фотка года 2 прошло, но я до сих пор помню звонок водителя... Мол, вы че в меня грузить собрались. Я уезжаю.Хотя груз иногда выглядит и более зловещеСейчас все ждут, что государство прижмет карго, но к слову ждут это все года, сколько работаю. И смотрим на Африку, есть ощущение, что это направление будет сильно расти.Спасибо, что прочитали, получайте и отправляйте грузы, а мы вам поможем.Уже больше года я раз в неделю беру интервью у предпринимателей про реальный бизнес, а не этот ваш успешный успех.Может показаться, что\xa0«Упал, поднялся»\xa0– это весёлые истории о том, как пожарить косточки, насушить листья, склеить картон, чтобы заработать миллионы на маркетплейсах. Но на самом деле в блоге уже больше 50 статей из разных ниш с подробными выкладками по цифрам.Подписывайтесь на блог «Упал, поднялся – интервью про бизнес».', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('На входе аудио, на выходе — саммари. Собираем локальный транскрибатор из бесплатного софта',), kwargs={}
Результат: на входе аудио на выходе  саммари собираем локальный транскрибатор из бесплатного софта
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: contains_keywords
Аргументы: args=('На входе аудио, на выходе — саммари. Собираем локальный транскрибатор из бесплатного софта', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:18 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('Всем привет! Меня зовут Николай Луняка, и я, как\xa0и многие из\xa0вас, ежедневно утопаю в\xa0потоке информации. Количество аудиоконтента растёт в\xa0геометрической прогрессии, при\xa0этом его нужно ещё «переварить» и зафиксировать. Интереснейшие лекции хочется сохранить не\xa0только в\xa0памяти, но\xa0и в\xa0виде тезисов, а\xa0ещё есть подкасты, интервью, да\xa0и банальные голосовые заметки, надиктованные на\xa0бегу. Знакомая картина?На\xa0помощь приходят облачные сервисы: транскрибация, саммаризация, диаризация — чуть\xa0ли не\xa0кофе в\xa0постель приносят. Удобно? Без\xa0сомнения. Как\xa0у любого хорошего решения, у\xa0облачных сервисов есть оборотная сторона:Приватность: куда на\xa0самом деле уходят мои данные? Кто их видит, как\xa0использует, и не\xa0всплывут\xa0ли мои приватные обсуждения там, где не\xa0надо? А\xa0если речь идёт о\xa0чувствительной информации? Использовать облачные сервисы в\xa0рабочем процессе опять\xa0же сложно из‑за NDA.Подписки. Для\xa0расшифровки приходится использовать несколько сервисов. Большинство из\xa0них платные\xa0— из\xa0ежемесячного бюджета набегает ощутимая сумма. При\xa0больших объёмах записей ценник становится соответствующим, зачастую кусачим. Зависимость от\xa0интернета. Куда без\xa0него в\xa0нашем «облачном» мире? Нет сети\xa0— нет обработки.Однажды я устал расшифровывать аудио пачкой инструментов в духе «Балерино-Капучино и Бобрито-Бандито» и решил собрать свой пайплайн.Дальше покажу мой вариант решения всех этих проблем\xa0— свой собственный уголок AI‑независимости, где аудиоданные в\xa0полной безопасности под\xa0моим неусыпным контролем. Для\xa0начала расскажу, какие инструменты показались мне наиболее подходящими. 1. Whisper: локальной магией из аудиофайла получаем текстНачнём с Whisper\xa0— модели распознавания речи от\xa0OpenAI в\xa0open‑source\xa0— готовый инструмент, не\xa0сырая демка, да\xa0ещё и бесплатная (ну, почти\xa0— электричество‑то компьютер кушает).Почему Whisper? Мои аргументы:Точность транскрибирования, близкая к\xa0идеалу, даже в\xa0версии tiny: из\xa0всего, что\xa0я пробовал локально, Whisper показывает, пожалуй, лучший результат. Особенно на\xa0английском, но\xa0и с\xa0русским справляется на\xa0ура. Меньше ошибок\xa0— меньше править руками.Многоязычность: он «всеядный», и даже сам пытается определить, на\xa0каком языке ему подсунули запись. Удобно!Не\xa0боится трудностей: шумы, акценты, не\xa0лучшая дикция\xa0— Whisper старается вытащить смысл, и часто успешно.Сам расставит точки и запятые (ну, почти). Пунктуацию и какое‑никакое форматирование он делает, и это сильно облегчает жизнь.Главный аргумент\xa0— работает локально. Никаких «отправьте нам ваше аудио».Под\xa0любые ресурсы и мощности вашего ПК: Модельки от\xa0крошечной «tiny» до\xa0монструозной «large» можно подобрать под\xa0своё\xa0железо. Я обычно целюсь в «large‑v3» для\xa0качества, если время позволяет.В\xa0общем, Whisper\xa0— наш надёжный поставщик текста из\xa0аудио. 2. NeMo: разложим по полочкам кто что сказалТекст мы получили. Но\xa0если это запись встречи на\xa0пять человек, как\xa0понять, где чья реплика? На\xa0помощь приходит NVIDIA NeMo. Это целый фреймворк для\xa0разговорного AI, но\xa0нас интересует конкретная фича\xa0— диаризация спикеров. NeMo пытается понять, сколько людей говорило и какие куски текста принадлежат каждому из\xa0них.Чем хорош NeMo для\xa0этой задачи:Различает голоса довольно неплохо, даже если кто‑то кого‑то перебивал, NeMo старается разобраться. Не\xa0всегда идеально, но\xa0часто очень помогает.Можно подкрутить, есть возможность тонкой настройки, если вы готовы в\xa0это погрузиться.За\xa0ним стоит NVIDIA, а\xa0это значит, проект живой, развивается, есть поддержка.3. Ollama: доступный мост к языковым моделям разных версийИтак, у\xa0нас есть текст, возможно, даже с\xa0разметкой по\xa0спикерам. Что\xa0дальше? А\xa0дальше хочется, чтобы кто‑то прочитал эту портянку текста и кратко выдал суть. Здесь в\xa0игру вступают большие языковые модели (LLM). Но\xa0запускать их локально\xa0— та ещё задачка...\xa0была, пока не\xa0появился Ollama.Ollama\xa0— спасение для\xa0тех, кто хочет подружиться с\xa0LLM:Простота: установить и запустить модель\xa0— буквально пара команд в\xa0терминале. Никаких танцев с\xa0бубном вокруг зависимостей (ну, почти).Поддерживает кучу популярных инструментов\xa0— Llama, Mistral, Gemma.Приватность\xa0— всё крутится локально.Есть API\xa0— скрипты или\xa0плагины могут легко общаться с\xa0моделью.Ollama\xa0— удобная «пусковая площадка» для\xa0Gemma, которая и будет заниматься погруженным анализом текста.4. Gemma 27B: кратко, по делу и по пунктам раскладываем текстGemma\xa0— это семейство моделей от\xa0Google, при\xa0том открытое, что\xa0не\xa0может не\xa0радовать. Есть разные размеры, я проводил эксперименты на\xa0Gemma 27B (27\xa0миллиардов параметров\xa0— звучит солидно). Хочется качественного анализа. Если у\xa0вас не\xa0тянет\xa0железо или\xa0меньше ресурсов, можно использовать модели, где параметров поменьше.Что\xa0мне нравится в\xa0Gemma (когда она работает через Ollama):Хоть это не\xa0гигант вроде GPT-4\xa0с 1,8\xa0триллионов параметров, Gemma 27B вполне достойно справляется с\xa0генерацией и пониманием текста. Для\xa0саммари\xa0— то, что\xa0доктор прописал.Модельки Gemma неплохо оптимизированы для\xa0запуска на\xa0обычном (относительно мощном)\xa0железе. Интересная особенность Ollama\xa0— она подсовывает квантованные версии (это когда модель «ужимают» для\xa0скорости, не\xa0критично теряя в\xa0точности).Открытость\xa0— больше людей пользуется и даёт обратную связь, система\xa0быстрее развивается.Обучена на\xa0многих языках, так что\xa0с\xa0нашими «великим и могучим» проблем\xa0быть не\xa0должно.5. Obsidian: цифровой мозг, куда всё стекаетсяКуда\xa0же мы будем складывать наши сокровища\xa0— транскрипты, диалоги, саммари? Я для\xa0себя выбрал Obsidian — не\xa0просто заметочник, а\xa0целая система управления знаниями. И самое главное\xa0— он работает с\xa0локальными файлами в\xa0Markdown.Почему Obsidian\xa0— идеальный финальный аккорд:Все заметки лежат в\xa0папке на\xa0моем компьютере. Стоп паранойя.Markdown\xa0— это просто и удобно: легко писать, читать и переносить куда угодно.Плагины\xa0— их тысячи! Вот где настоящая магия. Можно настроить Obsidian так, как\xa0тебе удобно, интегрировать с\xa0чем угодно. В\xa0нашем случае\xa0— автоматизировать сохранение результатов обработки аудио.Можно связывать заметки друг с\xa0другом, строить целые карты знаний. Отчёт по\xa0встрече легко связывается с\xa0проектом, задачами, мыслями.Внешний вид, горячие клавиши\xa0— всё можно кастомизировать.Obsidian для\xa0меня\xa0— не\xa0просто хранилище, а\xa0активный инструмент. Сюда будут складироваться результаты работы нашего AI‑комбайна, отсюда\xa0же мы будем работать с\xa0ними дальше.Вот такая команда сервисов у\xa0нас собралась в\xa0пайплайн. Каждый со своей ролью, но\xa0вместе они\xa0— сила.Как заставить этот оркестр играть слаженно: путь от аудиозаписи до осмысленной заметки в ObsidianС\xa0нашими чудо‑инструментами мы более‑менее разобрались. Наступает самый ответственный момент: как\xa0эти разрозненные компоненты соединить в\xa0единый, слаженно работающий конвейер? Как\xa0превратить аудиофайл в\xa0информационную конфетку\xa0— структурированную, осмысленную и готовую к\xa0употреблению заметку в\xa0Obsidian? Давайте пройдёмся по\xa0шагам этого увлекательного процесса, как\xa0его реализую я.Шаг 1: Готовим «сырьё» – наш драгоценный аудиофайлОбычно приложения типа Zoom или\xa0Контур.Толк предупреждают юзеров о\xa0записи аудио. Но\xa0хороший тон\xa0— предупредить собеседников, что\xa0вы записываете созвон.Всё начинается, как\xa0нетрудно догадаться, с\xa0аудио. Я\xa0лично стараюсь использовать формат.wav или.flac\xa0— исторически сложилось, что\xa0Whisper с\xa0ними дружит особенно хорошо, да\xa0и меньше шансов нарваться на\xa0неожиданные сюрпризы с\xa0экзотическими кодеками. Тем не\xa0менее, Whisper довольно «всеяден» и с\xa0удовольствием «скушает» и MP3, и M4A, и многие другие популярные форматы. Главное, чтобы сама запись\xa0была более‑менее приличного качества. Если у\xa0вас, скажем, стереозапись со встречи, где разные участники\xa0были записаны на\xa0разные каналы\xa0— вообще шикарный вариант, NeMo потом скажет вам отдельное спасибо. Но\xa0и с\xa0обычной моно‑записью вполне можно жить и получать достойные результаты. Дополнительно можно убрать длинные паузы (тишину) и попробовать улучшить качество записи при\xa0помощи библиотеки ffmpeg:cmd = [\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"ffmpeg",\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-i", str(input_path), \xa0 # входной файл\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-ac", "1",\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 # преобразовать звук в моно (1 канал)\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-ar", "16000",\xa0 \xa0 \xa0 \xa0 \xa0 # понизить частоту 16 кГц\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-af", \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 "silenceremove=start_periods=1:start_silence=0.3:start_threshold=-35dB:\\\ndetection=peak",\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 # фильтр для удаления пауз\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0str(output_path)\n\xa0\xa0\xa0]Я использую следующие фильтры:start_periods=1 # реагирует на 1ю возникшую паузу\nstart_silence=0.3 # пауза считается значимой, если длится дольше 0.3 сек\nstart_threshold=-35dB # всё тише −35\u202fдБ считается тишиной\ndetection=peak # на основе пикового сигнала в аудиоШаг 2: Whisper, на выход! Превращаем голос в буквы, или Магия транскрибацииПервым делом мы «скармливаем» наш аудиофайл Whisper. Я обычно использую модель «large‑v3» для\xa0русского языка, если нужна максимальная точность и есть немного времени подождать. Если\xa0же ситуация «горит» и результат нужен «ещё вчера»\xa0— можно взять модель «medium». Whisper немного попыхтит, проанализирует аудиодорожку и выдаст текстовый файл. И что\xa0особенно приятно\xa0— уже с\xa0запятыми, точками, а\xa0иногда даже с\xa0попытками разбить текст на\xa0абзацы. Красота, да\xa0и только!Как\xa0это может выглядеть в\xa0консоли (очень упрощённый пример):bash\nwhisper vstrecha.wav --model large-v3 --language ru --output_format txtНа\xa0выходе мы получаем, например, файл «vstrecha.txt»\xa0— с\xa0ним можно работать дальше.Лайфхак: если у\xa0вас есть хорошая видеокарта с\xa0поддержкой RTX, для\xa0транскрибации можно использовать GPU.Мой скрипт: # Аргументы командной строки\n \xa0 p = argparse.ArgumentParser()\n# Обязательный аргумент -- путь к файлу.\n \xa0 p.add_argument("path", help="Аудио‑ или видеофайл")\n\xa0 \n# Необязательный аргумент --lang, по умолчанию -- русский.\n \xa0 p.add_argument("--lang", default="ru")\n\xa0 \n# Параметр случайности (температура) для модели, влияет на вариативность результатов.\'\'\'\n \xa0 p.add_argument("--temperature", type=float, default=0)\n\xa0 \n# Размер beam search (если используется), влияет на точность/варианты распознавания.\n \xa0 p.add_argument("--beam_size", type=int)\n\xa0 \n# Булев флаг: использовать ли предыдущий текст как контекст при распознавании.\n \xa0 p.add_argument("--condition", action="store_true",\n\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 help="condition_on_previous_text")\n\xa0 \n# Необязательный текстовый ввод -- вводная для модели (можно подсказать контекст/темы).\n \xa0 p.add_argument("--prompt", default="",\n\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 help="Вводная: тема, участники, термины...")\n\xa0 \n# Парсит все аргументы из командной строки в объект args.\n \xa0 args = p.parse_args()\n\n \xa0 if not os.path.isfile(args.path):\n \xa0 \xa0 \xa0 raise SystemExit(f"Файл не найден: {args.path}")\n\xa0 \n# Проверяет, доступна ли видеокарта CUDA (GPU). Если нет -- используется CPU.\n \xa0 device = "cuda" if torch.cuda.is_available() else "cpu"\n\xa0 \n# Выводит на каком устройстве будет происходить транскрипция. \xa0 \n \xa0 print(f"Устройство: {device.upper()} --",\n \xa0 \xa0 \xa0 \xa0 torch.cuda.get_device_name(0) if device == "cuda" else "CPU")\n\xa0 \n# Загружает модель large-v3 на выбранное устройство (GPU или CPU).\n \xa0 model = whisper.load_model("large-v3", device=device)\n\n# Сообщение о старте и начало отсчёта времени.\n \xa0 print("Транскрибирование...")\n \xa0 t0 = time.time()\n \xa0 result = model.transcribe(\n \xa0 \xa0 \xa0 args.path,\n \xa0 \xa0 \xa0 language=args.lang,\n \xa0 \xa0 \xa0 temperature=args.temperature,\n \xa0 \xa0 \xa0 beam_size=args.beam_size,\n \xa0 \xa0 \xa0 condition_on_previous_text=args.condition,\n \xa0 \xa0 \xa0 initial_prompt=args.prompt or None \xa0 \n \xa0 )\n\xa0 \n# Показывает, сколько времени заняла транскрипция.\n \xa0 print(f"{round(time.time()-t0,2)} с")\n\xa0 \n# Сохранение результата в JSON и TXT\n \xa0 base = os.path.splitext(args.path)[0]\n \xa0 with open(base + ".json", "w", encoding="utf-8") as f:\n \xa0 \xa0 \xa0 json.dump(result["segments"], f, ensure_ascii=False, indent=2)\n \xa0 with open(base + ".txt", "w", encoding="utf-8") as f:\n \xa0 \xa0 \xa0 f.write(result["text"])\n \xa0 print("Сохранено:", base + ".json / .txt")Шаг 3: NeMo, помоги разобраться, кто есть кто! Искусство диаризацииПросто текст\xa0— конечно, хорошо, но\xa0если это\xa0была запись оживлённой беседы нескольких человек, без\xa0чёткого понимания, кто и что\xa0сказал, далеко не\xa0уедешь. Тут в\xa0дело вступает NeMo с\xa0функцией диаризации спикеров. Он снова «слушает» исходный аудиофайл и, опираясь на\xa0временные метки (которые Whisper тоже может любезно предоставить, если попросить его выдать результат в\xa0формате SRT или\xa0VTT), пытается аккуратно «нарезать» общую речь на\xa0отдельные кусочки и присвоить каждому уникальную метку: «Спикер_0», «Спикер_1», «Спикер_2» и\xa0т.\xa0д.NVIDIA рекомендует выполнять установку через pip install nemo_toolkit["all"]. Иногда могут возникнуть нюансы с\xa0зависимостями, так что\xa0внимательно читайте сообщения в\xa0консоли при\xa0установке. Официальная документация NeMo\xa0— ваш лучший друг.Сразу предупрежу: для\xa0дальнейшей работы и настройки это, как\xa0правило, не\xa0одна простая команда в\xa0консоли. Здесь потребуется небольшой скрипт на Python, который будет управлять работой NeMo, загружать модели (например, «titanet_large» для\xa0получения эмбеддингов голоса и «msdd_vad» или\xa0аналогичную для\xa0кластеризации сегментов). Результат определённо того стоит: вместо сплошного, неразборчивого потока текста мы получаем нечто гораздо более осмысленное, например:[Спикер_0]: Привет, команда! Какие у\xa0нас сегодня новости по\xa0проекту «Смарт»?[Спикер_1]: Привет! В\xa0целом, всё идет по\xa0плану, но\xa0есть пара нюансов, которые хотелось\xa0бы обсудить...Уже гораздо понятнее и информативнее, не\xa0правда\xa0ли?# Чтение аудио и извлечение эмбеддингов\nwav, sr = librosa.load(wav_path, sr=16000, mono=True)\nembs, stamps = extract_embeddings(wav, sr, model)\n\n# Автокластеризация спикеров по эмбеддингам\nlabels = auto_cluster(embs, max_k=max_k)\nspk_cnt = len(set(labels))\ndiar = merge_segments(stamps, labels)\n\n# Мерж с расшифровкой Whisper\nwith open(whisper_json, encoding="utf-8") as f:\n \xa0 whisper_segs = json.load(f)\n\ntagged = []\nfor seg in whisper_segs:\n \xa0 spk = next(\n \xa0 \xa0 \xa0 (f"Speaker{d[\'spk\'] + 1}" for d in diar\n\xa0 \xa0 \xa0 \xa0 if not (seg[\'end\'] <= d[\'s\'] or seg[\'start\'] >= d[\'e\'])),\n \xa0 \xa0 \xa0 "Unknown"\n \xa0 )\n \xa0 tagged.append({**seg, "speaker": spk})\n\n# Сохраняем результат\nout_path = Path(whisper_json).with_stem(Path(whisper_json).stem + "_tagged")\nwith open(out_path, "w", encoding="utf-8") as f:\n \xa0 json.dump(tagged, f, ensure_ascii=False, indent=2)Я использую следующий флоу: загружаю модель >> извлекает эмбеддинги (числовые данные, которые позволяют понять количество спикеров) >> кластеризует на\xa0группы говорящих >> сливает последовательные сегменты одного спикера >> сопоставляет с\xa0полученными данными на\xa0предыдущем шаге >> для\xa0каждого сегмента определяет, в\xa0какой диаризационный диапазон он попадает, присваивает спикера.Шаг 4: Gemma, твой звёдный час! Делаем умное и структурированное саммариПеред запуском локального LLM‑сервер через Ollama обязательно нужно активировать модель:ollama run gemma3:27bТеперь, когда у\xa0нас есть практически идеальный диаризованный транскрипт, время задействовать тяжёлую артиллерию\xa0— Gemma 27B, запущенную и управляемую через Ollama. Наша задача на\xa0этом этапе\xa0— «скормить» ей полученный текст и вежливо, но\xa0настойчиво попросить сделать качественную выжимку: о\xa0чём говорили, к\xa0каким выводам пришли, что\xa0решили, какие задачи поставили и на\xa0кого их повесили.Здесь важную роль играет правильно составленный запрос к\xa0модели. Я формулирую промпт примерно так:«Ты мой эффективный AI‑ассистент по\xa0анализу стенограмм совещаний и лекций. Вот тебе текст разговора нескольких людей. Сделай из\xa0него структурированное саммари на\xa0русском языке. В\xa0саммари обязательно выдели следующие пункты (можно использовать маркированные списки):1. Основные обсуждавшиеся темы или\xa0вопросы.2. Ключевые аргументы, предложения или\xa0идеи, высказанные участниками (если\xa0были).3. Принятые решения (если таковые\xa0были).4. Поставленные задачи с\xa0указанием ответственных\xa0лиц (если это можно однозначно понять из\xa0текста).5. Главные выводы или\xa0итоги обсуждения».Ollama отправляет этот промпт вместе с\xa0текстом нашей Gemma, и она, немного подумав (время и скорость обработки зависит от\xa0выбранной модели и вашего\xa0железа), выдаёт готовое саммари. Настоящая AI‑магия в\xa0действии!# Ключевые настройки скрипта\n\n--model - имя локальной LLM-модели в Ollama (“gemma:27b”, “llama3:8b”...) \n--no-stream - отключает потоковую генерацию (по умолчанию - включена) \n--timeout - ограничивает время ожидания ответа \nmax_chars - ограничивает длину текста для LLM (по умолчанию 15 000) \nsystem_prompt - инструкция для модели (как структурировать Markdown-резюме) \nВходной файл должен быть в формате JSON: `[{ “speaker”: “...”, “text”: “...”, “start”: ..., “end”: ... }, ...]Шаг 5: Все дороги ведут в Obsidian. Наводим порядок, систематизируем и пользуемся результатамиИ вот он, долгожданный финал нашего увлекательного путешествия. Собираем все наши артефакты: исходный «сырой» транскрипт от\xa0Whisper, диаризованный текст от\xa0NeMo, блестящее саммари от\xa0Gemma\xa0— и аккуратно, с\xa0любовью укладываем это богатство в\xa0наше хранилище Obsidian. Как\xa0это сделать? Вариантов масса:1. Старым дедовским способом\xa0— руками: скопировал\xa0— вставил. Долго, муторно, неэффективно, и вообще не\xa0наш метод, если мы говорим о\xa0регулярных задачах и автоматизации.2. Магия скриптов\xa0— наш выбор. Пишем небольшой (или большой, в\xa0зависимости от\xa0ваших амбиций) скрипт на\xa0Python, который будет выполнять все предыдущие шаги по\xa0очереди, а\xa0затем самостоятельно создавать новую заметку в\xa0Obsidian, правильно её называть (например, по\xa0дате и теме встречи или\xa0по\xa0имени исходного аудиофайла), добавлять теги, вставлять саммари, диаризованный транскрипт, а\xa0может, даже ссылку на\xa0исходный аудиофайл. В\xa0общем полный автомат, мечта любого лентяя (в хорошем смысле этого слова).3. Плагины Obsidian: расширяем горизонты. Тут тоже есть где разгуляться творческой мысли. Можно использовать плагин Obsidian Shell Commands для\xa0запуска Python‑скрипта прямо из\xa0интерфейса Obsidian или\xa0плагин Templater для\xa0создания новых заметок по\xa0заранее подготовленному красивому шаблону, куда будут автоматически подставляться все наши данные.Как\xa0может выглядеть итоговая заметка в\xa0Obsidian (мой\xa0личный вариант, который я постоянно дорабатываю)Так шаг за\xa0шагом из\xa0непонятного и объёмного аудиофайла мы получаем структурированную осмысленную информацию, с\xa0которой можно работать, по\xa0тексту которой можно искать, которой можно делиться с\xa0коллегами, и просто чувствовать себя настоящим молодцом, победившим информационный хаос. Удобно обернуть всё это дело в\xa0простенький GUI, как\xa0у\xa0меня и вышло:import os\nimport subprocess\n\ndef run_pipeline(filepath, use_clean=True, do_summary=True, temperature="0", beam_size=None, condition=False, prompt=""):\n \xa0 if not filepath or not os.path.exists(filepath):\n \xa0 \xa0 \xa0 raise FileNotFoundError(f"Файл не найден: {filepath}")\n\n \xa0 base_name = os.path.splitext(filepath)[0]\n \xa0 cleaned_file = base_name + "_cleaned.wav"\n \xa0 audio_file = cleaned_file if use_clean else filepath\n\n \xa0 # Шаг 1: Очистка аудио (опционально)\n \xa0 if use_clean:\n \xa0 \xa0 \xa0 subprocess.run(["python", "clean_audio.py", filepath])\n\n \xa0 # Шаг 2: Транскрипция Whisper\n \xa0 cmd = [\n \xa0 \xa0 \xa0 "python", "transcribe.py",\n \xa0 \xa0 \xa0 audio_file,\n \xa0 \xa0 \xa0 "--lang", "ru",\n \xa0 \xa0 \xa0 "--temperature", temperature,\n \xa0 ]\n \xa0 if beam_size:\n \xa0 \xa0 \xa0 cmd += ["--beam_size", str(beam_size)]\n \xa0 if condition:\n \xa0 \xa0 \xa0 cmd.append("--condition")\n \xa0 if prompt:\n \xa0 \xa0 \xa0 cmd += ["--prompt", prompt]\n \xa0 subprocess.run(cmd)\n\n \xa0 # Шаг 3: Диаризация NeMo\n \xa0 json_file = os.path.splitext(audio_file)[0] + ".json"\n \xa0 subprocess.run(["python", "diarize_nemo_auto.py", audio_file, json_file, "12"])\n\n \xa0 # Шаг 4: Конвертация в TXT / MD\n \xa0 tagged_json = os.path.splitext(audio_file)[0] + "_tagged.json"\n \xa0 if os.path.exists(tagged_json):\n \xa0 \xa0 \xa0 from convert_tagged_json_to_txt_md import convert_tagged_json_to_txt_md\n \xa0 \xa0 \xa0 convert_tagged_json_to_txt_md(tagged_json)\n\n \xa0 # Шаг 5: Генерация саммари (опционально)\n \xa0 if do_summary:\n \xa0 \xa0 \xa0 subprocess.run(["python", "summarize_json.py", tagged_json])Как\xa0вам такой подход? А что у других? Сравниваем наш “самосбор” с готовыми решениями, облачными и не оченьЗачем мудрить, если есть облачные гиганты и их свита?Google Speech‑to‑Text, AWS Transcribe, Azure Speech Services, Yandex SpeechKit, AssemblyAI, Otter.ai, Sonix.ai, Fireflies.ai и многие другие ребята, конечно, молодцы. У\xa0них, как\xa0правило, всё очень просто,\xa0быстро, удобно и часто весьма качественно.Чем готовые решения объективно круче:Простота: зарегистрировался, получил API‑ключ (или просто загрузил файл через веб‑интерфейс)\xa0— и через несколько минут получил результат. Никаких сложных установок, настроек зависимостей и чтения многостраничных мануалов.Скорость и масштабируемость: у\xa0этих компаний в\xa0распоряжении дата‑центры с\xa0тысячами мощных серверов. Они способны переваривать огромные объёмы аудио очень и очень\xa0быстро. Если вам нужно обработать терабайты записей в\xa0сжатые сроки\xa0— облака, скорее всего, ваш выбор.Дополнительные «фичи» и «плюшки»: часто облачные сервисы предлагают набор допов\xa0— автоматический анализ тональности речи, выделение ключевых слов и тем, определение эмоций, интеграции с\xa0популярными сервисами (CRM, таск‑менеджеры и\xa0т.\xa0д.).Где облачные сервисы однозначно проигрывают локальному стеку:Деньги, деньги, дребеденьги: практически все облачные сервисы работают по\xa0подписке или\xa0тарифицируют каждую обработанную минуту аудио (или каждый распознанный символ). Если вы пользуетесь их услугами регулярно и в\xa0больших объемах, ежемесячные счета набегают весьма приличные.Мои драгоценные данные у «дяди Сэма» (или у\xa0кого‑то ещё): вопрос конфиденциальности и безопасности данных стоит очень остро. Вы доверяете свои, возможно, очень чувствительные аудиозаписи третьей стороне. Не\xa0всегда хочется (а иногда и просто нельзя по\xa0соображениям безопасности или\xa0требованиям закона) светить совещания и\xa0личные разговоры.Без\xa0интернета\xa0— никуда, от\xa0слова «совсем»: тут всё предельно понятно. Есть интернет\xa0— есть сервис. Нет интернета\xa0— приходите завтра.Гибкость? Не, не\xa0слышали (или слышали, но\xa0не\xa0про\xa0вашу честь): что\xa0разработчики сервиса вам предоставили, тем вы и пользуетесь. Шаг влево, шаг вправо от\xa0стандартного функционала\xa0— или\xa0невозможно, или\xa0требует дополнительных затрат и согласований. Кастомизация под\xa0специфические нужды часто сильно ограничена.Чем самодельный пайплайн выигрывает:1. GDPR + офлайн. Данные не\xa0покидают диск. 2. Нулевые вложения\xa0— нет платных подписок. 3. Качество расшифровки. Gemma\u202f27B выделяет agenda / decisions / action\u202fitems почти как\xa0GPT‑4. 4. Интеграция с\xa0Obsidian. «Минутки» попадают в\xa0единый граф заметок, ищутся, тегируются, попадают в\xa0Dataview‑таблицы. 5. Гибкость. Хотите выгрузку в\xa0Jira или\xa0Notion\xa0— меняете промпт/скрипт, а\xa0не\xa0ждёте фичи от\xa0SaaS.Другие локальные решения (open-source и не только, если они существуют в природе)Тут тоже есть из\xa0чего выбрать, если хорошенько покопаться в\xa0закромах GitHub и других ресурсов. Однако найти готовое, комплексное и такое\xa0же гибкое решение довольно сложно.Сейчас Альфа тестирует плагин для\xa0Контур.Толка, чтобы транскрибировать и делать саммари созвонов в\xa0инфраструктуре банка на\xa0платформе AlfaGen. Это приятный доп для\xa0сотрудника\xa0— всё собрано и настроено за\xa0тебя, можно грузить любые рабочие обсуждения и даже клиентские данные, они не\xa0утекут за\xa0контур. Точно жду этот плагин.Альтернативы Whisper для\xa0транскрибации: конечно, существуют другие open‑source ASR‑модели и фреймворки (Kaldi, DeepSpeech, Vosk). Но\xa0Whisper, на\xa0мой взгляд,\xa0лидер по\xa0соотношению простоты использования, доступности предобученных моделей и итоговой точности для\xa0большинства языков и задач.Альтернативы NeMo для\xa0диаризации: можно посмотреть в\xa0сторону библиотек pyannote.audio\xa0— очень мощный и активно развивающийся инструмент. Выбор инструмента часто зависит от\xa0ваших специфических требований, качества аудио и готовности разбираться в\xa0особенностях библиотеки.Альтернативы Ollama/Gemma для\xa0запуска LLM: для\xa0локального запуска больших языковых моделей есть довольно много различных путей. Можно напрямую возиться с llama.cpp (если вы хардкорный разработчик и любите всё контролировать до\xa0деталей), есть LM Studio, GPT4All, Jan.ai. Ollama мне импонирует невероятной простотой установки и использования и удобным API. Выбор самих моделей просто огромен: тут вам и различные версии Llama (Llama 2, Llama 3), и Mistral, и Mixtral и многие другие. Gemma 27B\xa0— сбалансированный вариант для\xa0достаточно мощных домашних или\xa0рабочих ПК с\xa0качественной саммаризацией и анализом текста.Альтернативы Obsidian для\xa0управления знаниями: для\xa0заметок и построения персональной базы знаний есть множество других прекрасных инструментов: Joplin, Logseq, Notion (хотя он уже не\xa0совсем локальный и у\xa0него свои нюансы с\xa0приватностью), Standard Notes, Trillium Notes и другие. Obsidian с\xa0его ставкой на\xa0локальное хранение данных в\xa0простом Markdown‑формате, невероятной гибкостью, системой плагинов и активным сообществом\xa0— моя давняя и неизменная любовь.\nПолезные ссылки, чтобы собрать AI-пайплайн для транскрибацииWhisper от\xa0OpenAI: https://github.com/openai/whisperNVIDIA NeMo Toolkit: https://docs.nvidia.com/deeplearning/nemo/user‑guide/docs/en/stableOllama: https://ollama.comGoogle Gemma: https://ai.google.dev/gemmaObsidian: https://obsidian.mdPyTorch: https://pytorch.orgFaster Whisper: https://github.com/guillaumekln/faster‑whisperpyannote.audio (мощная альтернатива NeMo для\xa0задач диаризации спикеров): https://github.com/pyannote/pyannote‑audioLM Studio, Jan.ai, GPT4All (другие популярные инструменты для\xa0локального запуска LLM, если Ollama вам по\xa0какой‑то причине не\xa0подойдёт):https://lmstudio.aihttps://jan.aihttps://gpt4all.ioВыводДерзайте, друзья! Собирайте своих AI‑помощников, автоматизируйте рутину, освобождайте своё время для\xa0более творческих и интересных дел. Пусть работа с\xa0информацией приносит вам только радость, пользу и удовлетворение от\xa0результата. Если у\xa0вас есть вопросы или\xa0идеи по\xa0моему пайплайну или\xa0вы захотите поделиться своим опытом создания подобных систем\xa0— пишите в\xa0комментариях, будет интересно обсудить.',), kwargs={}
Результат: всем привет меня зовут николай луняка и я как и многие из вас ежедневно утопаю в потоке информации количество аудиоконтента растёт в геометрической прогрессии при этом его нужно ещё переварить и зафиксировать интереснейшие лекции хочется сохранить не только в памяти но и в виде тезисов а ещё есть подкасты интервью да и банальные голосовые заметки надиктованные на бегу знакомая картинана помощь приходят облачные сервисы транскрибация саммаризация диаризация  чуть ли не кофе в постель приносят удобно без сомнения как у любого хорошего решения у облачных сервисов есть оборотная сторонаприватность куда на самом деле уходят мои данные кто их видит как использует и не всплывут ли мои приватные обсуждения там где не надо а если речь идёт о чувствительной информации использовать облачные сервисы в рабочем процессе опять же сложно изза ndaподписки для расшифровки приходится использовать несколько сервисов большинство из них платные  из ежемесячного бюджета набегает ощутимая сумма при больших объёмах записей ценник становится соответствующим зачастую кусачим зависимость от интернета куда без него в нашем облачном мире нет сети  нет обработкиоднажды я устал расшифровывать аудио пачкой инструментов в духе балеринокапучино и бобритобандито и решил собрать свой пайплайндальше покажу мой вариант решения всех этих проблем  свой собственный уголок aiнезависимости где аудиоданные в полной безопасности под моим неусыпным контролем для начала расскажу какие инструменты показались мне наиболее подходящими 1 whisper локальной магией из аудиофайла получаем текстначнём с whisper  модели распознавания речи от openai в opensource  готовый инструмент не сырая демка да ещё и бесплатная ну почти  электричеството компьютер кушаетпочему whisper мои аргументыточность транскрибирования близкая к идеалу даже в версии tiny из всего что я пробовал локально whisper показывает пожалуй лучший результат особенно на английском но и с русским справляется на ура меньше ошибок  меньше править рукамимногоязычность он всеядный и даже сам пытается определить на каком языке ему подсунули запись удобноне боится трудностей шумы акценты не лучшая дикция  whisper старается вытащить смысл и часто успешносам расставит точки и запятые ну почти пунктуацию и какоеникакое форматирование он делает и это сильно облегчает жизньглавный аргумент  работает локально никаких отправьте нам ваше аудиопод любые ресурсы и мощности вашего пк модельки от крошечной tiny до монструозной large можно подобрать под своё железо я обычно целюсь в largev3 для качества если время позволяетв общем whisper  наш надёжный поставщик текста из аудио 2 nemo разложим по полочкам кто что сказалтекст мы получили но если это запись встречи на пять человек как понять где чья реплика на помощь приходит nvidia nemo это целый фреймворк для разговорного ai но нас интересует конкретная фича  диаризация спикеров nemo пытается понять сколько людей говорило и какие куски текста принадлежат каждому из нихчем хорош nemo для этой задачиразличает голоса довольно неплохо даже если ктото когото перебивал nemo старается разобраться не всегда идеально но часто очень помогаетможно подкрутить есть возможность тонкой настройки если вы готовы в это погрузитьсяза ним стоит nvidia а это значит проект живой развивается есть поддержка3 ollama доступный мост к языковым моделям разных версийитак у нас есть текст возможно даже с разметкой по спикерам что дальше а дальше хочется чтобы ктото прочитал эту портянку текста и кратко выдал суть здесь в игру вступают большие языковые модели llm но запускать их локально  та ещё задачка была пока не появился ollamaollama  спасение для тех кто хочет подружиться с llmпростота установить и запустить модель  буквально пара команд в терминале никаких танцев с бубном вокруг зависимостей ну почтиподдерживает кучу популярных инструментов  llama mistral gemmaприватность  всё крутится локальноесть api  скрипты или плагины могут легко общаться с модельюollama  удобная пусковая площадка для gemma которая и будет заниматься погруженным анализом текста4 gemma 27b кратко по делу и по пунктам раскладываем текстgemma  это семейство моделей от google при том открытое что не может не радовать есть разные размеры я проводил эксперименты на gemma 27b 27 миллиардов параметров  звучит солидно хочется качественного анализа если у вас не тянет железо или меньше ресурсов можно использовать модели где параметров поменьшечто мне нравится в gemma когда она работает через ollamaхоть это не гигант вроде gpt4 с 18 триллионов параметров gemma 27b вполне достойно справляется с генерацией и пониманием текста для саммари  то что доктор прописалмодельки gemma неплохо оптимизированы для запуска на обычном относительно мощном железе интересная особенность ollama  она подсовывает квантованные версии это когда модель ужимают для скорости не критично теряя в точностиоткрытость  больше людей пользуется и даёт обратную связь система быстрее развиваетсяобучена на многих языках так что с нашими великим и могучим проблем быть не должно5 obsidian цифровой мозг куда всё стекаетсякуда же мы будем складывать наши сокровища  транскрипты диалоги саммари я для себя выбрал obsidian  не просто заметочник а целая система управления знаниями и самое главное  он работает с локальными файлами в markdownпочему obsidian  идеальный финальный аккордвсе заметки лежат в папке на моем компьютере стоп паранойяmarkdown  это просто и удобно легко писать читать и переносить куда угодноплагины  их тысячи вот где настоящая магия можно настроить obsidian так как тебе удобно интегрировать с чем угодно в нашем случае  автоматизировать сохранение результатов обработки аудиоможно связывать заметки друг с другом строить целые карты знаний отчёт по встрече легко связывается с проектом задачами мыслямивнешний вид горячие клавиши  всё можно кастомизироватьobsidian для меня  не просто хранилище а активный инструмент сюда будут складироваться результаты работы нашего aiкомбайна отсюда же мы будем работать с ними дальшевот такая команда сервисов у нас собралась в пайплайн каждый со своей ролью но вместе они  силакак заставить этот оркестр играть слаженно путь от аудиозаписи до осмысленной заметки в obsidianс нашими чудоинструментами мы болееменее разобрались наступает самый ответственный момент как эти разрозненные компоненты соединить в единый слаженно работающий конвейер как превратить аудиофайл в информационную конфетку  структурированную осмысленную и готовую к употреблению заметку в obsidian давайте пройдёмся по шагам этого увлекательного процесса как его реализую яшаг 1 готовим сырьё  наш драгоценный аудиофайлобычно приложения типа zoom или контуртолк предупреждают юзеров о записи аудио но хороший тон  предупредить собеседников что вы записываете созвонвсё начинается как нетрудно догадаться с аудио я лично стараюсь использовать форматwav илиflac  исторически сложилось что whisper с ними дружит особенно хорошо да и меньше шансов нарваться на неожиданные сюрпризы с экзотическими кодеками тем не менее whisper довольно всеяден и с удовольствием скушает и mp3 и m4a и многие другие популярные форматы главное чтобы сама запись была болееменее приличного качества если у вас скажем стереозапись со встречи где разные участники были записаны на разные каналы  вообще шикарный вариант nemo потом скажет вам отдельное спасибо но и с обычной монозаписью вполне можно жить и получать достойные результаты дополнительно можно убрать длинные паузы тишину и попробовать улучшить качество записи при помощи библиотеки ffmpegcmd  
       ffmpeg
       i strinput_path    входной файл
       ac 1               преобразовать звук в моно 1 канал
       ar 16000           понизить частоту 16 кгц
       af                   silenceremovestart_periods1start_silence03start_threshold35db
detectionpeak                 фильтр для удаления пауз
       stroutput_path
   я использую следующие фильтрыstart_periods1  реагирует на 1ю возникшую паузу
start_silence03  пауза считается значимой если длится дольше 03 сек
start_threshold35db  всё тише 35 дб считается тишиной
detectionpeak  на основе пикового сигнала в аудиошаг 2 whisper на выход превращаем голос в буквы или магия транскрибациипервым делом мы скармливаем наш аудиофайл whisper я обычно использую модель largev3 для русского языка если нужна максимальная точность и есть немного времени подождать если же ситуация горит и результат нужен ещё вчера  можно взять модель medium whisper немного попыхтит проанализирует аудиодорожку и выдаст текстовый файл и что особенно приятно  уже с запятыми точками а иногда даже с попытками разбить текст на абзацы красота да и толькокак это может выглядеть в консоли очень упрощённый примерbash
whisper vstrechawav model largev3 language ru output_format txtна выходе мы получаем например файл vstrechatxt  с ним можно работать дальшелайфхак если у вас есть хорошая видеокарта с поддержкой rtx для транскрибации можно использовать gpuмой скрипт  аргументы командной строки
   p  argparseargumentparser
 обязательный аргумент  путь к файлу
   padd_argumentpath helpаудио или видеофайл
  
 необязательный аргумент lang по умолчанию  русский
   padd_argumentlang defaultru
  
 параметр случайности температура для модели влияет на вариативность результатов
   padd_argumenttemperature typefloat default0
  
 размер beam search если используется влияет на точностьварианты распознавания
   padd_argumentbeam_size typeint
  
 булев флаг использовать ли предыдущий текст как контекст при распознавании
   padd_argumentcondition actionstore_true
                  helpcondition_on_previous_text
  
 необязательный текстовый ввод  вводная для модели можно подсказать контексттемы
   padd_argumentprompt default
                  helpвводная тема участники термины
  
 парсит все аргументы из командной строки в объект args
   args  pparse_args

   if not ospathisfileargspath
       raise systemexitfфайл не найден argspath
  
 проверяет доступна ли видеокарта cuda gpu если нет  используется cpu
   device  cuda if torchcudais_available else cpu
  
 выводит на каком устройстве будет происходить транскрипция   
   printfустройство deviceupper 
         torchcudaget_device_name0 if device  cuda else cpu
  
 загружает модель largev3 на выбранное устройство gpu или cpu
   model  whisperload_modellargev3 devicedevice

 сообщение о старте и начало отсчёта времени
   printтранскрибирование
   t0  timetime
   result  modeltranscribe
       argspath
       languageargslang
       temperatureargstemperature
       beam_sizeargsbeam_size
       condition_on_previous_textargscondition
       initial_promptargsprompt or none   
   
  
 показывает сколько времени заняла транскрипция
   printfroundtimetimet02 с
  
 сохранение результата в json и txt
   base  ospathsplitextargspath0
   with openbase  json w encodingutf8 as f
       jsondumpresultsegments f ensure_asciifalse indent2
   with openbase  txt w encodingutf8 as f
       fwriteresulttext
   printсохранено base  json  txtшаг 3 nemo помоги разобраться кто есть кто искусство диаризациипросто текст  конечно хорошо но если это была запись оживлённой беседы нескольких человек без чёткого понимания кто и что сказал далеко не уедешь тут в дело вступает nemo с функцией диаризации спикеров он снова слушает исходный аудиофайл и опираясь на временные метки которые whisper тоже может любезно предоставить если попросить его выдать результат в формате srt или vtt пытается аккуратно нарезать общую речь на отдельные кусочки и присвоить каждому уникальную метку спикер_0 спикер_1 спикер_2 и т дnvidia рекомендует выполнять установку через pip install nemo_toolkitall иногда могут возникнуть нюансы с зависимостями так что внимательно читайте сообщения в консоли при установке официальная документация nemo  ваш лучший другсразу предупрежу для дальнейшей работы и настройки это как правило не одна простая команда в консоли здесь потребуется небольшой скрипт на python который будет управлять работой nemo загружать модели например titanet_large для получения эмбеддингов голоса и msdd_vad или аналогичную для кластеризации сегментов результат определённо того стоит вместо сплошного неразборчивого потока текста мы получаем нечто гораздо более осмысленное напримерспикер_0 привет команда какие у нас сегодня новости по проекту смартспикер_1 привет в целом всё идет по плану но есть пара нюансов которые хотелось бы обсудитьуже гораздо понятнее и информативнее не правда ли чтение аудио и извлечение эмбеддингов
wav sr  librosaloadwav_path sr16000 monotrue
embs stamps  extract_embeddingswav sr model

 автокластеризация спикеров по эмбеддингам
labels  auto_clusterembs max_kmax_k
spk_cnt  lensetlabels
diar  merge_segmentsstamps labels

 мерж с расшифровкой whisper
with openwhisper_json encodingutf8 as f
   whisper_segs  jsonloadf

tagged  
for seg in whisper_segs
   spk  next
       fspeakerdspk  1 for d in diar
        if not segend  ds or segstart  de
       unknown
   
   taggedappendseg speaker spk

 сохраняем результат
out_path  pathwhisper_jsonwith_stempathwhisper_jsonstem  _tagged
with openout_path w encodingutf8 as f
   jsondumptagged f ensure_asciifalse indent2я использую следующий флоу загружаю модель  извлекает эмбеддинги числовые данные которые позволяют понять количество спикеров  кластеризует на группы говорящих  сливает последовательные сегменты одного спикера  сопоставляет с полученными данными на предыдущем шаге  для каждого сегмента определяет в какой диаризационный диапазон он попадает присваивает спикерашаг 4 gemma твой звёдный час делаем умное и структурированное саммариперед запуском локального llmсервер через ollama обязательно нужно активировать модельollama run gemma327bтеперь когда у нас есть практически идеальный диаризованный транскрипт время задействовать тяжёлую артиллерию  gemma 27b запущенную и управляемую через ollama наша задача на этом этапе  скормить ей полученный текст и вежливо но настойчиво попросить сделать качественную выжимку о чём говорили к каким выводам пришли что решили какие задачи поставили и на кого их повесилиздесь важную роль играет правильно составленный запрос к модели я формулирую промпт примерно такты мой эффективный aiассистент по анализу стенограмм совещаний и лекций вот тебе текст разговора нескольких людей сделай из него структурированное саммари на русском языке в саммари обязательно выдели следующие пункты можно использовать маркированные списки1 основные обсуждавшиеся темы или вопросы2 ключевые аргументы предложения или идеи высказанные участниками если были3 принятые решения если таковые были4 поставленные задачи с указанием ответственных лиц если это можно однозначно понять из текста5 главные выводы или итоги обсужденияollama отправляет этот промпт вместе с текстом нашей gemma и она немного подумав время и скорость обработки зависит от выбранной модели и вашего железа выдаёт готовое саммари настоящая aiмагия в действии ключевые настройки скрипта

model  имя локальной llmмодели в ollama gemma27b llama38b 
nostream  отключает потоковую генерацию по умолчанию  включена 
timeout  ограничивает время ожидания ответа 
max_chars  ограничивает длину текста для llm по умолчанию 15 000 
system_prompt  инструкция для модели как структурировать markdownрезюме 
входной файл должен быть в формате json  speaker  text  start  end   шаг 5 все дороги ведут в obsidian наводим порядок систематизируем и пользуемся результатамии вот он долгожданный финал нашего увлекательного путешествия собираем все наши артефакты исходный сырой транскрипт от whisper диаризованный текст от nemo блестящее саммари от gemma  и аккуратно с любовью укладываем это богатство в наше хранилище obsidian как это сделать вариантов масса1 старым дедовским способом  руками скопировал  вставил долго муторно неэффективно и вообще не наш метод если мы говорим о регулярных задачах и автоматизации2 магия скриптов  наш выбор пишем небольшой или большой в зависимости от ваших амбиций скрипт на python который будет выполнять все предыдущие шаги по очереди а затем самостоятельно создавать новую заметку в obsidian правильно её называть например по дате и теме встречи или по имени исходного аудиофайла добавлять теги вставлять саммари диаризованный транскрипт а может даже ссылку на исходный аудиофайл в общем полный автомат мечта любого лентяя в хорошем смысле этого слова3 плагины obsidian расширяем горизонты тут тоже есть где разгуляться творческой мысли можно использовать плагин obsidian shell commands для запуска pythonскрипта прямо из интерфейса obsidian или плагин templater для создания новых заметок по заранее подготовленному красивому шаблону куда будут автоматически подставляться все наши данныекак может выглядеть итоговая заметка в obsidian мой личный вариант который я постоянно дорабатываютак шаг за шагом из непонятного и объёмного аудиофайла мы получаем структурированную осмысленную информацию с которой можно работать по тексту которой можно искать которой можно делиться с коллегами и просто чувствовать себя настоящим молодцом победившим информационный хаос удобно обернуть всё это дело в простенький gui как у меня и вышлоimport os
import subprocess

def run_pipelinefilepath use_cleantrue do_summarytrue temperature0 beam_sizenone conditionfalse prompt
   if not filepath or not ospathexistsfilepath
       raise filenotfounderrorfфайл не найден filepath

   base_name  ospathsplitextfilepath0
   cleaned_file  base_name  _cleanedwav
   audio_file  cleaned_file if use_clean else filepath

    шаг 1 очистка аудио опционально
   if use_clean
       subprocessrunpython clean_audiopy filepath

    шаг 2 транскрипция whisper
   cmd  
       python transcribepy
       audio_file
       lang ru
       temperature temperature
   
   if beam_size
       cmd  beam_size strbeam_size
   if condition
       cmdappendcondition
   if prompt
       cmd  prompt prompt
   subprocessruncmd

    шаг 3 диаризация nemo
   json_file  ospathsplitextaudio_file0  json
   subprocessrunpython diarize_nemo_autopy audio_file json_file 12

    шаг 4 конвертация в txt  md
   tagged_json  ospathsplitextaudio_file0  _taggedjson
   if ospathexiststagged_json
       from convert_tagged_json_to_txt_md import convert_tagged_json_to_txt_md
       convert_tagged_json_to_txt_mdtagged_json

    шаг 5 генерация саммари опционально
   if do_summary
       subprocessrunpython summarize_jsonpy tagged_jsonкак вам такой подход а что у других сравниваем наш самосбор с готовыми решениями облачными и не оченьзачем мудрить если есть облачные гиганты и их свитаgoogle speechtotext aws transcribe azure speech services yandex speechkit assemblyai otterai sonixai firefliesai и многие другие ребята конечно молодцы у них как правило всё очень просто быстро удобно и часто весьма качественночем готовые решения объективно кручепростота зарегистрировался получил apiключ или просто загрузил файл через вебинтерфейс  и через несколько минут получил результат никаких сложных установок настроек зависимостей и чтения многостраничных мануаловскорость и масштабируемость у этих компаний в распоряжении датацентры с тысячами мощных серверов они способны переваривать огромные объёмы аудио очень и очень быстро если вам нужно обработать терабайты записей в сжатые сроки  облака скорее всего ваш выбордополнительные фичи и плюшки часто облачные сервисы предлагают набор допов  автоматический анализ тональности речи выделение ключевых слов и тем определение эмоций интеграции с популярными сервисами crm таскменеджеры и т дгде облачные сервисы однозначно проигрывают локальному стекуденьги деньги дребеденьги практически все облачные сервисы работают по подписке или тарифицируют каждую обработанную минуту аудио или каждый распознанный символ если вы пользуетесь их услугами регулярно и в больших объемах ежемесячные счета набегают весьма приличныемои драгоценные данные у дяди сэма или у когото ещё вопрос конфиденциальности и безопасности данных стоит очень остро вы доверяете свои возможно очень чувствительные аудиозаписи третьей стороне не всегда хочется а иногда и просто нельзя по соображениям безопасности или требованиям закона светить совещания и личные разговорыбез интернета  никуда от слова совсем тут всё предельно понятно есть интернет  есть сервис нет интернета  приходите завтрагибкость не не слышали или слышали но не про вашу честь что разработчики сервиса вам предоставили тем вы и пользуетесь шаг влево шаг вправо от стандартного функционала  или невозможно или требует дополнительных затрат и согласований кастомизация под специфические нужды часто сильно ограниченачем самодельный пайплайн выигрывает1 gdpr  офлайн данные не покидают диск 2 нулевые вложения  нет платных подписок 3 качество расшифровки gemma 27b выделяет agenda  decisions  action items почти как gpt4 4 интеграция с obsidian минутки попадают в единый граф заметок ищутся тегируются попадают в dataviewтаблицы 5 гибкость хотите выгрузку в jira или notion  меняете промптскрипт а не ждёте фичи от saasдругие локальные решения opensource и не только если они существуют в природетут тоже есть из чего выбрать если хорошенько покопаться в закромах github и других ресурсов однако найти готовое комплексное и такое же гибкое решение довольно сложносейчас альфа тестирует плагин для контуртолка чтобы транскрибировать и делать саммари созвонов в инфраструктуре банка на платформе alfagen это приятный доп для сотрудника  всё собрано и настроено за тебя можно грузить любые рабочие обсуждения и даже клиентские данные они не утекут за контур точно жду этот плагинальтернативы whisper для транскрибации конечно существуют другие opensource asrмодели и фреймворки kaldi deepspeech vosk но whisper на мой взгляд лидер по соотношению простоты использования доступности предобученных моделей и итоговой точности для большинства языков и задачальтернативы nemo для диаризации можно посмотреть в сторону библиотек pyannoteaudio  очень мощный и активно развивающийся инструмент выбор инструмента часто зависит от ваших специфических требований качества аудио и готовности разбираться в особенностях библиотекиальтернативы ollamagemma для запуска llm для локального запуска больших языковых моделей есть довольно много различных путей можно напрямую возиться с llamacpp если вы хардкорный разработчик и любите всё контролировать до деталей есть lm studio gpt4all janai ollama мне импонирует невероятной простотой установки и использования и удобным api выбор самих моделей просто огромен тут вам и различные версии llama llama 2 llama 3 и mistral и mixtral и многие другие gemma 27b  сбалансированный вариант для достаточно мощных домашних или рабочих пк с качественной саммаризацией и анализом текстаальтернативы obsidian для управления знаниями для заметок и построения персональной базы знаний есть множество других прекрасных инструментов joplin logseq notion хотя он уже не совсем локальный и у него свои нюансы с приватностью standard notes trillium notes и другие obsidian с его ставкой на локальное хранение данных в простом markdownформате невероятной гибкостью системой плагинов и активным сообществом  моя давняя и неизменная любовь
полезные ссылки чтобы собрать aiпайплайн для транскрибацииwhisper от openai httpsgithubcomopenaiwhispernvidia nemo toolkit httpsdocsnvidiacomdeeplearningnemouserguidedocsenstableollama httpsollamacomgoogle gemma httpsaigoogledevgemmaobsidian httpsobsidianmdpytorch httpspytorchorgfaster whisper httpsgithubcomguillaumeklnfasterwhisperpyannoteaudio мощная альтернатива nemo для задач диаризации спикеров httpsgithubcompyannotepyannoteaudiolm studio janai gpt4all другие популярные инструменты для локального запуска llm если ollama вам по какойто причине не подойдётhttpslmstudioaihttpsjanaihttpsgpt4allioвыводдерзайте друзья собирайте своих aiпомощников автоматизируйте рутину освобождайте своё время для более творческих и интересных дел пусть работа с информацией приносит вам только радость пользу и удовлетворение от результата если у вас есть вопросы или идеи по моему пайплайну или вы захотите поделиться своим опытом создания подобных систем  пишите в комментариях будет интересно обсудить
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: contains_keywords
Аргументы: args=('Всем привет! Меня зовут Николай Луняка, и я, как\xa0и многие из\xa0вас, ежедневно утопаю в\xa0потоке информации. Количество аудиоконтента растёт в\xa0геометрической прогрессии, при\xa0этом его нужно ещё «переварить» и зафиксировать. Интереснейшие лекции хочется сохранить не\xa0только в\xa0памяти, но\xa0и в\xa0виде тезисов, а\xa0ещё есть подкасты, интервью, да\xa0и банальные голосовые заметки, надиктованные на\xa0бегу. Знакомая картина?На\xa0помощь приходят облачные сервисы: транскрибация, саммаризация, диаризация — чуть\xa0ли не\xa0кофе в\xa0постель приносят. Удобно? Без\xa0сомнения. Как\xa0у любого хорошего решения, у\xa0облачных сервисов есть оборотная сторона:Приватность: куда на\xa0самом деле уходят мои данные? Кто их видит, как\xa0использует, и не\xa0всплывут\xa0ли мои приватные обсуждения там, где не\xa0надо? А\xa0если речь идёт о\xa0чувствительной информации? Использовать облачные сервисы в\xa0рабочем процессе опять\xa0же сложно из‑за NDA.Подписки. Для\xa0расшифровки приходится использовать несколько сервисов. Большинство из\xa0них платные\xa0— из\xa0ежемесячного бюджета набегает ощутимая сумма. При\xa0больших объёмах записей ценник становится соответствующим, зачастую кусачим. Зависимость от\xa0интернета. Куда без\xa0него в\xa0нашем «облачном» мире? Нет сети\xa0— нет обработки.Однажды я устал расшифровывать аудио пачкой инструментов в духе «Балерино-Капучино и Бобрито-Бандито» и решил собрать свой пайплайн.Дальше покажу мой вариант решения всех этих проблем\xa0— свой собственный уголок AI‑независимости, где аудиоданные в\xa0полной безопасности под\xa0моим неусыпным контролем. Для\xa0начала расскажу, какие инструменты показались мне наиболее подходящими. 1. Whisper: локальной магией из аудиофайла получаем текстНачнём с Whisper\xa0— модели распознавания речи от\xa0OpenAI в\xa0open‑source\xa0— готовый инструмент, не\xa0сырая демка, да\xa0ещё и бесплатная (ну, почти\xa0— электричество‑то компьютер кушает).Почему Whisper? Мои аргументы:Точность транскрибирования, близкая к\xa0идеалу, даже в\xa0версии tiny: из\xa0всего, что\xa0я пробовал локально, Whisper показывает, пожалуй, лучший результат. Особенно на\xa0английском, но\xa0и с\xa0русским справляется на\xa0ура. Меньше ошибок\xa0— меньше править руками.Многоязычность: он «всеядный», и даже сам пытается определить, на\xa0каком языке ему подсунули запись. Удобно!Не\xa0боится трудностей: шумы, акценты, не\xa0лучшая дикция\xa0— Whisper старается вытащить смысл, и часто успешно.Сам расставит точки и запятые (ну, почти). Пунктуацию и какое‑никакое форматирование он делает, и это сильно облегчает жизнь.Главный аргумент\xa0— работает локально. Никаких «отправьте нам ваше аудио».Под\xa0любые ресурсы и мощности вашего ПК: Модельки от\xa0крошечной «tiny» до\xa0монструозной «large» можно подобрать под\xa0своё\xa0железо. Я обычно целюсь в «large‑v3» для\xa0качества, если время позволяет.В\xa0общем, Whisper\xa0— наш надёжный поставщик текста из\xa0аудио. 2. NeMo: разложим по полочкам кто что сказалТекст мы получили. Но\xa0если это запись встречи на\xa0пять человек, как\xa0понять, где чья реплика? На\xa0помощь приходит NVIDIA NeMo. Это целый фреймворк для\xa0разговорного AI, но\xa0нас интересует конкретная фича\xa0— диаризация спикеров. NeMo пытается понять, сколько людей говорило и какие куски текста принадлежат каждому из\xa0них.Чем хорош NeMo для\xa0этой задачи:Различает голоса довольно неплохо, даже если кто‑то кого‑то перебивал, NeMo старается разобраться. Не\xa0всегда идеально, но\xa0часто очень помогает.Можно подкрутить, есть возможность тонкой настройки, если вы готовы в\xa0это погрузиться.За\xa0ним стоит NVIDIA, а\xa0это значит, проект живой, развивается, есть поддержка.3. Ollama: доступный мост к языковым моделям разных версийИтак, у\xa0нас есть текст, возможно, даже с\xa0разметкой по\xa0спикерам. Что\xa0дальше? А\xa0дальше хочется, чтобы кто‑то прочитал эту портянку текста и кратко выдал суть. Здесь в\xa0игру вступают большие языковые модели (LLM). Но\xa0запускать их локально\xa0— та ещё задачка...\xa0была, пока не\xa0появился Ollama.Ollama\xa0— спасение для\xa0тех, кто хочет подружиться с\xa0LLM:Простота: установить и запустить модель\xa0— буквально пара команд в\xa0терминале. Никаких танцев с\xa0бубном вокруг зависимостей (ну, почти).Поддерживает кучу популярных инструментов\xa0— Llama, Mistral, Gemma.Приватность\xa0— всё крутится локально.Есть API\xa0— скрипты или\xa0плагины могут легко общаться с\xa0моделью.Ollama\xa0— удобная «пусковая площадка» для\xa0Gemma, которая и будет заниматься погруженным анализом текста.4. Gemma 27B: кратко, по делу и по пунктам раскладываем текстGemma\xa0— это семейство моделей от\xa0Google, при\xa0том открытое, что\xa0не\xa0может не\xa0радовать. Есть разные размеры, я проводил эксперименты на\xa0Gemma 27B (27\xa0миллиардов параметров\xa0— звучит солидно). Хочется качественного анализа. Если у\xa0вас не\xa0тянет\xa0железо или\xa0меньше ресурсов, можно использовать модели, где параметров поменьше.Что\xa0мне нравится в\xa0Gemma (когда она работает через Ollama):Хоть это не\xa0гигант вроде GPT-4\xa0с 1,8\xa0триллионов параметров, Gemma 27B вполне достойно справляется с\xa0генерацией и пониманием текста. Для\xa0саммари\xa0— то, что\xa0доктор прописал.Модельки Gemma неплохо оптимизированы для\xa0запуска на\xa0обычном (относительно мощном)\xa0железе. Интересная особенность Ollama\xa0— она подсовывает квантованные версии (это когда модель «ужимают» для\xa0скорости, не\xa0критично теряя в\xa0точности).Открытость\xa0— больше людей пользуется и даёт обратную связь, система\xa0быстрее развивается.Обучена на\xa0многих языках, так что\xa0с\xa0нашими «великим и могучим» проблем\xa0быть не\xa0должно.5. Obsidian: цифровой мозг, куда всё стекаетсяКуда\xa0же мы будем складывать наши сокровища\xa0— транскрипты, диалоги, саммари? Я для\xa0себя выбрал Obsidian — не\xa0просто заметочник, а\xa0целая система управления знаниями. И самое главное\xa0— он работает с\xa0локальными файлами в\xa0Markdown.Почему Obsidian\xa0— идеальный финальный аккорд:Все заметки лежат в\xa0папке на\xa0моем компьютере. Стоп паранойя.Markdown\xa0— это просто и удобно: легко писать, читать и переносить куда угодно.Плагины\xa0— их тысячи! Вот где настоящая магия. Можно настроить Obsidian так, как\xa0тебе удобно, интегрировать с\xa0чем угодно. В\xa0нашем случае\xa0— автоматизировать сохранение результатов обработки аудио.Можно связывать заметки друг с\xa0другом, строить целые карты знаний. Отчёт по\xa0встрече легко связывается с\xa0проектом, задачами, мыслями.Внешний вид, горячие клавиши\xa0— всё можно кастомизировать.Obsidian для\xa0меня\xa0— не\xa0просто хранилище, а\xa0активный инструмент. Сюда будут складироваться результаты работы нашего AI‑комбайна, отсюда\xa0же мы будем работать с\xa0ними дальше.Вот такая команда сервисов у\xa0нас собралась в\xa0пайплайн. Каждый со своей ролью, но\xa0вместе они\xa0— сила.Как заставить этот оркестр играть слаженно: путь от аудиозаписи до осмысленной заметки в ObsidianС\xa0нашими чудо‑инструментами мы более‑менее разобрались. Наступает самый ответственный момент: как\xa0эти разрозненные компоненты соединить в\xa0единый, слаженно работающий конвейер? Как\xa0превратить аудиофайл в\xa0информационную конфетку\xa0— структурированную, осмысленную и готовую к\xa0употреблению заметку в\xa0Obsidian? Давайте пройдёмся по\xa0шагам этого увлекательного процесса, как\xa0его реализую я.Шаг 1: Готовим «сырьё» – наш драгоценный аудиофайлОбычно приложения типа Zoom или\xa0Контур.Толк предупреждают юзеров о\xa0записи аудио. Но\xa0хороший тон\xa0— предупредить собеседников, что\xa0вы записываете созвон.Всё начинается, как\xa0нетрудно догадаться, с\xa0аудио. Я\xa0лично стараюсь использовать формат.wav или.flac\xa0— исторически сложилось, что\xa0Whisper с\xa0ними дружит особенно хорошо, да\xa0и меньше шансов нарваться на\xa0неожиданные сюрпризы с\xa0экзотическими кодеками. Тем не\xa0менее, Whisper довольно «всеяден» и с\xa0удовольствием «скушает» и MP3, и M4A, и многие другие популярные форматы. Главное, чтобы сама запись\xa0была более‑менее приличного качества. Если у\xa0вас, скажем, стереозапись со встречи, где разные участники\xa0были записаны на\xa0разные каналы\xa0— вообще шикарный вариант, NeMo потом скажет вам отдельное спасибо. Но\xa0и с\xa0обычной моно‑записью вполне можно жить и получать достойные результаты. Дополнительно можно убрать длинные паузы (тишину) и попробовать улучшить качество записи при\xa0помощи библиотеки ffmpeg:cmd = [\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"ffmpeg",\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-i", str(input_path), \xa0 # входной файл\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-ac", "1",\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 # преобразовать звук в моно (1 канал)\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-ar", "16000",\xa0 \xa0 \xa0 \xa0 \xa0 # понизить частоту 16 кГц\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0"-af", \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 "silenceremove=start_periods=1:start_silence=0.3:start_threshold=-35dB:\\\ndetection=peak",\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 # фильтр для удаления пауз\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0str(output_path)\n\xa0\xa0\xa0]Я использую следующие фильтры:start_periods=1 # реагирует на 1ю возникшую паузу\nstart_silence=0.3 # пауза считается значимой, если длится дольше 0.3 сек\nstart_threshold=-35dB # всё тише −35\u202fдБ считается тишиной\ndetection=peak # на основе пикового сигнала в аудиоШаг 2: Whisper, на выход! Превращаем голос в буквы, или Магия транскрибацииПервым делом мы «скармливаем» наш аудиофайл Whisper. Я обычно использую модель «large‑v3» для\xa0русского языка, если нужна максимальная точность и есть немного времени подождать. Если\xa0же ситуация «горит» и результат нужен «ещё вчера»\xa0— можно взять модель «medium». Whisper немного попыхтит, проанализирует аудиодорожку и выдаст текстовый файл. И что\xa0особенно приятно\xa0— уже с\xa0запятыми, точками, а\xa0иногда даже с\xa0попытками разбить текст на\xa0абзацы. Красота, да\xa0и только!Как\xa0это может выглядеть в\xa0консоли (очень упрощённый пример):bash\nwhisper vstrecha.wav --model large-v3 --language ru --output_format txtНа\xa0выходе мы получаем, например, файл «vstrecha.txt»\xa0— с\xa0ним можно работать дальше.Лайфхак: если у\xa0вас есть хорошая видеокарта с\xa0поддержкой RTX, для\xa0транскрибации можно использовать GPU.Мой скрипт: # Аргументы командной строки\n \xa0 p = argparse.ArgumentParser()\n# Обязательный аргумент -- путь к файлу.\n \xa0 p.add_argument("path", help="Аудио‑ или видеофайл")\n\xa0 \n# Необязательный аргумент --lang, по умолчанию -- русский.\n \xa0 p.add_argument("--lang", default="ru")\n\xa0 \n# Параметр случайности (температура) для модели, влияет на вариативность результатов.\'\'\'\n \xa0 p.add_argument("--temperature", type=float, default=0)\n\xa0 \n# Размер beam search (если используется), влияет на точность/варианты распознавания.\n \xa0 p.add_argument("--beam_size", type=int)\n\xa0 \n# Булев флаг: использовать ли предыдущий текст как контекст при распознавании.\n \xa0 p.add_argument("--condition", action="store_true",\n\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 help="condition_on_previous_text")\n\xa0 \n# Необязательный текстовый ввод -- вводная для модели (можно подсказать контекст/темы).\n \xa0 p.add_argument("--prompt", default="",\n\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 help="Вводная: тема, участники, термины...")\n\xa0 \n# Парсит все аргументы из командной строки в объект args.\n \xa0 args = p.parse_args()\n\n \xa0 if not os.path.isfile(args.path):\n \xa0 \xa0 \xa0 raise SystemExit(f"Файл не найден: {args.path}")\n\xa0 \n# Проверяет, доступна ли видеокарта CUDA (GPU). Если нет -- используется CPU.\n \xa0 device = "cuda" if torch.cuda.is_available() else "cpu"\n\xa0 \n# Выводит на каком устройстве будет происходить транскрипция. \xa0 \n \xa0 print(f"Устройство: {device.upper()} --",\n \xa0 \xa0 \xa0 \xa0 torch.cuda.get_device_name(0) if device == "cuda" else "CPU")\n\xa0 \n# Загружает модель large-v3 на выбранное устройство (GPU или CPU).\n \xa0 model = whisper.load_model("large-v3", device=device)\n\n# Сообщение о старте и начало отсчёта времени.\n \xa0 print("Транскрибирование...")\n \xa0 t0 = time.time()\n \xa0 result = model.transcribe(\n \xa0 \xa0 \xa0 args.path,\n \xa0 \xa0 \xa0 language=args.lang,\n \xa0 \xa0 \xa0 temperature=args.temperature,\n \xa0 \xa0 \xa0 beam_size=args.beam_size,\n \xa0 \xa0 \xa0 condition_on_previous_text=args.condition,\n \xa0 \xa0 \xa0 initial_prompt=args.prompt or None \xa0 \n \xa0 )\n\xa0 \n# Показывает, сколько времени заняла транскрипция.\n \xa0 print(f"{round(time.time()-t0,2)} с")\n\xa0 \n# Сохранение результата в JSON и TXT\n \xa0 base = os.path.splitext(args.path)[0]\n \xa0 with open(base + ".json", "w", encoding="utf-8") as f:\n \xa0 \xa0 \xa0 json.dump(result["segments"], f, ensure_ascii=False, indent=2)\n \xa0 with open(base + ".txt", "w", encoding="utf-8") as f:\n \xa0 \xa0 \xa0 f.write(result["text"])\n \xa0 print("Сохранено:", base + ".json / .txt")Шаг 3: NeMo, помоги разобраться, кто есть кто! Искусство диаризацииПросто текст\xa0— конечно, хорошо, но\xa0если это\xa0была запись оживлённой беседы нескольких человек, без\xa0чёткого понимания, кто и что\xa0сказал, далеко не\xa0уедешь. Тут в\xa0дело вступает NeMo с\xa0функцией диаризации спикеров. Он снова «слушает» исходный аудиофайл и, опираясь на\xa0временные метки (которые Whisper тоже может любезно предоставить, если попросить его выдать результат в\xa0формате SRT или\xa0VTT), пытается аккуратно «нарезать» общую речь на\xa0отдельные кусочки и присвоить каждому уникальную метку: «Спикер_0», «Спикер_1», «Спикер_2» и\xa0т.\xa0д.NVIDIA рекомендует выполнять установку через pip install nemo_toolkit["all"]. Иногда могут возникнуть нюансы с\xa0зависимостями, так что\xa0внимательно читайте сообщения в\xa0консоли при\xa0установке. Официальная документация NeMo\xa0— ваш лучший друг.Сразу предупрежу: для\xa0дальнейшей работы и настройки это, как\xa0правило, не\xa0одна простая команда в\xa0консоли. Здесь потребуется небольшой скрипт на Python, который будет управлять работой NeMo, загружать модели (например, «titanet_large» для\xa0получения эмбеддингов голоса и «msdd_vad» или\xa0аналогичную для\xa0кластеризации сегментов). Результат определённо того стоит: вместо сплошного, неразборчивого потока текста мы получаем нечто гораздо более осмысленное, например:[Спикер_0]: Привет, команда! Какие у\xa0нас сегодня новости по\xa0проекту «Смарт»?[Спикер_1]: Привет! В\xa0целом, всё идет по\xa0плану, но\xa0есть пара нюансов, которые хотелось\xa0бы обсудить...Уже гораздо понятнее и информативнее, не\xa0правда\xa0ли?# Чтение аудио и извлечение эмбеддингов\nwav, sr = librosa.load(wav_path, sr=16000, mono=True)\nembs, stamps = extract_embeddings(wav, sr, model)\n\n# Автокластеризация спикеров по эмбеддингам\nlabels = auto_cluster(embs, max_k=max_k)\nspk_cnt = len(set(labels))\ndiar = merge_segments(stamps, labels)\n\n# Мерж с расшифровкой Whisper\nwith open(whisper_json, encoding="utf-8") as f:\n \xa0 whisper_segs = json.load(f)\n\ntagged = []\nfor seg in whisper_segs:\n \xa0 spk = next(\n \xa0 \xa0 \xa0 (f"Speaker{d[\'spk\'] + 1}" for d in diar\n\xa0 \xa0 \xa0 \xa0 if not (seg[\'end\'] <= d[\'s\'] or seg[\'start\'] >= d[\'e\'])),\n \xa0 \xa0 \xa0 "Unknown"\n \xa0 )\n \xa0 tagged.append({**seg, "speaker": spk})\n\n# Сохраняем результат\nout_path = Path(whisper_json).with_stem(Path(whisper_json).stem + "_tagged")\nwith open(out_path, "w", encoding="utf-8") as f:\n \xa0 json.dump(tagged, f, ensure_ascii=False, indent=2)Я использую следующий флоу: загружаю модель >> извлекает эмбеддинги (числовые данные, которые позволяют понять количество спикеров) >> кластеризует на\xa0группы говорящих >> сливает последовательные сегменты одного спикера >> сопоставляет с\xa0полученными данными на\xa0предыдущем шаге >> для\xa0каждого сегмента определяет, в\xa0какой диаризационный диапазон он попадает, присваивает спикера.Шаг 4: Gemma, твой звёдный час! Делаем умное и структурированное саммариПеред запуском локального LLM‑сервер через Ollama обязательно нужно активировать модель:ollama run gemma3:27bТеперь, когда у\xa0нас есть практически идеальный диаризованный транскрипт, время задействовать тяжёлую артиллерию\xa0— Gemma 27B, запущенную и управляемую через Ollama. Наша задача на\xa0этом этапе\xa0— «скормить» ей полученный текст и вежливо, но\xa0настойчиво попросить сделать качественную выжимку: о\xa0чём говорили, к\xa0каким выводам пришли, что\xa0решили, какие задачи поставили и на\xa0кого их повесили.Здесь важную роль играет правильно составленный запрос к\xa0модели. Я формулирую промпт примерно так:«Ты мой эффективный AI‑ассистент по\xa0анализу стенограмм совещаний и лекций. Вот тебе текст разговора нескольких людей. Сделай из\xa0него структурированное саммари на\xa0русском языке. В\xa0саммари обязательно выдели следующие пункты (можно использовать маркированные списки):1. Основные обсуждавшиеся темы или\xa0вопросы.2. Ключевые аргументы, предложения или\xa0идеи, высказанные участниками (если\xa0были).3. Принятые решения (если таковые\xa0были).4. Поставленные задачи с\xa0указанием ответственных\xa0лиц (если это можно однозначно понять из\xa0текста).5. Главные выводы или\xa0итоги обсуждения».Ollama отправляет этот промпт вместе с\xa0текстом нашей Gemma, и она, немного подумав (время и скорость обработки зависит от\xa0выбранной модели и вашего\xa0железа), выдаёт готовое саммари. Настоящая AI‑магия в\xa0действии!# Ключевые настройки скрипта\n\n--model - имя локальной LLM-модели в Ollama (“gemma:27b”, “llama3:8b”...) \n--no-stream - отключает потоковую генерацию (по умолчанию - включена) \n--timeout - ограничивает время ожидания ответа \nmax_chars - ограничивает длину текста для LLM (по умолчанию 15 000) \nsystem_prompt - инструкция для модели (как структурировать Markdown-резюме) \nВходной файл должен быть в формате JSON: `[{ “speaker”: “...”, “text”: “...”, “start”: ..., “end”: ... }, ...]Шаг 5: Все дороги ведут в Obsidian. Наводим порядок, систематизируем и пользуемся результатамиИ вот он, долгожданный финал нашего увлекательного путешествия. Собираем все наши артефакты: исходный «сырой» транскрипт от\xa0Whisper, диаризованный текст от\xa0NeMo, блестящее саммари от\xa0Gemma\xa0— и аккуратно, с\xa0любовью укладываем это богатство в\xa0наше хранилище Obsidian. Как\xa0это сделать? Вариантов масса:1. Старым дедовским способом\xa0— руками: скопировал\xa0— вставил. Долго, муторно, неэффективно, и вообще не\xa0наш метод, если мы говорим о\xa0регулярных задачах и автоматизации.2. Магия скриптов\xa0— наш выбор. Пишем небольшой (или большой, в\xa0зависимости от\xa0ваших амбиций) скрипт на\xa0Python, который будет выполнять все предыдущие шаги по\xa0очереди, а\xa0затем самостоятельно создавать новую заметку в\xa0Obsidian, правильно её называть (например, по\xa0дате и теме встречи или\xa0по\xa0имени исходного аудиофайла), добавлять теги, вставлять саммари, диаризованный транскрипт, а\xa0может, даже ссылку на\xa0исходный аудиофайл. В\xa0общем полный автомат, мечта любого лентяя (в хорошем смысле этого слова).3. Плагины Obsidian: расширяем горизонты. Тут тоже есть где разгуляться творческой мысли. Можно использовать плагин Obsidian Shell Commands для\xa0запуска Python‑скрипта прямо из\xa0интерфейса Obsidian или\xa0плагин Templater для\xa0создания новых заметок по\xa0заранее подготовленному красивому шаблону, куда будут автоматически подставляться все наши данные.Как\xa0может выглядеть итоговая заметка в\xa0Obsidian (мой\xa0личный вариант, который я постоянно дорабатываю)Так шаг за\xa0шагом из\xa0непонятного и объёмного аудиофайла мы получаем структурированную осмысленную информацию, с\xa0которой можно работать, по\xa0тексту которой можно искать, которой можно делиться с\xa0коллегами, и просто чувствовать себя настоящим молодцом, победившим информационный хаос. Удобно обернуть всё это дело в\xa0простенький GUI, как\xa0у\xa0меня и вышло:import os\nimport subprocess\n\ndef run_pipeline(filepath, use_clean=True, do_summary=True, temperature="0", beam_size=None, condition=False, prompt=""):\n \xa0 if not filepath or not os.path.exists(filepath):\n \xa0 \xa0 \xa0 raise FileNotFoundError(f"Файл не найден: {filepath}")\n\n \xa0 base_name = os.path.splitext(filepath)[0]\n \xa0 cleaned_file = base_name + "_cleaned.wav"\n \xa0 audio_file = cleaned_file if use_clean else filepath\n\n \xa0 # Шаг 1: Очистка аудио (опционально)\n \xa0 if use_clean:\n \xa0 \xa0 \xa0 subprocess.run(["python", "clean_audio.py", filepath])\n\n \xa0 # Шаг 2: Транскрипция Whisper\n \xa0 cmd = [\n \xa0 \xa0 \xa0 "python", "transcribe.py",\n \xa0 \xa0 \xa0 audio_file,\n \xa0 \xa0 \xa0 "--lang", "ru",\n \xa0 \xa0 \xa0 "--temperature", temperature,\n \xa0 ]\n \xa0 if beam_size:\n \xa0 \xa0 \xa0 cmd += ["--beam_size", str(beam_size)]\n \xa0 if condition:\n \xa0 \xa0 \xa0 cmd.append("--condition")\n \xa0 if prompt:\n \xa0 \xa0 \xa0 cmd += ["--prompt", prompt]\n \xa0 subprocess.run(cmd)\n\n \xa0 # Шаг 3: Диаризация NeMo\n \xa0 json_file = os.path.splitext(audio_file)[0] + ".json"\n \xa0 subprocess.run(["python", "diarize_nemo_auto.py", audio_file, json_file, "12"])\n\n \xa0 # Шаг 4: Конвертация в TXT / MD\n \xa0 tagged_json = os.path.splitext(audio_file)[0] + "_tagged.json"\n \xa0 if os.path.exists(tagged_json):\n \xa0 \xa0 \xa0 from convert_tagged_json_to_txt_md import convert_tagged_json_to_txt_md\n \xa0 \xa0 \xa0 convert_tagged_json_to_txt_md(tagged_json)\n\n \xa0 # Шаг 5: Генерация саммари (опционально)\n \xa0 if do_summary:\n \xa0 \xa0 \xa0 subprocess.run(["python", "summarize_json.py", tagged_json])Как\xa0вам такой подход? А что у других? Сравниваем наш “самосбор” с готовыми решениями, облачными и не оченьЗачем мудрить, если есть облачные гиганты и их свита?Google Speech‑to‑Text, AWS Transcribe, Azure Speech Services, Yandex SpeechKit, AssemblyAI, Otter.ai, Sonix.ai, Fireflies.ai и многие другие ребята, конечно, молодцы. У\xa0них, как\xa0правило, всё очень просто,\xa0быстро, удобно и часто весьма качественно.Чем готовые решения объективно круче:Простота: зарегистрировался, получил API‑ключ (или просто загрузил файл через веб‑интерфейс)\xa0— и через несколько минут получил результат. Никаких сложных установок, настроек зависимостей и чтения многостраничных мануалов.Скорость и масштабируемость: у\xa0этих компаний в\xa0распоряжении дата‑центры с\xa0тысячами мощных серверов. Они способны переваривать огромные объёмы аудио очень и очень\xa0быстро. Если вам нужно обработать терабайты записей в\xa0сжатые сроки\xa0— облака, скорее всего, ваш выбор.Дополнительные «фичи» и «плюшки»: часто облачные сервисы предлагают набор допов\xa0— автоматический анализ тональности речи, выделение ключевых слов и тем, определение эмоций, интеграции с\xa0популярными сервисами (CRM, таск‑менеджеры и\xa0т.\xa0д.).Где облачные сервисы однозначно проигрывают локальному стеку:Деньги, деньги, дребеденьги: практически все облачные сервисы работают по\xa0подписке или\xa0тарифицируют каждую обработанную минуту аудио (или каждый распознанный символ). Если вы пользуетесь их услугами регулярно и в\xa0больших объемах, ежемесячные счета набегают весьма приличные.Мои драгоценные данные у «дяди Сэма» (или у\xa0кого‑то ещё): вопрос конфиденциальности и безопасности данных стоит очень остро. Вы доверяете свои, возможно, очень чувствительные аудиозаписи третьей стороне. Не\xa0всегда хочется (а иногда и просто нельзя по\xa0соображениям безопасности или\xa0требованиям закона) светить совещания и\xa0личные разговоры.Без\xa0интернета\xa0— никуда, от\xa0слова «совсем»: тут всё предельно понятно. Есть интернет\xa0— есть сервис. Нет интернета\xa0— приходите завтра.Гибкость? Не, не\xa0слышали (или слышали, но\xa0не\xa0про\xa0вашу честь): что\xa0разработчики сервиса вам предоставили, тем вы и пользуетесь. Шаг влево, шаг вправо от\xa0стандартного функционала\xa0— или\xa0невозможно, или\xa0требует дополнительных затрат и согласований. Кастомизация под\xa0специфические нужды часто сильно ограничена.Чем самодельный пайплайн выигрывает:1. GDPR + офлайн. Данные не\xa0покидают диск. 2. Нулевые вложения\xa0— нет платных подписок. 3. Качество расшифровки. Gemma\u202f27B выделяет agenda / decisions / action\u202fitems почти как\xa0GPT‑4. 4. Интеграция с\xa0Obsidian. «Минутки» попадают в\xa0единый граф заметок, ищутся, тегируются, попадают в\xa0Dataview‑таблицы. 5. Гибкость. Хотите выгрузку в\xa0Jira или\xa0Notion\xa0— меняете промпт/скрипт, а\xa0не\xa0ждёте фичи от\xa0SaaS.Другие локальные решения (open-source и не только, если они существуют в природе)Тут тоже есть из\xa0чего выбрать, если хорошенько покопаться в\xa0закромах GitHub и других ресурсов. Однако найти готовое, комплексное и такое\xa0же гибкое решение довольно сложно.Сейчас Альфа тестирует плагин для\xa0Контур.Толка, чтобы транскрибировать и делать саммари созвонов в\xa0инфраструктуре банка на\xa0платформе AlfaGen. Это приятный доп для\xa0сотрудника\xa0— всё собрано и настроено за\xa0тебя, можно грузить любые рабочие обсуждения и даже клиентские данные, они не\xa0утекут за\xa0контур. Точно жду этот плагин.Альтернативы Whisper для\xa0транскрибации: конечно, существуют другие open‑source ASR‑модели и фреймворки (Kaldi, DeepSpeech, Vosk). Но\xa0Whisper, на\xa0мой взгляд,\xa0лидер по\xa0соотношению простоты использования, доступности предобученных моделей и итоговой точности для\xa0большинства языков и задач.Альтернативы NeMo для\xa0диаризации: можно посмотреть в\xa0сторону библиотек pyannote.audio\xa0— очень мощный и активно развивающийся инструмент. Выбор инструмента часто зависит от\xa0ваших специфических требований, качества аудио и готовности разбираться в\xa0особенностях библиотеки.Альтернативы Ollama/Gemma для\xa0запуска LLM: для\xa0локального запуска больших языковых моделей есть довольно много различных путей. Можно напрямую возиться с llama.cpp (если вы хардкорный разработчик и любите всё контролировать до\xa0деталей), есть LM Studio, GPT4All, Jan.ai. Ollama мне импонирует невероятной простотой установки и использования и удобным API. Выбор самих моделей просто огромен: тут вам и различные версии Llama (Llama 2, Llama 3), и Mistral, и Mixtral и многие другие. Gemma 27B\xa0— сбалансированный вариант для\xa0достаточно мощных домашних или\xa0рабочих ПК с\xa0качественной саммаризацией и анализом текста.Альтернативы Obsidian для\xa0управления знаниями: для\xa0заметок и построения персональной базы знаний есть множество других прекрасных инструментов: Joplin, Logseq, Notion (хотя он уже не\xa0совсем локальный и у\xa0него свои нюансы с\xa0приватностью), Standard Notes, Trillium Notes и другие. Obsidian с\xa0его ставкой на\xa0локальное хранение данных в\xa0простом Markdown‑формате, невероятной гибкостью, системой плагинов и активным сообществом\xa0— моя давняя и неизменная любовь.\nПолезные ссылки, чтобы собрать AI-пайплайн для транскрибацииWhisper от\xa0OpenAI: https://github.com/openai/whisperNVIDIA NeMo Toolkit: https://docs.nvidia.com/deeplearning/nemo/user‑guide/docs/en/stableOllama: https://ollama.comGoogle Gemma: https://ai.google.dev/gemmaObsidian: https://obsidian.mdPyTorch: https://pytorch.orgFaster Whisper: https://github.com/guillaumekln/faster‑whisperpyannote.audio (мощная альтернатива NeMo для\xa0задач диаризации спикеров): https://github.com/pyannote/pyannote‑audioLM Studio, Jan.ai, GPT4All (другие популярные инструменты для\xa0локального запуска LLM, если Ollama вам по\xa0какой‑то причине не\xa0подойдёт):https://lmstudio.aihttps://jan.aihttps://gpt4all.ioВыводДерзайте, друзья! Собирайте своих AI‑помощников, автоматизируйте рутину, освобождайте своё время для\xa0более творческих и интересных дел. Пусть работа с\xa0информацией приносит вам только радость, пользу и удовлетворение от\xa0результата. Если у\xa0вас есть вопросы или\xa0идеи по\xa0моему пайплайну или\xa0вы захотите поделиться своим опытом создания подобных систем\xa0— пишите в\xa0комментариях, будет интересно обсудить.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('Как заставить вашу базу данных летать, а не ползать. Часть 1 масштабирование и репликация',), kwargs={}
Результат: как заставить вашу базу данных летать а не ползать часть 1 масштабирование и репликация
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: contains_keywords
Аргументы: args=('Как заставить вашу базу данных летать, а не ползать. Часть 1 масштабирование и репликация', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:19 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('Всем привет! Меня зовут Илья Криволапов, тружусь системным аналитиком в SENSE на проекте одного из цветных банков РФ. В профессии я уже пятый год и, несмотря на фамилию, ломал прод всего лишь несколько незначительных раз (надеюсь).\xa0На досуге я преподаю в университете дисциплину «Хранение и обработка больших объемов данных» и за все время у меня накопилось много полезной информации. Непростительно хранить такой клад у себя в столе, поэтому я подготовил для читателей Хабра ультимативный гайд по оптимизации или хорошему такому, грамотному проектированию баз данных с расчетом на масштабирование.Всего в цикле будет 3 статьи. В первой поговорим о двух разных подходах масштабирования БД и о том, как лучше его делать и как лучше не делать (Никогда. Пожалуйста).\xa0Кому будет полезно? Всем отвечающим за «здоровье» базы данных: DBA, архитекторам, DevOps-инженерам, аналитикам и разработчикам.\xa0Согласны? Узнали? Тогда поехали!Когда база данных кричит «Помогите!»Представьте, ваше приложение стало популярным. Но теперь база данных тормозит, как старый компьютер с Windows XP, а пользователи жалуются, что «все зависает» (а вы уже мечтаете о побеге в Гималаи). Что делать?Масштабирование: два принципиально разных подходаПрежде чем переходить к сложным решениям, важно понять базовые стратегии.1. Вертикальное масштабирование (Scale Up): когда больше — не значит лучшеПо сути, мы делаем наш сервер мощнее по четырем ключевым направлениям:CPU (процессор)Добавляем ядер — теперь сервер может пережевывать больше запросов одновременно. Как шеф-повар с четырьмя руками, который успевает и суп мешать, и котлеты переворачивать.RAM (оперативная память)Увеличиваем «кратковременную память» сервера. Теперь он может держать в уме не 10 таблиц, а 100. И не нужно постоянно «вспоминать», лезть за данными на медленный диск.Диски (HDD → SSD/NVMe)Меняем старый жёсткий диск (как велосипед) на SSD (спортивный мотоцикл). Скорость чтения/записи вырастает в 50-100 раз!СетьУлучшаем «дороги», по которым данные ходят к пользователям. Было как грунтовка — стало как шестиполосное шоссе.Почему это так популярно?✅ Проще некудаНикаких изменений в коде, никаких сложных настроек. Купил сервер мощнее — воткнул вместо старого. Всё работает как прежде, только быстрее.✅ Один сервер — одна головная больНе нужно думать о синхронизации между узлами, распределении запросов. Всё в одном месте — и следить проще, и чинить.✅ Совместимость 100%Ваше приложение даже не заметит подмены. Та же база, те же драйверы — просто теперь летает.Но есть и подводные камни❗️ Физические пределыКак бы вы ни прокачивали свой внедорожник, он никогда не станет космическим кораблём. Максимум RAM в одном сервере — около 6 ТБ (и это будет стоить как небольшой самолёт).❗️ Цена растёт экспоненциально с увеличением мощностиПервые 32 ГБ RAM — 200. Следующие 32ГБ — уже 300. А когда добираетесь до 1 ТБ — каждая добавленная планта памяти увеличивает стоимость на тысячи долларов.❗️ «Я упал — все упали»Один сервер = одна точка отказа. Если он отвалится, поминай как звали.❗️ Апгрейд = downtimeЧтобы добавить памяти, часто нужно выключать сервер. Для многих систем даже небольшая недоступность критически важных сервисов недопустима.Когда вертикальное масштабирование — идеальный выбор?Стартапы на этапе ростаПока у вас 50-100 тысяч пользователей — проще раз в полгода переезжать на сервер мощнее.Системы с предсказуемой нагрузкойЕсли у вас нет резких скачков трафика (как во время Черной пятницы), вертикальное масштабирование покрывает все нужды.Когда важна простотаНет команды DevOps? Нет времени на настройку кластеров? Scale-up спасает ситуацию.КейсОдин интернет-магазин столкнулся с проблемой: их PostgreSQL начал захлебываться при RPS == 5000 (запросов в секунду). Решение?Было: Сервер с 16 ядрами CPU, 64 ГБ RAM, HDDСтало: 32 ядра, 256 ГБ RAM, NVMeРезультат?Время отклика упало с 1200 мс до 90 мсСтоимость сервера выросла в 3 разаНо! Разработчики потратили время на миграцию. К счастью, всего 2 дняДля сравнения: выполнение шардирования потребовало бы 2-3 месяца работы и увеличение штата на двух инженеров.Вертикальное масштабирование — как костыль, который иногда превращается в супер-протез. Да, у него есть пределы, но часто именно оно становится самым быстрым и экономичным решением.\xa02. Горизонтальное масштабирование (Scale Out): путь современных высоконагруженных системЧто значит «добавить сервер»?Это как превратить уютную кофейню в сеть ресторанов. Есть три основных способа оптимизации:Репликация (клонирование)Создаем копии главного сервера. Заказы принимает только шеф-повар (master), но готовить помогают другие повара (replicas). Клиенты получают блюда быстрее, ведь официанты (requests) для приготовления своего заказа могут найти любого свободного повара.Шардинг (разделение меню)Даем клиентам возможность посещать разный набор ресторанов: в первом подают суши, во втором — пиццу, в третьем — стейки. Каждый повар специализируется на своём блюде (шарде данных), за счет чего можно достичь увеличения необходимых показателей.Кластеризация (франшиза по доставке еды)Сеть ресторанов с единым стандартом. Каждый может принимать заказы, а данные синхронизируются и маршрутизируются между всеми точками в соответствии с установленными параметрами.Почему крупные компании выбирают scale-out?✅ Масштабируемость до бесконечностиНужно больше мощности? Просто добавьте ещё серверов. Технически ограничений нет — Facebook использует десятки тысяч серверов для своих баз данных.✅ ОтказоустойчивостьУпал один сервер? Система даже не заметит. Данные хранятся в нескольких экземплярах, как важные документы в сейфе с дубликатами.✅ Экономия на железе10 серверов по 5 тыс долларов часто дешевле одного за 100 тыс долларов.✅ Гибкость распределения нагрузкиПик активности в Азии? Увеличиваем количество серверов в Сингапуре. Ночью можно часть выключить для экономии.Но не все так просто❗️ Архитектурная головная больТеперь ваше приложение должно понимать:куда писать новые данные;откуда читать актуальную информацию;как работать с транзакциями между серверами.❗️ CAP-теорема — приходится выбиратьКак в том анекдоте про «быстро, дёшево, качественно» — можно выбрать только два из трёх:Консистентность (все данные актуальны);Доступность (система всегда отвечает);Устойчивость к разделению (работает при обрывах связи).❗️ Сложность администрированияТеперь нужно следить не за одним сервером, а за целым зоопарком. Автоматизация становится must-have.❗️ Особенности шардингаCross-shard запросы как заказ комплексного обеда из разных ресторанов. Сложно, долго, иногда блюда приходят в разное время.Когда горизонтальное масштабирование — идеальный выбор?Высоконагруженные сервисыСоцсети, маркетплейсы, SaaS-платформы — где десятки тысяч запросов в секунду.Глобальные проектыНужно размещать данные ближе к пользователям в разных регионах.Критически важные системыКогда простой недопустим даже на минуту — банки, платежные системы.КейсОдин игровой сервис столкнулся с проблемой: 2 млн активных пользователей ежедневно, PostgreSQL не справлялся при RPS==5000. Решение?Разделили данные по игровым регионам (шардинг)Для каждого региона сделали 3 репликиНастроили автоматическое переключение при сбояхРезультат:Пропускная способность выросла в 20 разЗадержки уменьшились с 2 секунд до 50 мсОтказоустойчивость — система переживет падение любого из серверовПравда, пришлось:Переписать 30% кода приложенияНанять двух DevOps-инженеровВнедрить сложную систему мониторингаГоризонтальное масштабирование — как переход от ларька с шаурмой к сети ресторанов. Сложнее управлять, зато нет ограничений по масштабированию. Главное — правильно выбрать стратегию (Репликация, шардинг или кластер. А может и вовсе решение, совмещающее приведенные механизмы) и быть готовым к новым архитектурным вызовам.Вертикальное vs горизонтальное масштабированиеКритерий🔼 Вертикальное масштабирование↔️ Горизонтальное масштабированиеПринцип работы"Вырасти выше"Апгрейд одного сервера"Расширяйся шире"Добавление новых узловСкорость внедрения🟢 Быстро (дни)Замена железа🟡 Долго\xa0(недели/месяцы)Изменение архитектуры и кодовой базыМакс. мощность🔴 Жесткие ограниченияФизические лимиты железа🟢 БезграничноМожно добавлять узлы бесконечно. Если сможете за ними уследитьОтказоустойчивость🔴 Единая точка отказаСбой сервера критичен и приводит к недоступности🟢 АвтовосстановлениеРаботает при падении узловЭкономика🔴 Дорогой апгрейдЦена растет экспоненциально🟢 Линейные затратыЭкономия на массовостиАдминистрирование🟢 Простое1 сервер = 1 точка управления🔴 СложноеТребует оркестрации и тех. поддержанияИзменения кода🟢 МинимальныеЧасто не требуются🔴 ЗначительныеПоддержка распределенностиИдеальный кейсСтартапыСредние нагрузкиMVPHighload-системыГлобальные проектыКритически-важные сервисыРепликация данных: как создать непотопляемую систему-броненосецПосле сравнения подходов становится ясно: горизонтальное масштабирование — это не только про мощность, но и про надежность. И здесь на первый план выходит репликация — технология, которая:Делает вашу БД практически неуязвимой к сбоям;Ускоряет чтение в десятки раз;Позволяет пережить даже падение дата-центра.Почему это важно?Представьте, что ваша база данных — это единственный экземпляр важного документа. Если он потеряется или будет поврежден — катастрофа неизбежна. Репликация решает эту проблему, создавая несколько синхронизированных копий данных. Это как сделать нотариально заверенные копии паспорта и хранить их в разных местах.Что такое репликация на практике?Это процесс автоматического копирования данных с главного сервера (мастера) на подчинённые (реплики).Как это работает на примере кейса с рестораном, который был рассмотрен в рамках предыдущей статьи:Управляющая компания (мастер) получает поставку расходных материалов, приуроченных к новому году (новую информацию);Он сразу рассылает её во все филиалы (реплики);Клиент может обратиться в любой филиал и получить продукт в сезонной упаковке, на которой он найдет приятное поздравление с новым годом.Основные типы репликации: как выбрать правильный подходОкей, поиграем с аналогиями еще. Представьте, что вы капитан корабля, перевозящего ценный груз (данные). Можно отправить его:С охраной, которая подтвердит доставку (синхронная репликация);Быстро, но без гарантий (асинхронная репликация);С частичным сопровождением (полусинхронная репликация).Выбор типа репликации определяет, насколько надёжно и быстро будут доставлены ваши данные. Давайте разберем каждый вариант.Синхронная репликация: надёжность прежде всегоКак работает:Мастер ждёт подтверждения от ВСЕХ реплик перед завершением операции записи. Это как отправка документов с курьером, который требует подпись о получении в каждом отделении.Техническая реализация в PostgreSQL:synchronous_standby_names = \'FIRST 2 (node1, node2, node3)\'Плюсы:✅ Полная гарантия сохранности данных;✅ Простота аварийного восстановления.Минусы:❗️ Большие временные задержки (200-500 мс);❗️Процессы в системе могут быть приостановлены при проблемах с репликами;❗️ Ограниченная геораспределенность.Пример из практики:В банковской системе при 3 синхронных репликах:Обычная задержка перевода: 300 мс;При падении одной реплики: система продолжает работать;При падении двух: переводы временно блокируются.Асинхронная репликация: скорость любой ценойКак работает:Мастер записывает данные локально и сразу отвечает клиенту. Реплики обновляются в фоновом режиме. Это как отправить письмо по электронной почте — вы знаете, что оно дойдёт, но не знаете когда и будет ли оно прочитано.Настройка в MySQL:CHANGE MASTER TO MASTER_DELAY = 3600; -- Задержка репликации 1 часПлюсы:✅ Минимальные задержки (1-5 мс);✅ Работает при любых проблемах с репликами;✅ Идеально для географического распределения.Минусы:❗️ Возможна потеря последних данных;❗️ Сложное восстановление после аварий;❗️ Время обновления для каждой из реплик может быть разным.Реальный кейс:Пользователь публикует контент от своего имени:Он же сможет видеть его сразу после отправки;Подписчики могут увидеть его с задержкой 2-5 сек;При аварии возможна всего контента, опубликованного за последние 5 минут.Полусинхронная репликация: золотая серединаКак работает:Мастер ждёт подтверждения только от N реплик (обычно 1-2). Это как отправка документов с требованием хотя бы одного подтверждения о получении.Конфигурация в MySQL:rpl_semi_sync_master_wait_for_slave_count = 1Плюсы:✅ Разумный баланс скорости и надёжности;✅ Частичная защита от потерь данных;✅ Хорошая геораспределенность.Минусы:❗️ Более сложная настройка;❗️ Нужен мониторинг работы всех реплик, особое внимание к «отстающим»;❗️ Возможная потеря данных.Пример использования:Предположим, мы реализовали данный механизм для интернет-магазина:Подтверждение заказа происходит после сохранения в мастере и одной реплике;Задержка около 50-100 мс;Потеря данных возможна только при одновременном падении мастера и основной реплики.Как выбрать тип репликации?Для финансовых систем → СинхроннаяПример: Банковские переводы, где важен каждый бит данныхДля соцсетей/аналитики → АсинхроннаяПример: Лента новостей, где скорость важнее актуальностиДля e-commerce → ПолусинхроннаяПример: Корзина покупок, где нужен баланс скорости и надёжностиСовет: Современные СУБД позволяют комбинировать разные типы репликации для разных таблиц!Выбор типа репликации — это всегда компромисс между:Скоростью (асинхронная);Надежностью (синхронная);Балансом (полусинхронная).Как опытный капитан, вы должны выбрать оптимальный маршрут для своего ценного груза данных. Правильный выбор сделает вашу систему быстрой, надежной и устойчивой к штормам.Почему репликация — must have для серьёзных проектов?✅ Живучесть системыПри падении мастера одна из реплик мгновенно берет управление на себя. Как в авиации — если пилот теряет сознание, его сразу заменяет второй пилот.✅ Молниеносное чтение данныхЗапросы можно распределять по всем репликам. Представьте магазин, где 100 кассиров вместо одного. Разница очевидна!✅ Географическая независимостьДанные можно разместить ближе к пользователям. Для москвичей — сервер в Москве, для жителей Владивостока — во Владивостоке.✅ Безболезненное обновлениеМожно выводить мастера на обслуживание без остановки работы — система автоматически переключится на реплики.Тёмная сторона репликации❗️ Головная боль с синхронизациейКогда реплики отстают от мастера, пользователи могут видеть устаревшие данные. Представьте, что баланс на карте обновляется с задержкой в 5 минут… Приятного тут явно мало!❗️ Дорогое удовольствиеКаждая реплика требует ресурсов. В некоторых случаях эти затраты нецелесообразны.❗️ Сложность настройкиНужно грамотно настроить параметры репликации, иначе можно получить "мёртвые" реплики, которые не успевают за мастером.Когда репликация спасает проект?Высоконагруженные сервисыСоцсети, где чтений в 100 раз больше, чем обновления/создания записейСистемы, работающие с критически важными даннымиБанки, биржи, медицинские учрежденияГлобальные проектыСервисы с пользователями в разных часовых поясахРепликация — это страховой полис для ваших данных. Она требует инвестиций и грамотной настройки, но когда случается беда, вы понимаете, что каждая копейка была потрачена не зря.\xa0ИтогОптимизация базы данных — это искусство находить баланс между скоростью, надёжностью и масштабируемостью. В первой части мы рассмотрели два ключевых подхода к масштабированию: вертикальное и горизонтальное Первое позволяет быстро устранить узкие места за счёт усиления серверной части, а второе открывает путь к построению распределённых отказоустойчивых систем, готовых к любым нагрузкам.Да, в некоторых случаях легче, быстрее и даже правильнее будет просто «накинуть железа», но по-настоящему мощные системы сложно создать без грамотного проектирования и применения методов репликации и шардирования – подхода, при котором данные и нагрузка распределяются между несколькими узлами. Мы рассмотрим устройство шардинга, кейсы для внедрения и сложности, с которыми придется столкнуться.\xa0А пока давайте обсудим, как вы решаете проблему «внезапного» роста нагрузки и объёма данных. Буду рад узнать про Ваш опыт в комментариях!',), kwargs={}
Результат: всем привет меня зовут илья криволапов тружусь системным аналитиком в sense на проекте одного из цветных банков рф в профессии я уже пятый год и несмотря на фамилию ломал прод всего лишь несколько незначительных раз надеюсь на досуге я преподаю в университете дисциплину хранение и обработка больших объемов данных и за все время у меня накопилось много полезной информации непростительно хранить такой клад у себя в столе поэтому я подготовил для читателей хабра ультимативный гайд по оптимизации или хорошему такому грамотному проектированию баз данных с расчетом на масштабированиевсего в цикле будет 3 статьи в первой поговорим о двух разных подходах масштабирования бд и о том как лучше его делать и как лучше не делать никогда пожалуйста кому будет полезно всем отвечающим за здоровье базы данных dba архитекторам devopsинженерам аналитикам и разработчикам согласны узнали тогда поехаликогда база данных кричит помогитепредставьте ваше приложение стало популярным но теперь база данных тормозит как старый компьютер с windows xp а пользователи жалуются что все зависает а вы уже мечтаете о побеге в гималаи что делатьмасштабирование два принципиально разных подходапрежде чем переходить к сложным решениям важно понять базовые стратегии1 вертикальное масштабирование scale up когда больше  не значит лучшепо сути мы делаем наш сервер мощнее по четырем ключевым направлениямcpu процессордобавляем ядер  теперь сервер может пережевывать больше запросов одновременно как шефповар с четырьмя руками который успевает и суп мешать и котлеты переворачиватьram оперативная памятьувеличиваем кратковременную память сервера теперь он может держать в уме не 10 таблиц а 100 и не нужно постоянно вспоминать лезть за данными на медленный дискдиски hdd  ssdnvmeменяем старый жёсткий диск как велосипед на ssd спортивный мотоцикл скорость чтениязаписи вырастает в 50100 разсетьулучшаем дороги по которым данные ходят к пользователям было как грунтовка  стало как шестиполосное шоссепочему это так популярно проще некуданикаких изменений в коде никаких сложных настроек купил сервер мощнее  воткнул вместо старого всё работает как прежде только быстрее один сервер  одна головная больне нужно думать о синхронизации между узлами распределении запросов всё в одном месте  и следить проще и чинить совместимость 100ваше приложение даже не заметит подмены та же база те же драйверы  просто теперь летаетно есть и подводные камни физические пределыкак бы вы ни прокачивали свой внедорожник он никогда не станет космическим кораблём максимум ram в одном сервере  около 6 тб и это будет стоить как небольшой самолёт цена растёт экспоненциально с увеличением мощностипервые 32 гб ram  200 следующие 32гб  уже 300 а когда добираетесь до 1 тб  каждая добавленная планта памяти увеличивает стоимость на тысячи долларов я упал  все упалиодин сервер  одна точка отказа если он отвалится поминай как звали апгрейд  downtimeчтобы добавить памяти часто нужно выключать сервер для многих систем даже небольшая недоступность критически важных сервисов недопустимакогда вертикальное масштабирование  идеальный выборстартапы на этапе ростапока у вас 50100 тысяч пользователей  проще раз в полгода переезжать на сервер мощнеесистемы с предсказуемой нагрузкойесли у вас нет резких скачков трафика как во время черной пятницы вертикальное масштабирование покрывает все нуждыкогда важна простотанет команды devops нет времени на настройку кластеров scaleup спасает ситуациюкейсодин интернетмагазин столкнулся с проблемой их postgresql начал захлебываться при rps  5000 запросов в секунду решениебыло сервер с 16 ядрами cpu 64 гб ram hddстало 32 ядра 256 гб ram nvmeрезультатвремя отклика упало с 1200 мс до 90 мсстоимость сервера выросла в 3 разано разработчики потратили время на миграцию к счастью всего 2 днядля сравнения выполнение шардирования потребовало бы 23 месяца работы и увеличение штата на двух инженероввертикальное масштабирование  как костыль который иногда превращается в суперпротез да у него есть пределы но часто именно оно становится самым быстрым и экономичным решением 2 горизонтальное масштабирование scale out путь современных высоконагруженных системчто значит добавить серверэто как превратить уютную кофейню в сеть ресторанов есть три основных способа оптимизациирепликация клонированиесоздаем копии главного сервера заказы принимает только шефповар master но готовить помогают другие повара replicas клиенты получают блюда быстрее ведь официанты requests для приготовления своего заказа могут найти любого свободного поварашардинг разделение менюдаем клиентам возможность посещать разный набор ресторанов в первом подают суши во втором  пиццу в третьем  стейки каждый повар специализируется на своём блюде шарде данных за счет чего можно достичь увеличения необходимых показателейкластеризация франшиза по доставке едысеть ресторанов с единым стандартом каждый может принимать заказы а данные синхронизируются и маршрутизируются между всеми точками в соответствии с установленными параметрамипочему крупные компании выбирают scaleout масштабируемость до бесконечностинужно больше мощности просто добавьте ещё серверов технически ограничений нет  facebook использует десятки тысяч серверов для своих баз данных отказоустойчивостьупал один сервер система даже не заметит данные хранятся в нескольких экземплярах как важные документы в сейфе с дубликатами экономия на железе10 серверов по 5 тыс долларов часто дешевле одного за 100 тыс долларов гибкость распределения нагрузкипик активности в азии увеличиваем количество серверов в сингапуре ночью можно часть выключить для экономиино не все так просто архитектурная головная больтеперь ваше приложение должно пониматькуда писать новые данныеоткуда читать актуальную информациюкак работать с транзакциями между серверами capтеорема  приходится выбиратькак в том анекдоте про быстро дёшево качественно  можно выбрать только два из трёхконсистентность все данные актуальныдоступность система всегда отвечаетустойчивость к разделению работает при обрывах связи сложность администрированиятеперь нужно следить не за одним сервером а за целым зоопарком автоматизация становится musthave особенности шардингаcrossshard запросы как заказ комплексного обеда из разных ресторанов сложно долго иногда блюда приходят в разное времякогда горизонтальное масштабирование  идеальный выборвысоконагруженные сервисысоцсети маркетплейсы saasплатформы  где десятки тысяч запросов в секундуглобальные проектынужно размещать данные ближе к пользователям в разных регионахкритически важные системыкогда простой недопустим даже на минуту  банки платежные системыкейсодин игровой сервис столкнулся с проблемой 2 млн активных пользователей ежедневно postgresql не справлялся при rps5000 решениеразделили данные по игровым регионам шардингдля каждого региона сделали 3 репликинастроили автоматическое переключение при сбояхрезультатпропускная способность выросла в 20 раззадержки уменьшились с 2 секунд до 50 мсотказоустойчивость  система переживет падение любого из серверовправда пришлосьпереписать 30 кода приложениянанять двух devopsинженероввнедрить сложную систему мониторингагоризонтальное масштабирование  как переход от ларька с шаурмой к сети ресторанов сложнее управлять зато нет ограничений по масштабированию главное  правильно выбрать стратегию репликация шардинг или кластер а может и вовсе решение совмещающее приведенные механизмы и быть готовым к новым архитектурным вызовамвертикальное vs горизонтальное масштабированиекритерий вертикальное масштабирование горизонтальное масштабированиепринцип работывырасти вышеапгрейд одного серверарасширяйся ширедобавление новых узловскорость внедрения быстро днизамена железа долго неделимесяцыизменение архитектуры и кодовой базымакс мощность жесткие ограниченияфизические лимиты железа безграничноможно добавлять узлы бесконечно если сможете за ними уследитьотказоустойчивость единая точка отказасбой сервера критичен и приводит к недоступности автовосстановлениеработает при падении узловэкономика дорогой апгрейдцена растет экспоненциально линейные затратыэкономия на массовостиадминистрирование простое1 сервер  1 точка управления сложноетребует оркестрации и тех поддержанияизменения кода минимальныечасто не требуются значительныеподдержка распределенностиидеальный кейсстартапысредние нагрузкиmvphighloadсистемыглобальные проектыкритическиважные сервисырепликация данных как создать непотопляемую системуброненосецпосле сравнения подходов становится ясно горизонтальное масштабирование  это не только про мощность но и про надежность и здесь на первый план выходит репликация  технология котораяделает вашу бд практически неуязвимой к сбоямускоряет чтение в десятки разпозволяет пережить даже падение датацентрапочему это важнопредставьте что ваша база данных  это единственный экземпляр важного документа если он потеряется или будет поврежден  катастрофа неизбежна репликация решает эту проблему создавая несколько синхронизированных копий данных это как сделать нотариально заверенные копии паспорта и хранить их в разных местахчто такое репликация на практикеэто процесс автоматического копирования данных с главного сервера мастера на подчинённые репликикак это работает на примере кейса с рестораном который был рассмотрен в рамках предыдущей статьиуправляющая компания мастер получает поставку расходных материалов приуроченных к новому году новую информациюон сразу рассылает её во все филиалы репликиклиент может обратиться в любой филиал и получить продукт в сезонной упаковке на которой он найдет приятное поздравление с новым годомосновные типы репликации как выбрать правильный подходокей поиграем с аналогиями еще представьте что вы капитан корабля перевозящего ценный груз данные можно отправить егос охраной которая подтвердит доставку синхронная репликациябыстро но без гарантий асинхронная репликацияс частичным сопровождением полусинхронная репликациявыбор типа репликации определяет насколько надёжно и быстро будут доставлены ваши данные давайте разберем каждый вариантсинхронная репликация надёжность прежде всегокак работаетмастер ждёт подтверждения от всех реплик перед завершением операции записи это как отправка документов с курьером который требует подпись о получении в каждом отделениитехническая реализация в postgresqlsynchronous_standby_names  first 2 node1 node2 node3плюсы полная гарантия сохранности данных простота аварийного восстановленияминусы большие временные задержки 200500 мспроцессы в системе могут быть приостановлены при проблемах с репликами ограниченная геораспределенностьпример из практикив банковской системе при 3 синхронных репликахобычная задержка перевода 300 мспри падении одной реплики система продолжает работатьпри падении двух переводы временно блокируютсяасинхронная репликация скорость любой ценойкак работаетмастер записывает данные локально и сразу отвечает клиенту реплики обновляются в фоновом режиме это как отправить письмо по электронной почте  вы знаете что оно дойдёт но не знаете когда и будет ли оно прочитанонастройка в mysqlchange master to master_delay  3600  задержка репликации 1 часплюсы минимальные задержки 15 мс работает при любых проблемах с репликами идеально для географического распределенияминусы возможна потеря последних данных сложное восстановление после аварий время обновления для каждой из реплик может быть разнымреальный кейспользователь публикует контент от своего именион же сможет видеть его сразу после отправкиподписчики могут увидеть его с задержкой 25 секпри аварии возможна всего контента опубликованного за последние 5 минутполусинхронная репликация золотая серединакак работаетмастер ждёт подтверждения только от n реплик обычно 12 это как отправка документов с требованием хотя бы одного подтверждения о полученииконфигурация в mysqlrpl_semi_sync_master_wait_for_slave_count  1плюсы разумный баланс скорости и надёжности частичная защита от потерь данных хорошая геораспределенностьминусы более сложная настройка нужен мониторинг работы всех реплик особое внимание к отстающим возможная потеря данныхпример использованияпредположим мы реализовали данный механизм для интернетмагазинаподтверждение заказа происходит после сохранения в мастере и одной репликезадержка около 50100 мспотеря данных возможна только при одновременном падении мастера и основной репликикак выбрать тип репликациидля финансовых систем  синхроннаяпример банковские переводы где важен каждый бит данныхдля соцсетейаналитики  асинхроннаяпример лента новостей где скорость важнее актуальностидля ecommerce  полусинхроннаяпример корзина покупок где нужен баланс скорости и надёжностисовет современные субд позволяют комбинировать разные типы репликации для разных таблицвыбор типа репликации  это всегда компромисс междускоростью асинхроннаянадежностью синхроннаябалансом полусинхроннаякак опытный капитан вы должны выбрать оптимальный маршрут для своего ценного груза данных правильный выбор сделает вашу систему быстрой надежной и устойчивой к штормампочему репликация  must have для серьёзных проектов живучесть системыпри падении мастера одна из реплик мгновенно берет управление на себя как в авиации  если пилот теряет сознание его сразу заменяет второй пилот молниеносное чтение данныхзапросы можно распределять по всем репликам представьте магазин где 100 кассиров вместо одного разница очевидна географическая независимостьданные можно разместить ближе к пользователям для москвичей  сервер в москве для жителей владивостока  во владивостоке безболезненное обновлениеможно выводить мастера на обслуживание без остановки работы  система автоматически переключится на репликитёмная сторона репликации головная боль с синхронизациейкогда реплики отстают от мастера пользователи могут видеть устаревшие данные представьте что баланс на карте обновляется с задержкой в 5 минут приятного тут явно мало дорогое удовольствиекаждая реплика требует ресурсов в некоторых случаях эти затраты нецелесообразны сложность настройкинужно грамотно настроить параметры репликации иначе можно получить мёртвые реплики которые не успевают за мастеромкогда репликация спасает проектвысоконагруженные сервисысоцсети где чтений в 100 раз больше чем обновлениясоздания записейсистемы работающие с критически важными даннымибанки биржи медицинские учрежденияглобальные проектысервисы с пользователями в разных часовых поясахрепликация  это страховой полис для ваших данных она требует инвестиций и грамотной настройки но когда случается беда вы понимаете что каждая копейка была потрачена не зря итогоптимизация базы данных  это искусство находить баланс между скоростью надёжностью и масштабируемостью в первой части мы рассмотрели два ключевых подхода к масштабированию вертикальное и горизонтальное первое позволяет быстро устранить узкие места за счёт усиления серверной части а второе открывает путь к построению распределённых отказоустойчивых систем готовых к любым нагрузкамда в некоторых случаях легче быстрее и даже правильнее будет просто накинуть железа но понастоящему мощные системы сложно создать без грамотного проектирования и применения методов репликации и шардирования  подхода при котором данные и нагрузка распределяются между несколькими узлами мы рассмотрим устройство шардинга кейсы для внедрения и сложности с которыми придется столкнуться а пока давайте обсудим как вы решаете проблему внезапного роста нагрузки и объёма данных буду рад узнать про ваш опыт в комментариях
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: contains_keywords
Аргументы: args=('Всем привет! Меня зовут Илья Криволапов, тружусь системным аналитиком в SENSE на проекте одного из цветных банков РФ. В профессии я уже пятый год и, несмотря на фамилию, ломал прод всего лишь несколько незначительных раз (надеюсь).\xa0На досуге я преподаю в университете дисциплину «Хранение и обработка больших объемов данных» и за все время у меня накопилось много полезной информации. Непростительно хранить такой клад у себя в столе, поэтому я подготовил для читателей Хабра ультимативный гайд по оптимизации или хорошему такому, грамотному проектированию баз данных с расчетом на масштабирование.Всего в цикле будет 3 статьи. В первой поговорим о двух разных подходах масштабирования БД и о том, как лучше его делать и как лучше не делать (Никогда. Пожалуйста).\xa0Кому будет полезно? Всем отвечающим за «здоровье» базы данных: DBA, архитекторам, DevOps-инженерам, аналитикам и разработчикам.\xa0Согласны? Узнали? Тогда поехали!Когда база данных кричит «Помогите!»Представьте, ваше приложение стало популярным. Но теперь база данных тормозит, как старый компьютер с Windows XP, а пользователи жалуются, что «все зависает» (а вы уже мечтаете о побеге в Гималаи). Что делать?Масштабирование: два принципиально разных подходаПрежде чем переходить к сложным решениям, важно понять базовые стратегии.1. Вертикальное масштабирование (Scale Up): когда больше — не значит лучшеПо сути, мы делаем наш сервер мощнее по четырем ключевым направлениям:CPU (процессор)Добавляем ядер — теперь сервер может пережевывать больше запросов одновременно. Как шеф-повар с четырьмя руками, который успевает и суп мешать, и котлеты переворачивать.RAM (оперативная память)Увеличиваем «кратковременную память» сервера. Теперь он может держать в уме не 10 таблиц, а 100. И не нужно постоянно «вспоминать», лезть за данными на медленный диск.Диски (HDD → SSD/NVMe)Меняем старый жёсткий диск (как велосипед) на SSD (спортивный мотоцикл). Скорость чтения/записи вырастает в 50-100 раз!СетьУлучшаем «дороги», по которым данные ходят к пользователям. Было как грунтовка — стало как шестиполосное шоссе.Почему это так популярно?✅ Проще некудаНикаких изменений в коде, никаких сложных настроек. Купил сервер мощнее — воткнул вместо старого. Всё работает как прежде, только быстрее.✅ Один сервер — одна головная больНе нужно думать о синхронизации между узлами, распределении запросов. Всё в одном месте — и следить проще, и чинить.✅ Совместимость 100%Ваше приложение даже не заметит подмены. Та же база, те же драйверы — просто теперь летает.Но есть и подводные камни❗️ Физические пределыКак бы вы ни прокачивали свой внедорожник, он никогда не станет космическим кораблём. Максимум RAM в одном сервере — около 6 ТБ (и это будет стоить как небольшой самолёт).❗️ Цена растёт экспоненциально с увеличением мощностиПервые 32 ГБ RAM — 200. Следующие 32ГБ — уже 300. А когда добираетесь до 1 ТБ — каждая добавленная планта памяти увеличивает стоимость на тысячи долларов.❗️ «Я упал — все упали»Один сервер = одна точка отказа. Если он отвалится, поминай как звали.❗️ Апгрейд = downtimeЧтобы добавить памяти, часто нужно выключать сервер. Для многих систем даже небольшая недоступность критически важных сервисов недопустима.Когда вертикальное масштабирование — идеальный выбор?Стартапы на этапе ростаПока у вас 50-100 тысяч пользователей — проще раз в полгода переезжать на сервер мощнее.Системы с предсказуемой нагрузкойЕсли у вас нет резких скачков трафика (как во время Черной пятницы), вертикальное масштабирование покрывает все нужды.Когда важна простотаНет команды DevOps? Нет времени на настройку кластеров? Scale-up спасает ситуацию.КейсОдин интернет-магазин столкнулся с проблемой: их PostgreSQL начал захлебываться при RPS == 5000 (запросов в секунду). Решение?Было: Сервер с 16 ядрами CPU, 64 ГБ RAM, HDDСтало: 32 ядра, 256 ГБ RAM, NVMeРезультат?Время отклика упало с 1200 мс до 90 мсСтоимость сервера выросла в 3 разаНо! Разработчики потратили время на миграцию. К счастью, всего 2 дняДля сравнения: выполнение шардирования потребовало бы 2-3 месяца работы и увеличение штата на двух инженеров.Вертикальное масштабирование — как костыль, который иногда превращается в супер-протез. Да, у него есть пределы, но часто именно оно становится самым быстрым и экономичным решением.\xa02. Горизонтальное масштабирование (Scale Out): путь современных высоконагруженных системЧто значит «добавить сервер»?Это как превратить уютную кофейню в сеть ресторанов. Есть три основных способа оптимизации:Репликация (клонирование)Создаем копии главного сервера. Заказы принимает только шеф-повар (master), но готовить помогают другие повара (replicas). Клиенты получают блюда быстрее, ведь официанты (requests) для приготовления своего заказа могут найти любого свободного повара.Шардинг (разделение меню)Даем клиентам возможность посещать разный набор ресторанов: в первом подают суши, во втором — пиццу, в третьем — стейки. Каждый повар специализируется на своём блюде (шарде данных), за счет чего можно достичь увеличения необходимых показателей.Кластеризация (франшиза по доставке еды)Сеть ресторанов с единым стандартом. Каждый может принимать заказы, а данные синхронизируются и маршрутизируются между всеми точками в соответствии с установленными параметрами.Почему крупные компании выбирают scale-out?✅ Масштабируемость до бесконечностиНужно больше мощности? Просто добавьте ещё серверов. Технически ограничений нет — Facebook использует десятки тысяч серверов для своих баз данных.✅ ОтказоустойчивостьУпал один сервер? Система даже не заметит. Данные хранятся в нескольких экземплярах, как важные документы в сейфе с дубликатами.✅ Экономия на железе10 серверов по 5 тыс долларов часто дешевле одного за 100 тыс долларов.✅ Гибкость распределения нагрузкиПик активности в Азии? Увеличиваем количество серверов в Сингапуре. Ночью можно часть выключить для экономии.Но не все так просто❗️ Архитектурная головная больТеперь ваше приложение должно понимать:куда писать новые данные;откуда читать актуальную информацию;как работать с транзакциями между серверами.❗️ CAP-теорема — приходится выбиратьКак в том анекдоте про «быстро, дёшево, качественно» — можно выбрать только два из трёх:Консистентность (все данные актуальны);Доступность (система всегда отвечает);Устойчивость к разделению (работает при обрывах связи).❗️ Сложность администрированияТеперь нужно следить не за одним сервером, а за целым зоопарком. Автоматизация становится must-have.❗️ Особенности шардингаCross-shard запросы как заказ комплексного обеда из разных ресторанов. Сложно, долго, иногда блюда приходят в разное время.Когда горизонтальное масштабирование — идеальный выбор?Высоконагруженные сервисыСоцсети, маркетплейсы, SaaS-платформы — где десятки тысяч запросов в секунду.Глобальные проектыНужно размещать данные ближе к пользователям в разных регионах.Критически важные системыКогда простой недопустим даже на минуту — банки, платежные системы.КейсОдин игровой сервис столкнулся с проблемой: 2 млн активных пользователей ежедневно, PostgreSQL не справлялся при RPS==5000. Решение?Разделили данные по игровым регионам (шардинг)Для каждого региона сделали 3 репликиНастроили автоматическое переключение при сбояхРезультат:Пропускная способность выросла в 20 разЗадержки уменьшились с 2 секунд до 50 мсОтказоустойчивость — система переживет падение любого из серверовПравда, пришлось:Переписать 30% кода приложенияНанять двух DevOps-инженеровВнедрить сложную систему мониторингаГоризонтальное масштабирование — как переход от ларька с шаурмой к сети ресторанов. Сложнее управлять, зато нет ограничений по масштабированию. Главное — правильно выбрать стратегию (Репликация, шардинг или кластер. А может и вовсе решение, совмещающее приведенные механизмы) и быть готовым к новым архитектурным вызовам.Вертикальное vs горизонтальное масштабированиеКритерий🔼 Вертикальное масштабирование↔️ Горизонтальное масштабированиеПринцип работы"Вырасти выше"Апгрейд одного сервера"Расширяйся шире"Добавление новых узловСкорость внедрения🟢 Быстро (дни)Замена железа🟡 Долго\xa0(недели/месяцы)Изменение архитектуры и кодовой базыМакс. мощность🔴 Жесткие ограниченияФизические лимиты железа🟢 БезграничноМожно добавлять узлы бесконечно. Если сможете за ними уследитьОтказоустойчивость🔴 Единая точка отказаСбой сервера критичен и приводит к недоступности🟢 АвтовосстановлениеРаботает при падении узловЭкономика🔴 Дорогой апгрейдЦена растет экспоненциально🟢 Линейные затратыЭкономия на массовостиАдминистрирование🟢 Простое1 сервер = 1 точка управления🔴 СложноеТребует оркестрации и тех. поддержанияИзменения кода🟢 МинимальныеЧасто не требуются🔴 ЗначительныеПоддержка распределенностиИдеальный кейсСтартапыСредние нагрузкиMVPHighload-системыГлобальные проектыКритически-важные сервисыРепликация данных: как создать непотопляемую систему-броненосецПосле сравнения подходов становится ясно: горизонтальное масштабирование — это не только про мощность, но и про надежность. И здесь на первый план выходит репликация — технология, которая:Делает вашу БД практически неуязвимой к сбоям;Ускоряет чтение в десятки раз;Позволяет пережить даже падение дата-центра.Почему это важно?Представьте, что ваша база данных — это единственный экземпляр важного документа. Если он потеряется или будет поврежден — катастрофа неизбежна. Репликация решает эту проблему, создавая несколько синхронизированных копий данных. Это как сделать нотариально заверенные копии паспорта и хранить их в разных местах.Что такое репликация на практике?Это процесс автоматического копирования данных с главного сервера (мастера) на подчинённые (реплики).Как это работает на примере кейса с рестораном, который был рассмотрен в рамках предыдущей статьи:Управляющая компания (мастер) получает поставку расходных материалов, приуроченных к новому году (новую информацию);Он сразу рассылает её во все филиалы (реплики);Клиент может обратиться в любой филиал и получить продукт в сезонной упаковке, на которой он найдет приятное поздравление с новым годом.Основные типы репликации: как выбрать правильный подходОкей, поиграем с аналогиями еще. Представьте, что вы капитан корабля, перевозящего ценный груз (данные). Можно отправить его:С охраной, которая подтвердит доставку (синхронная репликация);Быстро, но без гарантий (асинхронная репликация);С частичным сопровождением (полусинхронная репликация).Выбор типа репликации определяет, насколько надёжно и быстро будут доставлены ваши данные. Давайте разберем каждый вариант.Синхронная репликация: надёжность прежде всегоКак работает:Мастер ждёт подтверждения от ВСЕХ реплик перед завершением операции записи. Это как отправка документов с курьером, который требует подпись о получении в каждом отделении.Техническая реализация в PostgreSQL:synchronous_standby_names = \'FIRST 2 (node1, node2, node3)\'Плюсы:✅ Полная гарантия сохранности данных;✅ Простота аварийного восстановления.Минусы:❗️ Большие временные задержки (200-500 мс);❗️Процессы в системе могут быть приостановлены при проблемах с репликами;❗️ Ограниченная геораспределенность.Пример из практики:В банковской системе при 3 синхронных репликах:Обычная задержка перевода: 300 мс;При падении одной реплики: система продолжает работать;При падении двух: переводы временно блокируются.Асинхронная репликация: скорость любой ценойКак работает:Мастер записывает данные локально и сразу отвечает клиенту. Реплики обновляются в фоновом режиме. Это как отправить письмо по электронной почте — вы знаете, что оно дойдёт, но не знаете когда и будет ли оно прочитано.Настройка в MySQL:CHANGE MASTER TO MASTER_DELAY = 3600; -- Задержка репликации 1 часПлюсы:✅ Минимальные задержки (1-5 мс);✅ Работает при любых проблемах с репликами;✅ Идеально для географического распределения.Минусы:❗️ Возможна потеря последних данных;❗️ Сложное восстановление после аварий;❗️ Время обновления для каждой из реплик может быть разным.Реальный кейс:Пользователь публикует контент от своего имени:Он же сможет видеть его сразу после отправки;Подписчики могут увидеть его с задержкой 2-5 сек;При аварии возможна всего контента, опубликованного за последние 5 минут.Полусинхронная репликация: золотая серединаКак работает:Мастер ждёт подтверждения только от N реплик (обычно 1-2). Это как отправка документов с требованием хотя бы одного подтверждения о получении.Конфигурация в MySQL:rpl_semi_sync_master_wait_for_slave_count = 1Плюсы:✅ Разумный баланс скорости и надёжности;✅ Частичная защита от потерь данных;✅ Хорошая геораспределенность.Минусы:❗️ Более сложная настройка;❗️ Нужен мониторинг работы всех реплик, особое внимание к «отстающим»;❗️ Возможная потеря данных.Пример использования:Предположим, мы реализовали данный механизм для интернет-магазина:Подтверждение заказа происходит после сохранения в мастере и одной реплике;Задержка около 50-100 мс;Потеря данных возможна только при одновременном падении мастера и основной реплики.Как выбрать тип репликации?Для финансовых систем → СинхроннаяПример: Банковские переводы, где важен каждый бит данныхДля соцсетей/аналитики → АсинхроннаяПример: Лента новостей, где скорость важнее актуальностиДля e-commerce → ПолусинхроннаяПример: Корзина покупок, где нужен баланс скорости и надёжностиСовет: Современные СУБД позволяют комбинировать разные типы репликации для разных таблиц!Выбор типа репликации — это всегда компромисс между:Скоростью (асинхронная);Надежностью (синхронная);Балансом (полусинхронная).Как опытный капитан, вы должны выбрать оптимальный маршрут для своего ценного груза данных. Правильный выбор сделает вашу систему быстрой, надежной и устойчивой к штормам.Почему репликация — must have для серьёзных проектов?✅ Живучесть системыПри падении мастера одна из реплик мгновенно берет управление на себя. Как в авиации — если пилот теряет сознание, его сразу заменяет второй пилот.✅ Молниеносное чтение данныхЗапросы можно распределять по всем репликам. Представьте магазин, где 100 кассиров вместо одного. Разница очевидна!✅ Географическая независимостьДанные можно разместить ближе к пользователям. Для москвичей — сервер в Москве, для жителей Владивостока — во Владивостоке.✅ Безболезненное обновлениеМожно выводить мастера на обслуживание без остановки работы — система автоматически переключится на реплики.Тёмная сторона репликации❗️ Головная боль с синхронизациейКогда реплики отстают от мастера, пользователи могут видеть устаревшие данные. Представьте, что баланс на карте обновляется с задержкой в 5 минут… Приятного тут явно мало!❗️ Дорогое удовольствиеКаждая реплика требует ресурсов. В некоторых случаях эти затраты нецелесообразны.❗️ Сложность настройкиНужно грамотно настроить параметры репликации, иначе можно получить "мёртвые" реплики, которые не успевают за мастером.Когда репликация спасает проект?Высоконагруженные сервисыСоцсети, где чтений в 100 раз больше, чем обновления/создания записейСистемы, работающие с критически важными даннымиБанки, биржи, медицинские учрежденияГлобальные проектыСервисы с пользователями в разных часовых поясахРепликация — это страховой полис для ваших данных. Она требует инвестиций и грамотной настройки, но когда случается беда, вы понимаете, что каждая копейка была потрачена не зря.\xa0ИтогОптимизация базы данных — это искусство находить баланс между скоростью, надёжностью и масштабируемостью. В первой части мы рассмотрели два ключевых подхода к масштабированию: вертикальное и горизонтальное Первое позволяет быстро устранить узкие места за счёт усиления серверной части, а второе открывает путь к построению распределённых отказоустойчивых систем, готовых к любым нагрузкам.Да, в некоторых случаях легче, быстрее и даже правильнее будет просто «накинуть железа», но по-настоящему мощные системы сложно создать без грамотного проектирования и применения методов репликации и шардирования – подхода, при котором данные и нагрузка распределяются между несколькими узлами. Мы рассмотрим устройство шардинга, кейсы для внедрения и сложности, с которыми придется столкнуться.\xa0А пока давайте обсудим, как вы решаете проблему «внезапного» роста нагрузки и объёма данных. Буду рад узнать про Ваш опыт в комментариях!', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('Как я пытался продавать корпорациям экономию времени',), kwargs={}
Результат: как я пытался продавать корпорациям экономию времени
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: contains_keywords
Аргументы: args=('Как я пытался продавать корпорациям экономию времени', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:20 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('Всякая экономия в конечном счёте сводится к экономии времени. Карл МарксЭто история предпринимательского эксперимента из 2016 года: где я пытался выделиться на перегретом рынке телефонии, создав плагин для экономии времени при звонках. Но, как оказалось, экономия 12 секунд — не всегда весомый аргумент в мире корпоративных продаж. В статье нет технических деталей реализации, только отражение продажно-маркетинговых гипотез. Некоторые символы и буквы в текущем контексте могут читаться как-то иначе, но тогда это были просто буквы.Так получилось что большую часть своей экспертной технической деятельности я был связан с телефонией, корпоративными системами коммуникации, последнее звучит моднее. И вендоре по этой теме работал и потом когда сделал свою компанию тоже. Но, мне на давало покоя что я продаю (на самом деле перепродаю) чужие продукты. Маржинально, местами эксклюзивно, но не уникально. Короче, хотел что-то такое, что отлично от конкурентов.\xa0Тут важно сделать отсыл к структуре рынка телефонии. Проект состоит из двух частей. Первое - сама АТС, телефонная станция, та коробка, что творит магию и передает звук формата HD по проводам. Второе - телефонные аппараты. Последних в бюджете проекта могло быть до 80% и по сути заработок был на них. Работы, какие-то доработки-интеграции, вообще погрешность в плане денег. Но! Работы и какой-то эксклюзивный «допил» выгодно мог выделить проект на фоне конкурентов, потому что АТС и телефоны продавали все одинаковые. И в итоге, все сваливалось в цену. Все кто перепродает сталкивается с этими рассылками на 100500 адресов - Пришлите КП, или обоснуйте почему вы не шлете. Кстати, от этой схемы, вроде как, и закупщики сами страдают. Ну бог с ними.\xa0Решил я значит как-то на фоне этого всего выделиться. Сначала думал телефоны больших боссов красить. Сделали два прототипа, в Гжель и Хохлому. Толку ноль, форточки только красивые. Да и в тот момент я не сильно умел такое пиарить.\xa0Смотришь вот на этой сейчас и думаешь - Как тебе это вообще в голову пришло?Понятно, что никто ТАКОЕ не заказал.Продукт нужно делать, ну такой чтоб\xa0 нравился - так я думал тогда.Ну ладно, эта гипотеза слита. Стал думать над тем, как отличаться от остальных, если все телефоны одинаковы. А  очень хорошо думаю под физическую нагрузку, тогда как раз готовился к первому марафону. И во дворе дома натыкаюсь на грузовичок, те что побольше Газелей. А сзади у него гидроборт, это такая платформа откидывающаяся для удобства погрузки-разгрузки. Платформу обычно не ставят на заводе, это уже тюнинг такой. Получается продукт, для другого продукта, формата “рыба-прилипала”. И тут стало понятно, что мне вот такая “прилипала” и нужна, только не к грузовикам, а к телефонам. Какая-нить опция которую можно докупить, но чтоб докупить ее хотели много кто.\xa0Идея пришла почти сразу, нужно сделать программный плагин для телефона чтоб с ним работать к компа. Так я придумал Zalle. Название с потолка, не значит ничего. Короче смысл был такой, на ПК ставится плагин и с него можно управлять аппаратом, а именно набирать номера и удобно копировать их при входящем звонке. Что-то подобное было реализовано в Outlook и называлось CTI (Computer Telephony Integration).\xa0В моей схеме вся завязка была именно на аппараты, хотя классически это делают через АТС.Механика такая, в любом приложении или документе на ПК выделяешь номер, нажимаешь комбинацию горячих клавиш, скрипт чистит номер от скобочек-черточек и кидает в сторону аппарата, тот включает громкую связь начинает набор номера.\xa0На каждый тип аппаратов были видео со схемой работы и настройками.При входящим звонке, в правом нижнем углу экрана на компе,\xa0 всплывало уведомление с номером, возможность отбить, ответить, скопировать номер в буфер обмена или создать стикер с напоминалкой.\xa0Вообще, я разогнался и решил сразу делать «космолет», так чтобы отдельные приложения Zalle\xa0 между собой взаимодействовали. Справа появлялась панель с контактами, можно\xa0 было делиться друг с другом, этакая CRM на минималках.\xa0 Разработка была у внешнего подрядчика.Продукт есть, осталась фигня и миллиард в кармане - так думал я в тот момент.Хотя сначала решил распространять бесплатно, типа, вот придет мировая слава, а потом ее и монетизируем. Прикрутил свой скрипт к трем производителям телефонов (Yealink, Grandsteram и Snom, хотел еще к Cisco, но там не оказалось нужного API).Что делал в плане продвижения?Ну конечно же пихал проспекты с рекламой в те аппараты которые продавал сам. Там концепция, как мне казалась, была интересная - «Поzzвони за 3 секунды!» В смысле что обычный набор номера занимает 12 секунд, средний менеджер делает 50 звонков в день. Умножаем одно на другое и получаем экономию времени.\xa0Вот такие наклейки были на коробках с аппаратами.Экономия времени должна хорошо продаваться - так думал я тогда.\xa0Следующие месяца 3 я провел за презами и рекламными материалами. Удалось даже вложить рекламу в коробку телефона на уровне производства. Китайцы сами печатали и паковали. Активно пихал всем знакомым кому более-менее релевантно было. Выступал на конференциях по теме телефонии. Пробовал интегрировать свою штуку с Evernote (может кто помнит, это такой мультидевайсный блокнот с нашими основателями). В итоге отказался от этой псевдо CRM и упростил продукт по максимуму. Нифига!\xa0Народ не понимал и не видел ценности. Экономия 12 сек, оказалась не супер-офером. Была попытка получить инвестиции от ФРИИ. Там отдельный квест в заполнении анкеты, на нее уходит от 8 до 14 часов. Составлена офигенно, там и Отчество спросят и в трусы залезут. Зато в финале много чего начинаешь понимать, и про продукт, и про себя. Точку поставил созвон с экспертом фонда.Рынок очень маленький, а чек который ты можешь за него взять очень небольшой.Вот такой был вердикт.\xa0Это ТОП1 стартаперских граблей - сначала сделать продукт, влюбиться в него, а только потом пойти с этим в рынок чтобы спросить - А вам такое нужно? Мой вопрос стоил 20К долларов в 2016 году. ',), kwargs={}
Результат: всякая экономия в конечном счёте сводится к экономии времени карл марксэто история предпринимательского эксперимента из 2016 года где я пытался выделиться на перегретом рынке телефонии создав плагин для экономии времени при звонках но как оказалось экономия 12 секунд  не всегда весомый аргумент в мире корпоративных продаж в статье нет технических деталей реализации только отражение продажномаркетинговых гипотез некоторые символы и буквы в текущем контексте могут читаться както иначе но тогда это были просто буквытак получилось что большую часть своей экспертной технической деятельности я был связан с телефонией корпоративными системами коммуникации последнее звучит моднее и вендоре по этой теме работал и потом когда сделал свою компанию тоже но мне на давало покоя что я продаю на самом деле перепродаю чужие продукты маржинально местами эксклюзивно но не уникально короче хотел чтото такое что отлично от конкурентов тут важно сделать отсыл к структуре рынка телефонии проект состоит из двух частей первое  сама атс телефонная станция та коробка что творит магию и передает звук формата hd по проводам второе  телефонные аппараты последних в бюджете проекта могло быть до 80 и по сути заработок был на них работы какието доработкиинтеграции вообще погрешность в плане денег но работы и какойто эксклюзивный допил выгодно мог выделить проект на фоне конкурентов потому что атс и телефоны продавали все одинаковые и в итоге все сваливалось в цену все кто перепродает сталкивается с этими рассылками на 100500 адресов  пришлите кп или обоснуйте почему вы не шлете кстати от этой схемы вроде как и закупщики сами страдают ну бог с ними решил я значит както на фоне этого всего выделиться сначала думал телефоны больших боссов красить сделали два прототипа в гжель и хохлому толку ноль форточки только красивые да и в тот момент я не сильно умел такое пиарить смотришь вот на этой сейчас и думаешь  как тебе это вообще в голову пришлопонятно что никто такое не заказалпродукт нужно делать ну такой чтоб  нравился  так я думал тогдану ладно эта гипотеза слита стал думать над тем как отличаться от остальных если все телефоны одинаковы а  очень хорошо думаю под физическую нагрузку тогда как раз готовился к первому марафону и во дворе дома натыкаюсь на грузовичок те что побольше газелей а сзади у него гидроборт это такая платформа откидывающаяся для удобства погрузкиразгрузки платформу обычно не ставят на заводе это уже тюнинг такой получается продукт для другого продукта формата рыбаприлипала и тут стало понятно что мне вот такая прилипала и нужна только не к грузовикам а к телефонам какаянить опция которую можно докупить но чтоб докупить ее хотели много кто идея пришла почти сразу нужно сделать программный плагин для телефона чтоб с ним работать к компа так я придумал zalle название с потолка не значит ничего короче смысл был такой на пк ставится плагин и с него можно управлять аппаратом а именно набирать номера и удобно копировать их при входящем звонке чтото подобное было реализовано в outlook и называлось cti computer telephony integration в моей схеме вся завязка была именно на аппараты хотя классически это делают через атсмеханика такая в любом приложении или документе на пк выделяешь номер нажимаешь комбинацию горячих клавиш скрипт чистит номер от скобочекчерточек и кидает в сторону аппарата тот включает громкую связь начинает набор номера на каждый тип аппаратов были видео со схемой работы и настройкамипри входящим звонке в правом нижнем углу экрана на компе  всплывало уведомление с номером возможность отбить ответить скопировать номер в буфер обмена или создать стикер с напоминалкой вообще я разогнался и решил сразу делать космолет так чтобы отдельные приложения zalle  между собой взаимодействовали справа появлялась панель с контактами можно  было делиться друг с другом этакая crm на минималках  разработка была у внешнего подрядчикапродукт есть осталась фигня и миллиард в кармане  так думал я в тот моментхотя сначала решил распространять бесплатно типа вот придет мировая слава а потом ее и монетизируем прикрутил свой скрипт к трем производителям телефонов yealink grandsteram и snom хотел еще к cisco но там не оказалось нужного apiчто делал в плане продвиженияну конечно же пихал проспекты с рекламой в те аппараты которые продавал сам там концепция как мне казалась была интересная  поzzвони за 3 секунды в смысле что обычный набор номера занимает 12 секунд средний менеджер делает 50 звонков в день умножаем одно на другое и получаем экономию времени вот такие наклейки были на коробках с аппаратамиэкономия времени должна хорошо продаваться  так думал я тогда следующие месяца 3 я провел за презами и рекламными материалами удалось даже вложить рекламу в коробку телефона на уровне производства китайцы сами печатали и паковали активно пихал всем знакомым кому болееменее релевантно было выступал на конференциях по теме телефонии пробовал интегрировать свою штуку с evernote может кто помнит это такой мультидевайсный блокнот с нашими основателями в итоге отказался от этой псевдо crm и упростил продукт по максимуму нифига народ не понимал и не видел ценности экономия 12 сек оказалась не суперофером была попытка получить инвестиции от фрии там отдельный квест в заполнении анкеты на нее уходит от 8 до 14 часов составлена офигенно там и отчество спросят и в трусы залезут зато в финале много чего начинаешь понимать и про продукт и про себя точку поставил созвон с экспертом фондарынок очень маленький а чек который ты можешь за него взять очень небольшойвот такой был вердикт это топ1 стартаперских граблей  сначала сделать продукт влюбиться в него а только потом пойти с этим в рынок чтобы спросить  а вам такое нужно мой вопрос стоил 20к долларов в 2016 году 
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: contains_keywords
Аргументы: args=('Всякая экономия в конечном счёте сводится к экономии времени. Карл МарксЭто история предпринимательского эксперимента из 2016 года: где я пытался выделиться на перегретом рынке телефонии, создав плагин для экономии времени при звонках. Но, как оказалось, экономия 12 секунд — не всегда весомый аргумент в мире корпоративных продаж. В статье нет технических деталей реализации, только отражение продажно-маркетинговых гипотез. Некоторые символы и буквы в текущем контексте могут читаться как-то иначе, но тогда это были просто буквы.Так получилось что большую часть своей экспертной технической деятельности я был связан с телефонией, корпоративными системами коммуникации, последнее звучит моднее. И вендоре по этой теме работал и потом когда сделал свою компанию тоже. Но, мне на давало покоя что я продаю (на самом деле перепродаю) чужие продукты. Маржинально, местами эксклюзивно, но не уникально. Короче, хотел что-то такое, что отлично от конкурентов.\xa0Тут важно сделать отсыл к структуре рынка телефонии. Проект состоит из двух частей. Первое - сама АТС, телефонная станция, та коробка, что творит магию и передает звук формата HD по проводам. Второе - телефонные аппараты. Последних в бюджете проекта могло быть до 80% и по сути заработок был на них. Работы, какие-то доработки-интеграции, вообще погрешность в плане денег. Но! Работы и какой-то эксклюзивный «допил» выгодно мог выделить проект на фоне конкурентов, потому что АТС и телефоны продавали все одинаковые. И в итоге, все сваливалось в цену. Все кто перепродает сталкивается с этими рассылками на 100500 адресов - Пришлите КП, или обоснуйте почему вы не шлете. Кстати, от этой схемы, вроде как, и закупщики сами страдают. Ну бог с ними.\xa0Решил я значит как-то на фоне этого всего выделиться. Сначала думал телефоны больших боссов красить. Сделали два прототипа, в Гжель и Хохлому. Толку ноль, форточки только красивые. Да и в тот момент я не сильно умел такое пиарить.\xa0Смотришь вот на этой сейчас и думаешь - Как тебе это вообще в голову пришло?Понятно, что никто ТАКОЕ не заказал.Продукт нужно делать, ну такой чтоб\xa0 нравился - так я думал тогда.Ну ладно, эта гипотеза слита. Стал думать над тем, как отличаться от остальных, если все телефоны одинаковы. А  очень хорошо думаю под физическую нагрузку, тогда как раз готовился к первому марафону. И во дворе дома натыкаюсь на грузовичок, те что побольше Газелей. А сзади у него гидроборт, это такая платформа откидывающаяся для удобства погрузки-разгрузки. Платформу обычно не ставят на заводе, это уже тюнинг такой. Получается продукт, для другого продукта, формата “рыба-прилипала”. И тут стало понятно, что мне вот такая “прилипала” и нужна, только не к грузовикам, а к телефонам. Какая-нить опция которую можно докупить, но чтоб докупить ее хотели много кто.\xa0Идея пришла почти сразу, нужно сделать программный плагин для телефона чтоб с ним работать к компа. Так я придумал Zalle. Название с потолка, не значит ничего. Короче смысл был такой, на ПК ставится плагин и с него можно управлять аппаратом, а именно набирать номера и удобно копировать их при входящем звонке. Что-то подобное было реализовано в Outlook и называлось CTI (Computer Telephony Integration).\xa0В моей схеме вся завязка была именно на аппараты, хотя классически это делают через АТС.Механика такая, в любом приложении или документе на ПК выделяешь номер, нажимаешь комбинацию горячих клавиш, скрипт чистит номер от скобочек-черточек и кидает в сторону аппарата, тот включает громкую связь начинает набор номера.\xa0На каждый тип аппаратов были видео со схемой работы и настройками.При входящим звонке, в правом нижнем углу экрана на компе,\xa0 всплывало уведомление с номером, возможность отбить, ответить, скопировать номер в буфер обмена или создать стикер с напоминалкой.\xa0Вообще, я разогнался и решил сразу делать «космолет», так чтобы отдельные приложения Zalle\xa0 между собой взаимодействовали. Справа появлялась панель с контактами, можно\xa0 было делиться друг с другом, этакая CRM на минималках.\xa0 Разработка была у внешнего подрядчика.Продукт есть, осталась фигня и миллиард в кармане - так думал я в тот момент.Хотя сначала решил распространять бесплатно, типа, вот придет мировая слава, а потом ее и монетизируем. Прикрутил свой скрипт к трем производителям телефонов (Yealink, Grandsteram и Snom, хотел еще к Cisco, но там не оказалось нужного API).Что делал в плане продвижения?Ну конечно же пихал проспекты с рекламой в те аппараты которые продавал сам. Там концепция, как мне казалась, была интересная - «Поzzвони за 3 секунды!» В смысле что обычный набор номера занимает 12 секунд, средний менеджер делает 50 звонков в день. Умножаем одно на другое и получаем экономию времени.\xa0Вот такие наклейки были на коробках с аппаратами.Экономия времени должна хорошо продаваться - так думал я тогда.\xa0Следующие месяца 3 я провел за презами и рекламными материалами. Удалось даже вложить рекламу в коробку телефона на уровне производства. Китайцы сами печатали и паковали. Активно пихал всем знакомым кому более-менее релевантно было. Выступал на конференциях по теме телефонии. Пробовал интегрировать свою штуку с Evernote (может кто помнит, это такой мультидевайсный блокнот с нашими основателями). В итоге отказался от этой псевдо CRM и упростил продукт по максимуму. Нифига!\xa0Народ не понимал и не видел ценности. Экономия 12 сек, оказалась не супер-офером. Была попытка получить инвестиции от ФРИИ. Там отдельный квест в заполнении анкеты, на нее уходит от 8 до 14 часов. Составлена офигенно, там и Отчество спросят и в трусы залезут. Зато в финале много чего начинаешь понимать, и про продукт, и про себя. Точку поставил созвон с экспертом фонда.Рынок очень маленький, а чек который ты можешь за него взять очень небольшой.Вот такой был вердикт.\xa0Это ТОП1 стартаперских граблей - сначала сделать продукт, влюбиться в него, а только потом пойти с этим в рынок чтобы спросить - А вам такое нужно? Мой вопрос стоил 20К долларов в 2016 году. ', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('Ролевая модель в мессенджере: как одновременно работать с открытой и конфиденциальной информацией',), kwargs={}
Результат: ролевая модель в мессенджере как одновременно работать с открытой и конфиденциальной информацией
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: contains_keywords
Аргументы: args=('Ролевая модель в мессенджере: как одновременно работать с открытой и конфиденциальной информацией', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:21 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('Мессенджеры глубоко проникли в бизнес-процессы компаний, что подчас становится головной болью для специалистов по ИБ. Помогает решить задачу защиты чувствительной бизнес-информации такая функция как ролевая модель. Это специальная система управления, который определяет набор прав и разрешений для различных категорий пользователей, сервисов и приложений. Любых приложений — в том числе и\xa0 мессенджеров, подумали мы. И вот в 2024 году ролевая модель появилась в eXpress. В этой статье я, Алена Папушева, руководитель клиентской поддержки платформы корпоративных коммуникаций eXpress, покажу, как этот популярный инструмент применим в корпоративном мессенджере и как он помогает одновременно работать и с открытой, и с конфиденциальной информацией в рамках одного интерфейса.Что такое ролевая модель и как она работает в eXpressНе будем вдаваться в историю этого метода управления доступом, о нем можно найти много информации (например, в блоге коллег по ИБ). Сфокусируемся на возможностях ролевой модели в мессенджере. Ролевая модель — это обширный набор параметров, атрибутов и правил, которые можно настраивать с помощью консоли администрирования. Основные цели — предотвратить утечку данных, упростить процесс выдачи запретов пользователям мессенджера и управлять доступами к функциям мессенджера по атрибутам.Настройка ролевой модели происходит на сервере компании, а отображение — в клиентском приложении у пользователя. То есть при работе клиент-серверного приложения, где включена ролевая модель, клиент отправляет запрос о возможности совершить действие на сервер и получает от сервера положительный или отрицательный ответ.\xa0Ещё с момента выхода на рынок наш мессенджер отличался широким набором инструментов и технологий для защиты контента и каналов связи. Но время идет, требования заказчиков повышаются. Сегодня в корпоративном продукте критически важна функция гибкой настройки прав доступа и разграничения возможностей работы с чувствительными данными.\xa0Ролевая модель, реализованная в eXpress, помогает:устанавливать необходимые запреты в мессенджере и смартаппахна отправку, пересылку вложений;на просмотр вложений;на скачивание/пересылку/шаринг вложений;на доступ получателям к вложениям, которые отправили пользователи нашего сервера.устанавливать обязательные функции безопасностидоступ к платформе только по PIN-кодудоступ к смартаппам только определенным группам пользователей.Также пользователи корпоративного сервера должны быть своевременно предупреждены, что переписка идет с внешним пользователем, чтобы повысить внимательность и аккуратность работы с документами.Однако откуда в корпоративном мессенджере организации внешние пользователи? Ответ прост: они могут появиться в чате, если корпоративный мессенджер, как наш, поддерживает федеративный протокол передачи данных.Более того, в нашем случае федеративный протокол — ключевая концепция. В 2015 году, приступая к созданию eXpress, мы поставили цель создать корпоративный российский продукт, который заменит все публичные недоверенные мессенджеры, но при этом будет максимально похож на них. Поэтому в нашем мессенджере, как и в популярных публичных, можно общаться с внешним миром: контрагентами, партнерами, клиентами — всеми, кто также входит в Федерацию eXpress (а это уже почти 2 млн пользователей!).Ролевая модель глазами администратора: основные принципы настройкиРолевая модель на сервере включается и выключается одноименным тумблером. Открыв настройки ролевой модели, администратор видит список категорий пользователей и созданных для них правил. Для каждого правила отображается его название, описание, статус (активно или на паузе), свойства, инструменты редактирования.Допустим, администратору нужно создать новое правило. Ролевая модель работает на запреты: с ее помощью нельзя выдать разрешение — можно только что-то кому-то запретить. И администраторам важно тщательно продумать сами запреты и роли для пользователей заранее. Отсюда следует порядок действий администратора.\xa0Определяем запреты, которые заказчик хочет настроить: для кого они будут, на что конкретно будут направлены. Для удобства можно составить таблицу.Создаем группу пользователей в соответствующем разделе, даем ей название. Группу можно создать, например, по ролям OpenID или по определенным полям профиля: должностям, отделу, логинам и так далее. Также можно создать группу, в которую войдут все пользователи данного сервера — для этого достаточно отметить нужные платформы и указать название группы.Выбираем платформы, на которых будет действовать ограничение для этой группы пользователей, и тип подключения. Администратор системы может гибко настраивать политики обмена данными в зависимости от того, к какой сети подключается пользователь и с какого устройства он это делает. Правило может действовать, например, только для мобильных пользователей, подключенных не к корпоративной сети. В настройках группы ролевой модели можно выбрать внутренний или внешний контур. Что считать внутренним контуром, определяет настройка КСПД в разделе Fileservice.Здесь же можно добавить исключения. Если мы, например, настраиваем группу пользователей по группе AD, но хотим, чтобы на одного из пользователей правило не распространялось — добавляем его в исключения (по логину или его идентификатору).Создаем сами правила, даем им название и выбираем в них группу, область действия запрета (например, мессенджер), тип правила (например, запрет пересылки вложений) и тип вложения (например, изображения). Это 4 обязательных параметра, без них правило либо просто не сохранится, либо будет работать некорректно. Можно больше ничего не выбирать, тогда правило будет глобальным: например, запретит отправку изображений полностью конкретной группе пользователей. Можно сделать правило более локальным: например, в "назначении запрета" выбрать пользователей, присутствие которых в чате запрещает это действие, или конкретизировать параметры: например, ограничить вес прикрепляемых файлов 100 мегабайтами. Если какое-то правило должно распространяться на все типы вложений — нужно создать 3 правила: на изображения, видео и документы. Для этого достаточно скопировать правило и сменить тип вложения. Активируем сохраненное правило (по умолчанию оно сохраняется “на паузе”).Важно: все правила ролевой модели настраиваются исключительно на пользователей корпоративного сервера заказчика. То есть мы не можем настроить какое-то правило на публичных пользователей eXpress или пользователей другого корпоративного сервера (сотрудников другой организации, использующей eXpress).Ролевая модель глазами пользователя: популярные юз-кейсыЗапрет отправки документов внешним пользователям. Если вы заходите в чат, где присутствует пользователь публичной версии eXpress, система выдает предупреждение об этом. Пока вы сами не начнете переписку с этим пользователем, предупреждение не пропадает. Если отправка файлов внешнему пользователю ограничена, при попытке отправить или переслать такому пользователю файл вы увидите предупреждение о том, какой тип файлов отправлять нельзя.Ограничение на доступ к вложениям в зависимости от платформы. Если вы с мобильного устройства пытаетесь получить доступ к документам, но видите сообщение об ограничении на просмотр данных файлов с мобильных платформ — значит, в ролевой модели реализован соответствующий запрет и ничего не остается, как посмотреть файлы за компьютером в десктопной версии приложения.Ограничение на доступ к вложениям в зависимости от источника вложения. Допустим, в запрете просмотра видео администратором указано дополнительное условие «все, кроме пользователей со своего сервера». Тогда вы сможете смотреть видео от пользователей со своего сервера беспрепятственно, но видео от пользователей с других серверов посмотреть будет нельзя: файл будет заблюрен и над ним отобразится предупреждение об ограничении на просмотр вложений.Запрет на действия в чате, где присутствуют пользователи определенных категорий. Если такой запрет настроен, то, например, пока вы находитесь в групповом чате, в котором есть пользователи с вашего сервера и с доверенных серверов, обмен данными будет беспрепятственным. Но как только в чате появляется хотя бы один публичный пользователь — правило применяется (например, ограничивается пересылка/скачивание/шаринг изображений).Ранее мы упоминали о том, что правила распространяются только на пользователей нашего сервера. Однако, есть единственное правило, которое может ограничить просмотр файлов внешними пользователями — “Запрет для получателей скачивать вложения от пользователей с cts (корпоративного сервера)". В данном правиле выбранная группа пользователей\xa0 будет отправлять файлы беспрепятственно, проверка будет осуществляться на уровне получателя.\xa0В этом правиле обязательно нужно выбрать назначение запрета — по контуру или серверу (причем правило по контуру "строже" правила по серверу). Например, если в назначении запрета указать "Все, кроме пользователей внутреннего контура", то файл, отправленный пользователем из группы, можно будет открыть только пользователю нашего сервера и только из КСПД (конкретной локальной сети). Если же выбрать чуть менее строгий вариант "Все, кроме пользователей со своего сервера", файл, отправленный пользователем из группы, будет доступен для просмотра только пользователю с нашего сервера.Ролевая модель распространяется и на eXpress SmartApps. eXpress представляет собой платформу для отдельных графических приложений — смартаппов, и здесь также можно настроить политики и правила ролевой модели с областью действия "в smartapps". Например, если активно правило на запрет отправки изображений в конкретном (например, почтовом) смартаппе, то в этом смартаппе прикрепить к письму изображение будет нельзя, кнопка отправки будет неактивна.Правило на видимость смартаппов в каталоге настраивается не в ролевой модели, а в меню редактирования конкретного смартаппа в разделе "Боты". Ролевая модель в одноименной вкладке при этом обязательно должна быть включена.Самые популярные вопросыМожет ли неблагонадежный пользователь обойти запрет на пересылку файлов определенного типа? Администратор может не указывать расширение файлов в правиле — и тогда запрет будет действовать на документы любого формата.Как быстро применяются новые правила? При переключении по чатам или перезапуске приложения.Как узнать, кто и когда создал правило ролевой модели? Правила ролевой модели логируются в разделе “Аудит”. Если нажать на идентификатор каждого события, мы можем посмотреть подробности: с какого IP было создано правило, каким администратором, какое имя у этого правила и какое действие оно запрещает.Возможности ролевой модели в корпоративном мессенджере вовсе не ограничены перечисленными выше — мы продолжаем развивать эту фичу eXpress, планировать доработки и отвечать на вопросы заказчиков. И на ваши вопросы с радостью ответим — welcome в комментарии!',), kwargs={}
Результат: мессенджеры глубоко проникли в бизнеспроцессы компаний что подчас становится головной болью для специалистов по иб помогает решить задачу защиты чувствительной бизнесинформации такая функция как ролевая модель это специальная система управления который определяет набор прав и разрешений для различных категорий пользователей сервисов и приложений любых приложений  в том числе и  мессенджеров подумали мы и вот в 2024 году ролевая модель появилась в express в этой статье я алена папушева руководитель клиентской поддержки платформы корпоративных коммуникаций express покажу как этот популярный инструмент применим в корпоративном мессенджере и как он помогает одновременно работать и с открытой и с конфиденциальной информацией в рамках одного интерфейсачто такое ролевая модель и как она работает в expressне будем вдаваться в историю этого метода управления доступом о нем можно найти много информации например в блоге коллег по иб сфокусируемся на возможностях ролевой модели в мессенджере ролевая модель  это обширный набор параметров атрибутов и правил которые можно настраивать с помощью консоли администрирования основные цели  предотвратить утечку данных упростить процесс выдачи запретов пользователям мессенджера и управлять доступами к функциям мессенджера по атрибутамнастройка ролевой модели происходит на сервере компании а отображение  в клиентском приложении у пользователя то есть при работе клиентсерверного приложения где включена ролевая модель клиент отправляет запрос о возможности совершить действие на сервер и получает от сервера положительный или отрицательный ответ ещё с момента выхода на рынок наш мессенджер отличался широким набором инструментов и технологий для защиты контента и каналов связи но время идет требования заказчиков повышаются сегодня в корпоративном продукте критически важна функция гибкой настройки прав доступа и разграничения возможностей работы с чувствительными данными ролевая модель реализованная в express помогаетустанавливать необходимые запреты в мессенджере и смартаппахна отправку пересылку вложенийна просмотр вложенийна скачиваниепересылкушаринг вложенийна доступ получателям к вложениям которые отправили пользователи нашего сервераустанавливать обязательные функции безопасностидоступ к платформе только по pinкодудоступ к смартаппам только определенным группам пользователейтакже пользователи корпоративного сервера должны быть своевременно предупреждены что переписка идет с внешним пользователем чтобы повысить внимательность и аккуратность работы с документамиоднако откуда в корпоративном мессенджере организации внешние пользователи ответ прост они могут появиться в чате если корпоративный мессенджер как наш поддерживает федеративный протокол передачи данныхболее того в нашем случае федеративный протокол  ключевая концепция в 2015 году приступая к созданию express мы поставили цель создать корпоративный российский продукт который заменит все публичные недоверенные мессенджеры но при этом будет максимально похож на них поэтому в нашем мессенджере как и в популярных публичных можно общаться с внешним миром контрагентами партнерами клиентами  всеми кто также входит в федерацию express а это уже почти 2 млн пользователейролевая модель глазами администратора основные принципы настройкиролевая модель на сервере включается и выключается одноименным тумблером открыв настройки ролевой модели администратор видит список категорий пользователей и созданных для них правил для каждого правила отображается его название описание статус активно или на паузе свойства инструменты редактированиядопустим администратору нужно создать новое правило ролевая модель работает на запреты с ее помощью нельзя выдать разрешение  можно только чтото комуто запретить и администраторам важно тщательно продумать сами запреты и роли для пользователей заранее отсюда следует порядок действий администратора определяем запреты которые заказчик хочет настроить для кого они будут на что конкретно будут направлены для удобства можно составить таблицусоздаем группу пользователей в соответствующем разделе даем ей название группу можно создать например по ролям openid или по определенным полям профиля должностям отделу логинам и так далее также можно создать группу в которую войдут все пользователи данного сервера  для этого достаточно отметить нужные платформы и указать название группывыбираем платформы на которых будет действовать ограничение для этой группы пользователей и тип подключения администратор системы может гибко настраивать политики обмена данными в зависимости от того к какой сети подключается пользователь и с какого устройства он это делает правило может действовать например только для мобильных пользователей подключенных не к корпоративной сети в настройках группы ролевой модели можно выбрать внутренний или внешний контур что считать внутренним контуром определяет настройка кспд в разделе fileserviceздесь же можно добавить исключения если мы например настраиваем группу пользователей по группе ad но хотим чтобы на одного из пользователей правило не распространялось  добавляем его в исключения по логину или его идентификаторусоздаем сами правила даем им название и выбираем в них группу область действия запрета например мессенджер тип правила например запрет пересылки вложений и тип вложения например изображения это 4 обязательных параметра без них правило либо просто не сохранится либо будет работать некорректно можно больше ничего не выбирать тогда правило будет глобальным например запретит отправку изображений полностью конкретной группе пользователей можно сделать правило более локальным например в назначении запрета выбрать пользователей присутствие которых в чате запрещает это действие или конкретизировать параметры например ограничить вес прикрепляемых файлов 100 мегабайтами если какоето правило должно распространяться на все типы вложений  нужно создать 3 правила на изображения видео и документы для этого достаточно скопировать правило и сменить тип вложения активируем сохраненное правило по умолчанию оно сохраняется на паузеважно все правила ролевой модели настраиваются исключительно на пользователей корпоративного сервера заказчика то есть мы не можем настроить какоето правило на публичных пользователей express или пользователей другого корпоративного сервера сотрудников другой организации использующей expressролевая модель глазами пользователя популярные юзкейсызапрет отправки документов внешним пользователям если вы заходите в чат где присутствует пользователь публичной версии express система выдает предупреждение об этом пока вы сами не начнете переписку с этим пользователем предупреждение не пропадает если отправка файлов внешнему пользователю ограничена при попытке отправить или переслать такому пользователю файл вы увидите предупреждение о том какой тип файлов отправлять нельзяограничение на доступ к вложениям в зависимости от платформы если вы с мобильного устройства пытаетесь получить доступ к документам но видите сообщение об ограничении на просмотр данных файлов с мобильных платформ  значит в ролевой модели реализован соответствующий запрет и ничего не остается как посмотреть файлы за компьютером в десктопной версии приложенияограничение на доступ к вложениям в зависимости от источника вложения допустим в запрете просмотра видео администратором указано дополнительное условие все кроме пользователей со своего сервера тогда вы сможете смотреть видео от пользователей со своего сервера беспрепятственно но видео от пользователей с других серверов посмотреть будет нельзя файл будет заблюрен и над ним отобразится предупреждение об ограничении на просмотр вложенийзапрет на действия в чате где присутствуют пользователи определенных категорий если такой запрет настроен то например пока вы находитесь в групповом чате в котором есть пользователи с вашего сервера и с доверенных серверов обмен данными будет беспрепятственным но как только в чате появляется хотя бы один публичный пользователь  правило применяется например ограничивается пересылкаскачиваниешаринг изображенийранее мы упоминали о том что правила распространяются только на пользователей нашего сервера однако есть единственное правило которое может ограничить просмотр файлов внешними пользователями  запрет для получателей скачивать вложения от пользователей с cts корпоративного сервера в данном правиле выбранная группа пользователей  будет отправлять файлы беспрепятственно проверка будет осуществляться на уровне получателя в этом правиле обязательно нужно выбрать назначение запрета  по контуру или серверу причем правило по контуру строже правила по серверу например если в назначении запрета указать все кроме пользователей внутреннего контура то файл отправленный пользователем из группы можно будет открыть только пользователю нашего сервера и только из кспд конкретной локальной сети если же выбрать чуть менее строгий вариант все кроме пользователей со своего сервера файл отправленный пользователем из группы будет доступен для просмотра только пользователю с нашего сервераролевая модель распространяется и на express smartapps express представляет собой платформу для отдельных графических приложений  смартаппов и здесь также можно настроить политики и правила ролевой модели с областью действия в smartapps например если активно правило на запрет отправки изображений в конкретном например почтовом смартаппе то в этом смартаппе прикрепить к письму изображение будет нельзя кнопка отправки будет неактивнаправило на видимость смартаппов в каталоге настраивается не в ролевой модели а в меню редактирования конкретного смартаппа в разделе боты ролевая модель в одноименной вкладке при этом обязательно должна быть включенасамые популярные вопросыможет ли неблагонадежный пользователь обойти запрет на пересылку файлов определенного типа администратор может не указывать расширение файлов в правиле  и тогда запрет будет действовать на документы любого форматакак быстро применяются новые правила при переключении по чатам или перезапуске приложениякак узнать кто и когда создал правило ролевой модели правила ролевой модели логируются в разделе аудит если нажать на идентификатор каждого события мы можем посмотреть подробности с какого ip было создано правило каким администратором какое имя у этого правила и какое действие оно запрещаетвозможности ролевой модели в корпоративном мессенджере вовсе не ограничены перечисленными выше  мы продолжаем развивать эту фичу express планировать доработки и отвечать на вопросы заказчиков и на ваши вопросы с радостью ответим  welcome в комментарии
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: contains_keywords
Аргументы: args=('Мессенджеры глубоко проникли в бизнес-процессы компаний, что подчас становится головной болью для специалистов по ИБ. Помогает решить задачу защиты чувствительной бизнес-информации такая функция как ролевая модель. Это специальная система управления, который определяет набор прав и разрешений для различных категорий пользователей, сервисов и приложений. Любых приложений — в том числе и\xa0 мессенджеров, подумали мы. И вот в 2024 году ролевая модель появилась в eXpress. В этой статье я, Алена Папушева, руководитель клиентской поддержки платформы корпоративных коммуникаций eXpress, покажу, как этот популярный инструмент применим в корпоративном мессенджере и как он помогает одновременно работать и с открытой, и с конфиденциальной информацией в рамках одного интерфейса.Что такое ролевая модель и как она работает в eXpressНе будем вдаваться в историю этого метода управления доступом, о нем можно найти много информации (например, в блоге коллег по ИБ). Сфокусируемся на возможностях ролевой модели в мессенджере. Ролевая модель — это обширный набор параметров, атрибутов и правил, которые можно настраивать с помощью консоли администрирования. Основные цели — предотвратить утечку данных, упростить процесс выдачи запретов пользователям мессенджера и управлять доступами к функциям мессенджера по атрибутам.Настройка ролевой модели происходит на сервере компании, а отображение — в клиентском приложении у пользователя. То есть при работе клиент-серверного приложения, где включена ролевая модель, клиент отправляет запрос о возможности совершить действие на сервер и получает от сервера положительный или отрицательный ответ.\xa0Ещё с момента выхода на рынок наш мессенджер отличался широким набором инструментов и технологий для защиты контента и каналов связи. Но время идет, требования заказчиков повышаются. Сегодня в корпоративном продукте критически важна функция гибкой настройки прав доступа и разграничения возможностей работы с чувствительными данными.\xa0Ролевая модель, реализованная в eXpress, помогает:устанавливать необходимые запреты в мессенджере и смартаппахна отправку, пересылку вложений;на просмотр вложений;на скачивание/пересылку/шаринг вложений;на доступ получателям к вложениям, которые отправили пользователи нашего сервера.устанавливать обязательные функции безопасностидоступ к платформе только по PIN-кодудоступ к смартаппам только определенным группам пользователей.Также пользователи корпоративного сервера должны быть своевременно предупреждены, что переписка идет с внешним пользователем, чтобы повысить внимательность и аккуратность работы с документами.Однако откуда в корпоративном мессенджере организации внешние пользователи? Ответ прост: они могут появиться в чате, если корпоративный мессенджер, как наш, поддерживает федеративный протокол передачи данных.Более того, в нашем случае федеративный протокол — ключевая концепция. В 2015 году, приступая к созданию eXpress, мы поставили цель создать корпоративный российский продукт, который заменит все публичные недоверенные мессенджеры, но при этом будет максимально похож на них. Поэтому в нашем мессенджере, как и в популярных публичных, можно общаться с внешним миром: контрагентами, партнерами, клиентами — всеми, кто также входит в Федерацию eXpress (а это уже почти 2 млн пользователей!).Ролевая модель глазами администратора: основные принципы настройкиРолевая модель на сервере включается и выключается одноименным тумблером. Открыв настройки ролевой модели, администратор видит список категорий пользователей и созданных для них правил. Для каждого правила отображается его название, описание, статус (активно или на паузе), свойства, инструменты редактирования.Допустим, администратору нужно создать новое правило. Ролевая модель работает на запреты: с ее помощью нельзя выдать разрешение — можно только что-то кому-то запретить. И администраторам важно тщательно продумать сами запреты и роли для пользователей заранее. Отсюда следует порядок действий администратора.\xa0Определяем запреты, которые заказчик хочет настроить: для кого они будут, на что конкретно будут направлены. Для удобства можно составить таблицу.Создаем группу пользователей в соответствующем разделе, даем ей название. Группу можно создать, например, по ролям OpenID или по определенным полям профиля: должностям, отделу, логинам и так далее. Также можно создать группу, в которую войдут все пользователи данного сервера — для этого достаточно отметить нужные платформы и указать название группы.Выбираем платформы, на которых будет действовать ограничение для этой группы пользователей, и тип подключения. Администратор системы может гибко настраивать политики обмена данными в зависимости от того, к какой сети подключается пользователь и с какого устройства он это делает. Правило может действовать, например, только для мобильных пользователей, подключенных не к корпоративной сети. В настройках группы ролевой модели можно выбрать внутренний или внешний контур. Что считать внутренним контуром, определяет настройка КСПД в разделе Fileservice.Здесь же можно добавить исключения. Если мы, например, настраиваем группу пользователей по группе AD, но хотим, чтобы на одного из пользователей правило не распространялось — добавляем его в исключения (по логину или его идентификатору).Создаем сами правила, даем им название и выбираем в них группу, область действия запрета (например, мессенджер), тип правила (например, запрет пересылки вложений) и тип вложения (например, изображения). Это 4 обязательных параметра, без них правило либо просто не сохранится, либо будет работать некорректно. Можно больше ничего не выбирать, тогда правило будет глобальным: например, запретит отправку изображений полностью конкретной группе пользователей. Можно сделать правило более локальным: например, в "назначении запрета" выбрать пользователей, присутствие которых в чате запрещает это действие, или конкретизировать параметры: например, ограничить вес прикрепляемых файлов 100 мегабайтами. Если какое-то правило должно распространяться на все типы вложений — нужно создать 3 правила: на изображения, видео и документы. Для этого достаточно скопировать правило и сменить тип вложения. Активируем сохраненное правило (по умолчанию оно сохраняется “на паузе”).Важно: все правила ролевой модели настраиваются исключительно на пользователей корпоративного сервера заказчика. То есть мы не можем настроить какое-то правило на публичных пользователей eXpress или пользователей другого корпоративного сервера (сотрудников другой организации, использующей eXpress).Ролевая модель глазами пользователя: популярные юз-кейсыЗапрет отправки документов внешним пользователям. Если вы заходите в чат, где присутствует пользователь публичной версии eXpress, система выдает предупреждение об этом. Пока вы сами не начнете переписку с этим пользователем, предупреждение не пропадает. Если отправка файлов внешнему пользователю ограничена, при попытке отправить или переслать такому пользователю файл вы увидите предупреждение о том, какой тип файлов отправлять нельзя.Ограничение на доступ к вложениям в зависимости от платформы. Если вы с мобильного устройства пытаетесь получить доступ к документам, но видите сообщение об ограничении на просмотр данных файлов с мобильных платформ — значит, в ролевой модели реализован соответствующий запрет и ничего не остается, как посмотреть файлы за компьютером в десктопной версии приложения.Ограничение на доступ к вложениям в зависимости от источника вложения. Допустим, в запрете просмотра видео администратором указано дополнительное условие «все, кроме пользователей со своего сервера». Тогда вы сможете смотреть видео от пользователей со своего сервера беспрепятственно, но видео от пользователей с других серверов посмотреть будет нельзя: файл будет заблюрен и над ним отобразится предупреждение об ограничении на просмотр вложений.Запрет на действия в чате, где присутствуют пользователи определенных категорий. Если такой запрет настроен, то, например, пока вы находитесь в групповом чате, в котором есть пользователи с вашего сервера и с доверенных серверов, обмен данными будет беспрепятственным. Но как только в чате появляется хотя бы один публичный пользователь — правило применяется (например, ограничивается пересылка/скачивание/шаринг изображений).Ранее мы упоминали о том, что правила распространяются только на пользователей нашего сервера. Однако, есть единственное правило, которое может ограничить просмотр файлов внешними пользователями — “Запрет для получателей скачивать вложения от пользователей с cts (корпоративного сервера)". В данном правиле выбранная группа пользователей\xa0 будет отправлять файлы беспрепятственно, проверка будет осуществляться на уровне получателя.\xa0В этом правиле обязательно нужно выбрать назначение запрета — по контуру или серверу (причем правило по контуру "строже" правила по серверу). Например, если в назначении запрета указать "Все, кроме пользователей внутреннего контура", то файл, отправленный пользователем из группы, можно будет открыть только пользователю нашего сервера и только из КСПД (конкретной локальной сети). Если же выбрать чуть менее строгий вариант "Все, кроме пользователей со своего сервера", файл, отправленный пользователем из группы, будет доступен для просмотра только пользователю с нашего сервера.Ролевая модель распространяется и на eXpress SmartApps. eXpress представляет собой платформу для отдельных графических приложений — смартаппов, и здесь также можно настроить политики и правила ролевой модели с областью действия "в smartapps". Например, если активно правило на запрет отправки изображений в конкретном (например, почтовом) смартаппе, то в этом смартаппе прикрепить к письму изображение будет нельзя, кнопка отправки будет неактивна.Правило на видимость смартаппов в каталоге настраивается не в ролевой модели, а в меню редактирования конкретного смартаппа в разделе "Боты". Ролевая модель в одноименной вкладке при этом обязательно должна быть включена.Самые популярные вопросыМожет ли неблагонадежный пользователь обойти запрет на пересылку файлов определенного типа? Администратор может не указывать расширение файлов в правиле — и тогда запрет будет действовать на документы любого формата.Как быстро применяются новые правила? При переключении по чатам или перезапуске приложения.Как узнать, кто и когда создал правило ролевой модели? Правила ролевой модели логируются в разделе “Аудит”. Если нажать на идентификатор каждого события, мы можем посмотреть подробности: с какого IP было создано правило, каким администратором, какое имя у этого правила и какое действие оно запрещает.Возможности ролевой модели в корпоративном мессенджере вовсе не ограничены перечисленными выше — мы продолжаем развивать эту фичу eXpress, планировать доработки и отвечать на вопросы заказчиков. И на ваши вопросы с радостью ответим — welcome в комментарии!', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('Тенденции к усилению взаимодействия бизнеса и вузов на ИТ-рынке',), kwargs={}
Результат: тенденции к усилению взаимодействия бизнеса и вузов на итрынке
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: contains_keywords
Аргументы: args=('Тенденции к усилению взаимодействия бизнеса и вузов на ИТ-рынке', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:22 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('Как ИТ-компании решают вопрос кадрового голода? Как правительственные программы помогают вовлекать работодателей в образовательный процесс? Почему в C3D Labs появился отдел образовательных проектов? Рассказывает Любовь Белянина, руководитель по работе с персоналом C3D Labs. «Охота» на специалистов и кадровый голод Еще до недавнего времени бизнес был в активном поиске готовых специалистов, которых не нужно было обучать. Человек, получивший высшее образование, часто оказывался в условиях суровой действительности, где без опыта работы трудоустроиться было крайне проблематично. Молодые, мотивированные и потенциально продуктивные кадры оказывались за периметром отбора на многие вакансии. В вузах же часто обучение строилось в отрыве от реальных потребностей бизнеса. Такое положение вещей привело к пресловутому кадровому голоду, нехватке квалифицированных специалистов и «пробке из джунов» – пожалуй, основным трендам последних лет, с которыми столкнулись многие компании. В Москве и Санкт-Петербурге на одну вакансию приходит 5–6 резюме от специалистов без опыта или с минимальным опытом работы. При этом, к сожалению, часто у таких кандидатов нет необходимых бизнесу знаний (а не только практических навыков). Очевидно, что так не могло продолжаться бесконечно. У коммерческих компаний неизбежно возникает потребность пересмотра кадровой политики, а у вузов – установления тесных связей с компаниями. Пожалуй, это даже не вопрос выбора, а понимание объективной необходимости, которую диктует реальность. На сегодняшний день наблюдается тренд усиления связи между академическим структурами и бизнесом.Время переменВ ИТ-сфере как одной из наиболее прогрессивных сфер бизнеса эти идеи стали реализовываться в первую очередь. Эта тенденция нашла свое отражение и в правительственных программах. 10\xa0марта 2025\xa0года Минцифры\xa0сообщило, что\xa0стартовал\xa0отбор вузов, которые займутся разработкой и запуском новых программ бакалавриата для\xa0подготовки специалистов в\xa0области ИТ. Конкурс организован Минцифры и Аналитическим центром при\xa0Правительстве в\xa0рамках федерального проекта «Кадры для\xa0цифровой трансформации».\xa0Основной задачей проекта является обеспечение ИТ‑компаний высококвалифицированными кадрами, обладающими нужными практическими навыками, чтобы избежать необходимости дополнительного обучения при трудоустройстве. \xa0По данным Минцифры, показатель занятых в ИТ-отрасли в России составляет всего 2\xa0%. По оценкам Ассоциации предприятий компьютерных и информационных технологий, к 2030 году в России число ИТ-работников в экономике должно будет составлять минимум 4,9\xa0%. Это означает, что за 2025–2030 годы нужно привлечь 2\xa0млн новых специалистов высшей квалификации и 700\xa0тыс. средней квалификации. В самой масштабной в истории России программе поддержки вузов «Приоритет 2030» акцент делается на прикладных разработках и поиске индустриальных партнеров. Кроме того, Минцифры разрабатывает новые критерии для крупных ИТ-компаний (с выручкой от 1 млрд) по поддержке вузов, необходимые для сохранения аккредитации. Вовлечение компаний в образовательный процесс c большой долей вероятности будет обязательным условием для сохранения ими льгот и поможет улучшить квалификацию выпускников. Российские компании, осознавшие необходимость тесной связи между образованием и бизнесом, уже несколько лет работают в этом направлении. Бизнес сотрудничает с вузами в разных форматах: от участия в ярмарках вакансий, проведения мастер-классов, хакатонов и встреч до разработки образовательных проектов, курсов и совместных программ профпереподготовки «под ключ». В этом случае вузы готовят под запрос компаний узкопрофильных специалистов, которые в дальнейшем смогут утолить тот самый «кадровый голод» заказчика. Все чаще ИТ-компании начинают плотно сотрудничать с вузами, ведь именно необходимое образование – залог дальнейшего успеха как для самих специалистов, так и для компаний, в которых эти специалисты будут трудиться в дальнейшем.Риc. 1. C3D Labs активно принимает участие в хакатонах  Образовательные проекты C3D\xa0LabsНемного истории C3D Labs основана в 2012 году на базе математического подразделения АСКОН, работавшего над геометрическим ядром с 1995 года, и сегодня входит в АСКОН как дочерняя компания. Мы занимаемся разработкой геометрического ядра – ключевого компонента для создания инженерного программного обеспечения. Мы успешно сочетаем 35-летний опыт материнской компании АСКОН в индустрии САПР и актуальные технологии разработки.Наша компания в вопросе образовательных проектов идет в ногу с запросами времени и успешно идет к своей цели – выращиванию специалистов «под себя», в тоже время помогая осуществить мечту многих студентов технических вузов\xa0– «войти в ИТ».Отдел образовательных проектовC3D Labs\xa0развивает проекты в сфере образования уже достаточно давно, и руководство нашей компании приняло решение о выделении отдельного направления в структуре организации под эти задачи и открытии отдела образовательных проектов для более успешной их реализации. Новый отдел уже активно взаимодействует с учебными заведениями и готовит ряд мероприятий для студентов.Непрерывная работа Первое, о чем хочется сказать: уже 4 года наши ведущие математики-программисты преподают в\xa0Коломенском институте (филиале) Московского политехнического университета. Почему именно Коломна? Тут нужен небольшой экскурс в историю. Дело в том, что свое развитие АСКОН, наша материнская компания, начала именно в Коломне. В далеком 1989 году Александр Голиков и Татьяна Янкина открыли здесь первый центр разработки. В этом же году была выпущена первая версия системы автоматизированного проектирования (САПР) КОМПАС-График. Сегодня компания C3D\xa0Labs\xa0представлена тремя офисами: в Москве находится администрация компании, в Коломне и Нижнем Новгороде\xa0— офисы разработки. Крепкие исторические связи с Коломной способствовали тому, что изначально здесь мы начали реализовывать наши образовательные проекты. Рис. 2. Стажеры и их наставники в коломенском офисе C3D Labs  Коломенский Политех известен далеко за пределами своего города благодаря сильной математической базе и отличной подготовке по инженерным специальностям. Наши сотрудники Александр Алахвердянц, Сергей Белев и Александр Спиваков преподают в этом университете. Александр Алахвердянц\xa0ведет такие предметы, как «Введение в программирование и алгоритмизацию», «Структуры и алгоритмы обработки данных», «Объектно-ориентированное программирование на C++». Сергей Белев – «Функциональное и логическое программирование», «Операционные системы». Помимо этого, Сергей является научным руководителем для студентов и курирует их при написании курсовых и дипломных работ. Александр Спиваков ведет такие курсы, как «Прикладное ПО в технических системах» и «Системное программирование». В результате их прохождения студенты получают навыки работы в актуальной среде\xa0– с системой контроля версий, интегрированной средой разработки, а также навыки построения и переработки архитектуры сложных программ. Хочется отметить, что работу наших коллег высоко оценили депутат Мособлдумы Екатерина Лобышева и ректор Московского политехнического университета Владимир Владимирович\xa0Миклушевский. Коллеги получили благодарственные письма и памятные грамоты за свой вклад в образовательный процесс.Рис. 3. Мария Пилипец рассказывает о своей стажировке в C3D Labs в Коломенском ПолитехеЦентр разработки в Нижнем Новгороде был открыт в 2016 году, и сейчас там трудится значительная часть наших математиков-программистов. Сейчас мы активно укрепляем связи с ведущими нижегородскими техническими вузами. В скором времени мы запустим в Нижнем Новгороде ряд образовательных проектов.Помимо этого, С3D\xa0Labs – постоянный участник различных образовательных выставок, форумов, хакатонов. Только за прошлый год мы были участниками ИТ-конференций РУССОФТ и Нижегородского государственного архитектурно-строительного университета, провели хакатон совместно с Тюменским государственным университетом. Приняли участие во Всероссийском Фестивале науки «Наука 0+» в Уфе. Организовали стажировку совместно с компанией Rubius в Томске, были спикерами на выставке «Россия» (Александр Спиваков, руководитель группы образовательных проектов, рассказывал о профессии математика-программиста, о том, какими навыками нужно обладать для входа в эту профессию и где можно ей обучиться) и в «Сколтехе» (Максим Кулагин, руководитель группы тестирования и технической поддержки, рассказал студентам курса Advanced\xa0PLM (Center\xa0of\xa0Digital\xa0Engineering) о геометрическом моделировании, C3D\xa0Toolkit и его использовании в инженерном ПО).Рис. 4. Максим Кулагин читает лекцию о геометрическом ядре в «Сколтехе»  Также хочется отметить, что мы не боимся брать на работу молодых специалистов и вкладывать ресурсы в их развитие. На сегодняшний день на постоянной основе у нас трудится уже десять стажеров в наших офисах в Нижнем Новгороде и Коломне. Кроме того, мы привлекаем студентов из различных городов России\xa0на краткосрочные стажировки для участия во временных проектах. Интервью с нашими стажерами доступны в блоге и ВКонтакте.Рис. 5. Стажеры C3D Labs  Очевидно, что мы живем в эпоху постоянных перемен, и здорово быть их частью. Укрепление сотрудничества между бизнесом и сферой образования – это исключительно важный, необходимый и позитивный процесс. Наша компания в числе первых почувствовала этот тренд и начала активно работать в этом направлении.Хотите стать частью команды C3D Labs и участвовать в наших образовательных проектах? Узнайте подробности и подайте заявку на стажировку на карьерной странице.Мы всегда открыты к сотрудничеству!Любовь БелянинаРуководитель по работе с персоналомC3D Labs',), kwargs={}
Результат: как иткомпании решают вопрос кадрового голода как правительственные программы помогают вовлекать работодателей в образовательный процесс почему в c3d labs появился отдел образовательных проектов рассказывает любовь белянина руководитель по работе с персоналом c3d labs охота на специалистов и кадровый голод еще до недавнего времени бизнес был в активном поиске готовых специалистов которых не нужно было обучать человек получивший высшее образование часто оказывался в условиях суровой действительности где без опыта работы трудоустроиться было крайне проблематично молодые мотивированные и потенциально продуктивные кадры оказывались за периметром отбора на многие вакансии в вузах же часто обучение строилось в отрыве от реальных потребностей бизнеса такое положение вещей привело к пресловутому кадровому голоду нехватке квалифицированных специалистов и пробке из джунов  пожалуй основным трендам последних лет с которыми столкнулись многие компании в москве и санктпетербурге на одну вакансию приходит 56 резюме от специалистов без опыта или с минимальным опытом работы при этом к сожалению часто у таких кандидатов нет необходимых бизнесу знаний а не только практических навыков очевидно что так не могло продолжаться бесконечно у коммерческих компаний неизбежно возникает потребность пересмотра кадровой политики а у вузов  установления тесных связей с компаниями пожалуй это даже не вопрос выбора а понимание объективной необходимости которую диктует реальность на сегодняшний день наблюдается тренд усиления связи между академическим структурами и бизнесомвремя переменв итсфере как одной из наиболее прогрессивных сфер бизнеса эти идеи стали реализовываться в первую очередь эта тенденция нашла свое отражение и в правительственных программах 10 марта 2025 года минцифры сообщило что стартовал отбор вузов которые займутся разработкой и запуском новых программ бакалавриата для подготовки специалистов в области ит конкурс организован минцифры и аналитическим центром при правительстве в рамках федерального проекта кадры для цифровой трансформации основной задачей проекта является обеспечение иткомпаний высококвалифицированными кадрами обладающими нужными практическими навыками чтобы избежать необходимости дополнительного обучения при трудоустройстве  по данным минцифры показатель занятых в итотрасли в россии составляет всего 2  по оценкам ассоциации предприятий компьютерных и информационных технологий к 2030 году в россии число итработников в экономике должно будет составлять минимум 49  это означает что за 20252030 годы нужно привлечь 2 млн новых специалистов высшей квалификации и 700 тыс средней квалификации в самой масштабной в истории россии программе поддержки вузов приоритет 2030 акцент делается на прикладных разработках и поиске индустриальных партнеров кроме того минцифры разрабатывает новые критерии для крупных иткомпаний с выручкой от 1 млрд по поддержке вузов необходимые для сохранения аккредитации вовлечение компаний в образовательный процесс c большой долей вероятности будет обязательным условием для сохранения ими льгот и поможет улучшить квалификацию выпускников российские компании осознавшие необходимость тесной связи между образованием и бизнесом уже несколько лет работают в этом направлении бизнес сотрудничает с вузами в разных форматах от участия в ярмарках вакансий проведения мастерклассов хакатонов и встреч до разработки образовательных проектов курсов и совместных программ профпереподготовки под ключ в этом случае вузы готовят под запрос компаний узкопрофильных специалистов которые в дальнейшем смогут утолить тот самый кадровый голод заказчика все чаще иткомпании начинают плотно сотрудничать с вузами ведь именно необходимое образование  залог дальнейшего успеха как для самих специалистов так и для компаний в которых эти специалисты будут трудиться в дальнейшемриc 1 c3d labs активно принимает участие в хакатонах  образовательные проекты c3d labsнемного истории c3d labs основана в 2012 году на базе математического подразделения аскон работавшего над геометрическим ядром с 1995 года и сегодня входит в аскон как дочерняя компания мы занимаемся разработкой геометрического ядра  ключевого компонента для создания инженерного программного обеспечения мы успешно сочетаем 35летний опыт материнской компании аскон в индустрии сапр и актуальные технологии разработкинаша компания в вопросе образовательных проектов идет в ногу с запросами времени и успешно идет к своей цели  выращиванию специалистов под себя в тоже время помогая осуществить мечту многих студентов технических вузов  войти в итотдел образовательных проектовc3d labs развивает проекты в сфере образования уже достаточно давно и руководство нашей компании приняло решение о выделении отдельного направления в структуре организации под эти задачи и открытии отдела образовательных проектов для более успешной их реализации новый отдел уже активно взаимодействует с учебными заведениями и готовит ряд мероприятий для студентовнепрерывная работа первое о чем хочется сказать уже 4 года наши ведущие математикипрограммисты преподают в коломенском институте филиале московского политехнического университета почему именно коломна тут нужен небольшой экскурс в историю дело в том что свое развитие аскон наша материнская компания начала именно в коломне в далеком 1989 году александр голиков и татьяна янкина открыли здесь первый центр разработки в этом же году была выпущена первая версия системы автоматизированного проектирования сапр компасграфик сегодня компания c3d labs представлена тремя офисами в москве находится администрация компании в коломне и нижнем новгороде  офисы разработки крепкие исторические связи с коломной способствовали тому что изначально здесь мы начали реализовывать наши образовательные проекты рис 2 стажеры и их наставники в коломенском офисе c3d labs  коломенский политех известен далеко за пределами своего города благодаря сильной математической базе и отличной подготовке по инженерным специальностям наши сотрудники александр алахвердянц сергей белев и александр спиваков преподают в этом университете александр алахвердянц ведет такие предметы как введение в программирование и алгоритмизацию структуры и алгоритмы обработки данных объектноориентированное программирование на c сергей белев  функциональное и логическое программирование операционные системы помимо этого сергей является научным руководителем для студентов и курирует их при написании курсовых и дипломных работ александр спиваков ведет такие курсы как прикладное по в технических системах и системное программирование в результате их прохождения студенты получают навыки работы в актуальной среде  с системой контроля версий интегрированной средой разработки а также навыки построения и переработки архитектуры сложных программ хочется отметить что работу наших коллег высоко оценили депутат мособлдумы екатерина лобышева и ректор московского политехнического университета владимир владимирович миклушевский коллеги получили благодарственные письма и памятные грамоты за свой вклад в образовательный процессрис 3 мария пилипец рассказывает о своей стажировке в c3d labs в коломенском политехецентр разработки в нижнем новгороде был открыт в 2016 году и сейчас там трудится значительная часть наших математиковпрограммистов сейчас мы активно укрепляем связи с ведущими нижегородскими техническими вузами в скором времени мы запустим в нижнем новгороде ряд образовательных проектовпомимо этого с3d labs  постоянный участник различных образовательных выставок форумов хакатонов только за прошлый год мы были участниками итконференций руссофт и нижегородского государственного архитектурностроительного университета провели хакатон совместно с тюменским государственным университетом приняли участие во всероссийском фестивале науки наука 0 в уфе организовали стажировку совместно с компанией rubius в томске были спикерами на выставке россия александр спиваков руководитель группы образовательных проектов рассказывал о профессии математикапрограммиста о том какими навыками нужно обладать для входа в эту профессию и где можно ей обучиться и в сколтехе максим кулагин руководитель группы тестирования и технической поддержки рассказал студентам курса advanced plm center of digital engineering о геометрическом моделировании c3d toolkit и его использовании в инженерном порис 4 максим кулагин читает лекцию о геометрическом ядре в сколтехе  также хочется отметить что мы не боимся брать на работу молодых специалистов и вкладывать ресурсы в их развитие на сегодняшний день на постоянной основе у нас трудится уже десять стажеров в наших офисах в нижнем новгороде и коломне кроме того мы привлекаем студентов из различных городов россии на краткосрочные стажировки для участия во временных проектах интервью с нашими стажерами доступны в блоге и вконтактерис 5 стажеры c3d labs  очевидно что мы живем в эпоху постоянных перемен и здорово быть их частью укрепление сотрудничества между бизнесом и сферой образования  это исключительно важный необходимый и позитивный процесс наша компания в числе первых почувствовала этот тренд и начала активно работать в этом направлениихотите стать частью команды c3d labs и участвовать в наших образовательных проектах узнайте подробности и подайте заявку на стажировку на карьерной страницемы всегда открыты к сотрудничествулюбовь белянинаруководитель по работе с персоналомc3d labs
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: contains_keywords
Аргументы: args=('Как ИТ-компании решают вопрос кадрового голода? Как правительственные программы помогают вовлекать работодателей в образовательный процесс? Почему в C3D Labs появился отдел образовательных проектов? Рассказывает Любовь Белянина, руководитель по работе с персоналом C3D Labs. «Охота» на специалистов и кадровый голод Еще до недавнего времени бизнес был в активном поиске готовых специалистов, которых не нужно было обучать. Человек, получивший высшее образование, часто оказывался в условиях суровой действительности, где без опыта работы трудоустроиться было крайне проблематично. Молодые, мотивированные и потенциально продуктивные кадры оказывались за периметром отбора на многие вакансии. В вузах же часто обучение строилось в отрыве от реальных потребностей бизнеса. Такое положение вещей привело к пресловутому кадровому голоду, нехватке квалифицированных специалистов и «пробке из джунов» – пожалуй, основным трендам последних лет, с которыми столкнулись многие компании. В Москве и Санкт-Петербурге на одну вакансию приходит 5–6 резюме от специалистов без опыта или с минимальным опытом работы. При этом, к сожалению, часто у таких кандидатов нет необходимых бизнесу знаний (а не только практических навыков). Очевидно, что так не могло продолжаться бесконечно. У коммерческих компаний неизбежно возникает потребность пересмотра кадровой политики, а у вузов – установления тесных связей с компаниями. Пожалуй, это даже не вопрос выбора, а понимание объективной необходимости, которую диктует реальность. На сегодняшний день наблюдается тренд усиления связи между академическим структурами и бизнесом.Время переменВ ИТ-сфере как одной из наиболее прогрессивных сфер бизнеса эти идеи стали реализовываться в первую очередь. Эта тенденция нашла свое отражение и в правительственных программах. 10\xa0марта 2025\xa0года Минцифры\xa0сообщило, что\xa0стартовал\xa0отбор вузов, которые займутся разработкой и запуском новых программ бакалавриата для\xa0подготовки специалистов в\xa0области ИТ. Конкурс организован Минцифры и Аналитическим центром при\xa0Правительстве в\xa0рамках федерального проекта «Кадры для\xa0цифровой трансформации».\xa0Основной задачей проекта является обеспечение ИТ‑компаний высококвалифицированными кадрами, обладающими нужными практическими навыками, чтобы избежать необходимости дополнительного обучения при трудоустройстве. \xa0По данным Минцифры, показатель занятых в ИТ-отрасли в России составляет всего 2\xa0%. По оценкам Ассоциации предприятий компьютерных и информационных технологий, к 2030 году в России число ИТ-работников в экономике должно будет составлять минимум 4,9\xa0%. Это означает, что за 2025–2030 годы нужно привлечь 2\xa0млн новых специалистов высшей квалификации и 700\xa0тыс. средней квалификации. В самой масштабной в истории России программе поддержки вузов «Приоритет 2030» акцент делается на прикладных разработках и поиске индустриальных партнеров. Кроме того, Минцифры разрабатывает новые критерии для крупных ИТ-компаний (с выручкой от 1 млрд) по поддержке вузов, необходимые для сохранения аккредитации. Вовлечение компаний в образовательный процесс c большой долей вероятности будет обязательным условием для сохранения ими льгот и поможет улучшить квалификацию выпускников. Российские компании, осознавшие необходимость тесной связи между образованием и бизнесом, уже несколько лет работают в этом направлении. Бизнес сотрудничает с вузами в разных форматах: от участия в ярмарках вакансий, проведения мастер-классов, хакатонов и встреч до разработки образовательных проектов, курсов и совместных программ профпереподготовки «под ключ». В этом случае вузы готовят под запрос компаний узкопрофильных специалистов, которые в дальнейшем смогут утолить тот самый «кадровый голод» заказчика. Все чаще ИТ-компании начинают плотно сотрудничать с вузами, ведь именно необходимое образование – залог дальнейшего успеха как для самих специалистов, так и для компаний, в которых эти специалисты будут трудиться в дальнейшем.Риc. 1. C3D Labs активно принимает участие в хакатонах  Образовательные проекты C3D\xa0LabsНемного истории C3D Labs основана в 2012 году на базе математического подразделения АСКОН, работавшего над геометрическим ядром с 1995 года, и сегодня входит в АСКОН как дочерняя компания. Мы занимаемся разработкой геометрического ядра – ключевого компонента для создания инженерного программного обеспечения. Мы успешно сочетаем 35-летний опыт материнской компании АСКОН в индустрии САПР и актуальные технологии разработки.Наша компания в вопросе образовательных проектов идет в ногу с запросами времени и успешно идет к своей цели – выращиванию специалистов «под себя», в тоже время помогая осуществить мечту многих студентов технических вузов\xa0– «войти в ИТ».Отдел образовательных проектовC3D Labs\xa0развивает проекты в сфере образования уже достаточно давно, и руководство нашей компании приняло решение о выделении отдельного направления в структуре организации под эти задачи и открытии отдела образовательных проектов для более успешной их реализации. Новый отдел уже активно взаимодействует с учебными заведениями и готовит ряд мероприятий для студентов.Непрерывная работа Первое, о чем хочется сказать: уже 4 года наши ведущие математики-программисты преподают в\xa0Коломенском институте (филиале) Московского политехнического университета. Почему именно Коломна? Тут нужен небольшой экскурс в историю. Дело в том, что свое развитие АСКОН, наша материнская компания, начала именно в Коломне. В далеком 1989 году Александр Голиков и Татьяна Янкина открыли здесь первый центр разработки. В этом же году была выпущена первая версия системы автоматизированного проектирования (САПР) КОМПАС-График. Сегодня компания C3D\xa0Labs\xa0представлена тремя офисами: в Москве находится администрация компании, в Коломне и Нижнем Новгороде\xa0— офисы разработки. Крепкие исторические связи с Коломной способствовали тому, что изначально здесь мы начали реализовывать наши образовательные проекты. Рис. 2. Стажеры и их наставники в коломенском офисе C3D Labs  Коломенский Политех известен далеко за пределами своего города благодаря сильной математической базе и отличной подготовке по инженерным специальностям. Наши сотрудники Александр Алахвердянц, Сергей Белев и Александр Спиваков преподают в этом университете. Александр Алахвердянц\xa0ведет такие предметы, как «Введение в программирование и алгоритмизацию», «Структуры и алгоритмы обработки данных», «Объектно-ориентированное программирование на C++». Сергей Белев – «Функциональное и логическое программирование», «Операционные системы». Помимо этого, Сергей является научным руководителем для студентов и курирует их при написании курсовых и дипломных работ. Александр Спиваков ведет такие курсы, как «Прикладное ПО в технических системах» и «Системное программирование». В результате их прохождения студенты получают навыки работы в актуальной среде\xa0– с системой контроля версий, интегрированной средой разработки, а также навыки построения и переработки архитектуры сложных программ. Хочется отметить, что работу наших коллег высоко оценили депутат Мособлдумы Екатерина Лобышева и ректор Московского политехнического университета Владимир Владимирович\xa0Миклушевский. Коллеги получили благодарственные письма и памятные грамоты за свой вклад в образовательный процесс.Рис. 3. Мария Пилипец рассказывает о своей стажировке в C3D Labs в Коломенском ПолитехеЦентр разработки в Нижнем Новгороде был открыт в 2016 году, и сейчас там трудится значительная часть наших математиков-программистов. Сейчас мы активно укрепляем связи с ведущими нижегородскими техническими вузами. В скором времени мы запустим в Нижнем Новгороде ряд образовательных проектов.Помимо этого, С3D\xa0Labs – постоянный участник различных образовательных выставок, форумов, хакатонов. Только за прошлый год мы были участниками ИТ-конференций РУССОФТ и Нижегородского государственного архитектурно-строительного университета, провели хакатон совместно с Тюменским государственным университетом. Приняли участие во Всероссийском Фестивале науки «Наука 0+» в Уфе. Организовали стажировку совместно с компанией Rubius в Томске, были спикерами на выставке «Россия» (Александр Спиваков, руководитель группы образовательных проектов, рассказывал о профессии математика-программиста, о том, какими навыками нужно обладать для входа в эту профессию и где можно ей обучиться) и в «Сколтехе» (Максим Кулагин, руководитель группы тестирования и технической поддержки, рассказал студентам курса Advanced\xa0PLM (Center\xa0of\xa0Digital\xa0Engineering) о геометрическом моделировании, C3D\xa0Toolkit и его использовании в инженерном ПО).Рис. 4. Максим Кулагин читает лекцию о геометрическом ядре в «Сколтехе»  Также хочется отметить, что мы не боимся брать на работу молодых специалистов и вкладывать ресурсы в их развитие. На сегодняшний день на постоянной основе у нас трудится уже десять стажеров в наших офисах в Нижнем Новгороде и Коломне. Кроме того, мы привлекаем студентов из различных городов России\xa0на краткосрочные стажировки для участия во временных проектах. Интервью с нашими стажерами доступны в блоге и ВКонтакте.Рис. 5. Стажеры C3D Labs  Очевидно, что мы живем в эпоху постоянных перемен, и здорово быть их частью. Укрепление сотрудничества между бизнесом и сферой образования – это исключительно важный, необходимый и позитивный процесс. Наша компания в числе первых почувствовала этот тренд и начала активно работать в этом направлении.Хотите стать частью команды C3D Labs и участвовать в наших образовательных проектах? Узнайте подробности и подайте заявку на стажировку на карьерной странице.Мы всегда открыты к сотрудничеству!Любовь БелянинаРуководитель по работе с персоналомC3D Labs', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('Постоянная Капрекара: алгоритм, который всегда сводится к одному числу',), kwargs={}
Результат: постоянная капрекара алгоритм который всегда сводится к одному числу
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: contains_keywords
Аргументы: args=('Постоянная Капрекара: алгоритм, который всегда сводится к одному числу', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:23 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('В мире математики существует множество удивительных чисел, которые обладают уникальными свойствами. Изучение подобных математических феноменов развивает логическое мышление, открывает новые горизонты для исследований и практических применений.В 1949 году индийский математик Даттарая Капрекар обнаружил интересную закономерность у четырёхзначных чисел. При выполнении определённых действий с четырёхзначными числами (кроме тех, в которых все цифры одинаковые) всегда получается одно и тоже число.Суть алгоритма1. Выбрать 4-значное число (кроме тех, в которых все цифры одинаковые, например, 5555).2. Расположить цифры этого числа сначала в порядке убывания, затем в порядке возрастания. Получится два новых числа.3. Вычесть из большего числа меньшее.4. Повторять шаги 2–3 до появления неподвижной точки 6174.Пример: число 56216521 – 1256 = 52656552 – 2556 = 39969963 – 3699 = 62646642 – 2466 = 41767641 – 1467 = 6174Разность между максимальными и минимальными числами стремится к постоянной 6174.Для тех чисел, в которых все цифры одинаковые, алгоритм не имеет смысла.Код на Python для 4-значных чисел с пошаговым выводом процесса вычислений:Скрытый текстdef kaprekar_constant(number):\n    print(f"\\n{number}")\n    \n    if number < 1000 or number > 9999:\n        print("Ошибка: число должно быть 4-значным.")\n        return False\n    if len(set(str(number))) == 1:\n        print("Ошибка: все цифры одинаковые.")\n        return False\n    \n    while number != 6174:\n        num_str = str(number).zfill(4)\n        desc = int(\'\'.join(sorted(num_str, reverse=True)))\n        asc = int(\'\'.join(sorted(num_str)))\n        number = desc - asc\n        print(f"{desc} - {asc} = {number}")\n    \n    print("Получена постоянная Капрекара 6174")\n    return True\n\ndef main():\n    \n    while True:\n        input_number = input("\\nВведите 4-значное число (кроме тех, где все цифры одинаковые) или введите \'0\' для завершения программы: ")\n        \n        if input_number == \'0\':\n            print("Программа завершена.")\n            break\n            \n        if not input_number.isdigit():\n            print("Ошибка: введите число.")\n            continue\n            \n        kaprekar_constant(int(input_number))\n\nif __name__ == "__main__":\n    main()Уникальность числа 6174 заключается ещё и в том, что:процесс всегда сходится к 6174 за конечное число шагов;максимальное число итераций — 7;после достижения числа 6174 процесс входит в цикл, потому что 7641 – 1467 = 6174;если разделить число 6174 на сумму его цифр (6 + 1 + 7 + 4 = 18), получится 343 (6174 : 18 = 343), а это 7 в третьей степени (магия чисел!);число раскладывается на сумму первых трёх степеней числа 18 (181 + 182 + 183 = 6174).Для трёхзначных чисел также существует аналогичная константа — 495.Пример: число 123321 – 123 = 198981 – 189 = 792972 – 279 = 693963 – 369 = 594954 – 459 = 495Код на Python для 3-значных чисел с пошаговым выводом процесса вычислений:Скрытый текстdef constant_3digit(number):\n    print(f"\\n{number}")\n    \n    if number < 100 or number > 999:\n        print("Ошибка: число должно быть 3-значным.")\n        return False\n    if len(set(str(number))) == 1:\n        print("Ошибка: все цифры одинаковые.")\n        return False\n    \n    while number != 495:\n        num_str = str(number).zfill(3)\n        desc = int(\'\'.join(sorted(num_str, reverse=True)))\n        asc = int(\'\'.join(sorted(num_str)))\n        number = desc - asc\n        print(f"{desc} - {asc} = {number}")\n    \n    print("Получена постоянная 495")\n    return True\n\ndef main():\n    \n    while True:\n        input_number = input("\\nВведите 3-значное число (кроме тех, где все цифры одинаковые) или введите \'0\' для завершения программы: ")\n        \n        if input_number == \'0\':\n            print("Программа завершена.")\n            break\n            \n        if not input_number.isdigit():\n            print("Ошибка: введите 3-значное число:")\n            continue\n            \n        constant_3digit(int(input_number))\n\nif __name__ == "__main__":\n    main()Для\xa0двухзначных чисел подобный алгоритм приводит к числу 9. Но так как нужна устойчивая точка среди двухзначных чисел, то процесс зацикливается.Пример: число 3553 – 35 = 1881 – 18 = 6363 – 36 = 2772 – 27 = 4554 – 45 = 990 – 9 = 8181 – 18 = 63Обнаружен цикл. Число 63 уже встречалось.Цикл состоит из пяти чисел: 09 → 81 → 63 → 27 → 45 → 09 → ...Для пятизначных чисел и больше алгоритм Капрекара превращается в бесконечную карусель. Разница между перестановками зацикливается без сходимости к одному числу. Из-за большого количества возможных перестановок 5-значные числа попадают в бесконечные циклы.Практическое применениеДля постоянной Капрекара возможны интересные практические применения.Развитие логики и алгоритмического мышления. Процедура Капрекара — отличный пример для изучения циклов в программировании (например, написание кода для проверки сходимости числа к константе).Итерации процедуры можно использовать как простой алгоритм «перемешивания» цифр (хотя и нестойкий ко взлому).Генерация уникальных последовательностей. Например, цикл 63 → 27 → 45 → 09 → 81 → 63 можно использовать для создания простой «маскировки» данных.Математические квесты (например, «за сколько шагов 4-значное число превратится в 6174»), мобильные приложения-головоломки типа числовых трансформеров, чат-боты с математическими задачами.Алгоритм можно использовать в юнит-тестах, чтобы проверить: правильность сортировки цифр (asc и desc), корректность вычитания (desc – asc), обработку чисел с ведущими нулями (например, 0378 → 378).Оптимизация и алгоритмические задачи, например, анализ поведения для n-значных чисел (3-значные → 495, 4-значные → 6174, 5-значные → циклы).Генерация творческих идей.Константа Капрекара — удивительный математический феномен, который демонстрирует, как простые операции с числами могут приводить к неожиданным закономерностям.',), kwargs={}
Результат: в мире математики существует множество удивительных чисел которые обладают уникальными свойствами изучение подобных математических феноменов развивает логическое мышление открывает новые горизонты для исследований и практических примененийв 1949 году индийский математик даттарая капрекар обнаружил интересную закономерность у четырёхзначных чисел при выполнении определённых действий с четырёхзначными числами кроме тех в которых все цифры одинаковые всегда получается одно и тоже числосуть алгоритма1 выбрать 4значное число кроме тех в которых все цифры одинаковые например 55552 расположить цифры этого числа сначала в порядке убывания затем в порядке возрастания получится два новых числа3 вычесть из большего числа меньшее4 повторять шаги 23 до появления неподвижной точки 6174пример число 56216521  1256  52656552  2556  39969963  3699  62646642  2466  41767641  1467  6174разность между максимальными и минимальными числами стремится к постоянной 6174для тех чисел в которых все цифры одинаковые алгоритм не имеет смыслакод на python для 4значных чисел с пошаговым выводом процесса вычисленийскрытый текстdef kaprekar_constantnumber
    printfnnumber
    
    if number  1000 or number  9999
        printошибка число должно быть 4значным
        return false
    if lensetstrnumber  1
        printошибка все цифры одинаковые
        return false
    
    while number  6174
        num_str  strnumberzfill4
        desc  intjoinsortednum_str reversetrue
        asc  intjoinsortednum_str
        number  desc  asc
        printfdesc  asc  number
    
    printполучена постоянная капрекара 6174
    return true

def main
    
    while true
        input_number  inputnвведите 4значное число кроме тех где все цифры одинаковые или введите 0 для завершения программы 
        
        if input_number  0
            printпрограмма завершена
            break
            
        if not input_numberisdigit
            printошибка введите число
            continue
            
        kaprekar_constantintinput_number

if __name__  __main__
    mainуникальность числа 6174 заключается ещё и в том чтопроцесс всегда сходится к 6174 за конечное число шаговмаксимальное число итераций  7после достижения числа 6174 процесс входит в цикл потому что 7641  1467  6174если разделить число 6174 на сумму его цифр 6  1  7  4  18 получится 343 6174  18  343 а это 7 в третьей степени магия чиселчисло раскладывается на сумму первых трёх степеней числа 18 181  182  183  6174для трёхзначных чисел также существует аналогичная константа  495пример число 123321  123  198981  189  792972  279  693963  369  594954  459  495код на python для 3значных чисел с пошаговым выводом процесса вычисленийскрытый текстdef constant_3digitnumber
    printfnnumber
    
    if number  100 or number  999
        printошибка число должно быть 3значным
        return false
    if lensetstrnumber  1
        printошибка все цифры одинаковые
        return false
    
    while number  495
        num_str  strnumberzfill3
        desc  intjoinsortednum_str reversetrue
        asc  intjoinsortednum_str
        number  desc  asc
        printfdesc  asc  number
    
    printполучена постоянная 495
    return true

def main
    
    while true
        input_number  inputnвведите 3значное число кроме тех где все цифры одинаковые или введите 0 для завершения программы 
        
        if input_number  0
            printпрограмма завершена
            break
            
        if not input_numberisdigit
            printошибка введите 3значное число
            continue
            
        constant_3digitintinput_number

if __name__  __main__
    mainдля двухзначных чисел подобный алгоритм приводит к числу 9 но так как нужна устойчивая точка среди двухзначных чисел то процесс зацикливаетсяпример число 3553  35  1881  18  6363  36  2772  27  4554  45  990  9  8181  18  63обнаружен цикл число 63 уже встречалосьцикл состоит из пяти чисел 09  81  63  27  45  09  для пятизначных чисел и больше алгоритм капрекара превращается в бесконечную карусель разница между перестановками зацикливается без сходимости к одному числу изза большого количества возможных перестановок 5значные числа попадают в бесконечные циклыпрактическое применениедля постоянной капрекара возможны интересные практические примененияразвитие логики и алгоритмического мышления процедура капрекара  отличный пример для изучения циклов в программировании например написание кода для проверки сходимости числа к константеитерации процедуры можно использовать как простой алгоритм перемешивания цифр хотя и нестойкий ко взломугенерация уникальных последовательностей например цикл 63  27  45  09  81  63 можно использовать для создания простой маскировки данныхматематические квесты например за сколько шагов 4значное число превратится в 6174 мобильные приложенияголоволомки типа числовых трансформеров чатботы с математическими задачамиалгоритм можно использовать в юниттестах чтобы проверить правильность сортировки цифр asc и desc корректность вычитания desc  asc обработку чисел с ведущими нулями например 0378  378оптимизация и алгоритмические задачи например анализ поведения для nзначных чисел 3значные  495 4значные  6174 5значные  циклыгенерация творческих идейконстанта капрекара  удивительный математический феномен который демонстрирует как простые операции с числами могут приводить к неожиданным закономерностям
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: contains_keywords
Аргументы: args=('В мире математики существует множество удивительных чисел, которые обладают уникальными свойствами. Изучение подобных математических феноменов развивает логическое мышление, открывает новые горизонты для исследований и практических применений.В 1949 году индийский математик Даттарая Капрекар обнаружил интересную закономерность у четырёхзначных чисел. При выполнении определённых действий с четырёхзначными числами (кроме тех, в которых все цифры одинаковые) всегда получается одно и тоже число.Суть алгоритма1. Выбрать 4-значное число (кроме тех, в которых все цифры одинаковые, например, 5555).2. Расположить цифры этого числа сначала в порядке убывания, затем в порядке возрастания. Получится два новых числа.3. Вычесть из большего числа меньшее.4. Повторять шаги 2–3 до появления неподвижной точки 6174.Пример: число 56216521 – 1256 = 52656552 – 2556 = 39969963 – 3699 = 62646642 – 2466 = 41767641 – 1467 = 6174Разность между максимальными и минимальными числами стремится к постоянной 6174.Для тех чисел, в которых все цифры одинаковые, алгоритм не имеет смысла.Код на Python для 4-значных чисел с пошаговым выводом процесса вычислений:Скрытый текстdef kaprekar_constant(number):\n    print(f"\\n{number}")\n    \n    if number < 1000 or number > 9999:\n        print("Ошибка: число должно быть 4-значным.")\n        return False\n    if len(set(str(number))) == 1:\n        print("Ошибка: все цифры одинаковые.")\n        return False\n    \n    while number != 6174:\n        num_str = str(number).zfill(4)\n        desc = int(\'\'.join(sorted(num_str, reverse=True)))\n        asc = int(\'\'.join(sorted(num_str)))\n        number = desc - asc\n        print(f"{desc} - {asc} = {number}")\n    \n    print("Получена постоянная Капрекара 6174")\n    return True\n\ndef main():\n    \n    while True:\n        input_number = input("\\nВведите 4-значное число (кроме тех, где все цифры одинаковые) или введите \'0\' для завершения программы: ")\n        \n        if input_number == \'0\':\n            print("Программа завершена.")\n            break\n            \n        if not input_number.isdigit():\n            print("Ошибка: введите число.")\n            continue\n            \n        kaprekar_constant(int(input_number))\n\nif __name__ == "__main__":\n    main()Уникальность числа 6174 заключается ещё и в том, что:процесс всегда сходится к 6174 за конечное число шагов;максимальное число итераций — 7;после достижения числа 6174 процесс входит в цикл, потому что 7641 – 1467 = 6174;если разделить число 6174 на сумму его цифр (6 + 1 + 7 + 4 = 18), получится 343 (6174 : 18 = 343), а это 7 в третьей степени (магия чисел!);число раскладывается на сумму первых трёх степеней числа 18 (181 + 182 + 183 = 6174).Для трёхзначных чисел также существует аналогичная константа — 495.Пример: число 123321 – 123 = 198981 – 189 = 792972 – 279 = 693963 – 369 = 594954 – 459 = 495Код на Python для 3-значных чисел с пошаговым выводом процесса вычислений:Скрытый текстdef constant_3digit(number):\n    print(f"\\n{number}")\n    \n    if number < 100 or number > 999:\n        print("Ошибка: число должно быть 3-значным.")\n        return False\n    if len(set(str(number))) == 1:\n        print("Ошибка: все цифры одинаковые.")\n        return False\n    \n    while number != 495:\n        num_str = str(number).zfill(3)\n        desc = int(\'\'.join(sorted(num_str, reverse=True)))\n        asc = int(\'\'.join(sorted(num_str)))\n        number = desc - asc\n        print(f"{desc} - {asc} = {number}")\n    \n    print("Получена постоянная 495")\n    return True\n\ndef main():\n    \n    while True:\n        input_number = input("\\nВведите 3-значное число (кроме тех, где все цифры одинаковые) или введите \'0\' для завершения программы: ")\n        \n        if input_number == \'0\':\n            print("Программа завершена.")\n            break\n            \n        if not input_number.isdigit():\n            print("Ошибка: введите 3-значное число:")\n            continue\n            \n        constant_3digit(int(input_number))\n\nif __name__ == "__main__":\n    main()Для\xa0двухзначных чисел подобный алгоритм приводит к числу 9. Но так как нужна устойчивая точка среди двухзначных чисел, то процесс зацикливается.Пример: число 3553 – 35 = 1881 – 18 = 6363 – 36 = 2772 – 27 = 4554 – 45 = 990 – 9 = 8181 – 18 = 63Обнаружен цикл. Число 63 уже встречалось.Цикл состоит из пяти чисел: 09 → 81 → 63 → 27 → 45 → 09 → ...Для пятизначных чисел и больше алгоритм Капрекара превращается в бесконечную карусель. Разница между перестановками зацикливается без сходимости к одному числу. Из-за большого количества возможных перестановок 5-значные числа попадают в бесконечные циклы.Практическое применениеДля постоянной Капрекара возможны интересные практические применения.Развитие логики и алгоритмического мышления. Процедура Капрекара — отличный пример для изучения циклов в программировании (например, написание кода для проверки сходимости числа к константе).Итерации процедуры можно использовать как простой алгоритм «перемешивания» цифр (хотя и нестойкий ко взлому).Генерация уникальных последовательностей. Например, цикл 63 → 27 → 45 → 09 → 81 → 63 можно использовать для создания простой «маскировки» данных.Математические квесты (например, «за сколько шагов 4-значное число превратится в 6174»), мобильные приложения-головоломки типа числовых трансформеров, чат-боты с математическими задачами.Алгоритм можно использовать в юнит-тестах, чтобы проверить: правильность сортировки цифр (asc и desc), корректность вычитания (desc – asc), обработку чисел с ведущими нулями (например, 0378 → 378).Оптимизация и алгоритмические задачи, например, анализ поведения для n-значных чисел (3-значные → 495, 4-значные → 6174, 5-значные → циклы).Генерация творческих идей.Константа Капрекара — удивительный математический феномен, который демонстрирует, как простые операции с числами могут приводить к неожиданным закономерностям.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('От Docs as Code к Everything as Code: как Gramax меняет работу с документацией',), kwargs={}
Результат: от docs as code к everything as code как gramax меняет работу с документацией
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: contains_keywords
Аргументы: args=('От Docs as Code к Everything as Code: как Gramax меняет работу с документацией', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:25 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('Привет, Хабр! Меня зовут Катя, я лидирую Gramax, open-source платформу для управления технической документацией. Однажды мы с коллегами утонули в хаосе рабочих документов: без версий, без согласований, без истории принятых решений. Это подтолкнуло нас к созданию Gramax — инструмента, который интегрирует документацию в процесс разработки, делая его прозрачным и управляемым.В этой статье расскажем, как Gramax помогает на каждом этапе разработки ПО. Как перейти к документированию в подходе Docs as Code и шагнуть дальше — к Everything as Code.Кто, что, когда и зачем меняетЧто было у нас и часто бывает у других: кто-то переписывает требования или инструкцию, и никто толком не понимает, что именно изменилось. Почему поменяли? Что было раньше? Кто согласовал? — найти ответы почти невозможно. Нет понимания, что изменилось. Документ выглядит так же, но внутри могут быть полностью другие требования или описания. Приходится сравнивать версии вручную (если они вообще сохранились).Неясно, зачем внесли правки. Кто решил переписать требования? Почему убрали тот пункт? Что стало основанием для изменения? Контекст правок теряется в чатах и звонках, а спустя неделю об этом никто уже не помнит. Не видно, кто согласовал. Участники команды не понимают, была ли правка согласована или кто-то просто внес ее по своей инициативе. Не отследить, какие документы готовы, а какие в процессе.Нам было важно видеть, кто что предложил, как это обсуждали и к какому варианту пришли в итоге. Без гаданий, без лишних вопросов. Давайте сначала: что такое GramaxВизуальный редактор для Markdown с поддержкой OpenAPI, Mermaid, PlantUML и Draw.io.Интеграция с популярными Git-хранилищами, встроенный Git-клиент, запросы на слияние, версионирование.Независимость от вендоров. Потому что Gramax это self-hosted решение с открытым исходным кодом.Понятный и удобный интерфейс для разработчиков, аналитиков и нетехнических специалистов.Можно посмотреть картинки, а лучше - протестировать приложение самостоятельно:)Gramax помогает командам хранить всю документацию рядом с кодом, автоматизировать процессы и поддерживать единый источник правды.Ключевая идея Gramax — документация должна быть частью инженерной экосистемы, а не отдельным процессом, который отнимает время. Мы целимся в Everything as Code, где код, документация, архитектурные решения и знания управляются единообразно, с использованием лучших инженерных практик.Теперь о процессах: как использоватьРассмотрим, как разные участники IT-команды используют Gramax при разработке новой функции — например, платежного модуля.Системные и бизнес-аналитики: формирование требованийЗадача: аналитик должен подготовить постановку задачи для платежного модуля, согласовать ее с командой и зафиксировать в репозитории.Аналитик открывает Gramax, выбирает шаблон для формирования требований. Описывает все в визуальном редакторе с Mermaid-диаграммами для иллюстрации бизнес-процесса.Документ сохраняется в ветке spec-payment-module в Git-репозитории. Аналитик создает запрос на слияние в master, назначая архитектора и менеджера на ревью.В интерфейсе Gramax команда обсуждает документ с помощью комментариев. Аналитик вносит правку исправления за минуты, обновляя ветку.После согласования документ сливается в master.Результат: постановка оформлена по шаблону, история изменений сохранена в Git.Архитекторы: проектирование и ADRЗадача: архитектор должен создать архитектурное решение (ADR) для платежного модуля, согласовать его и сохранить рядом с кодом.Архитектор создает ADR в Gramax: описывает архитектуру платежного модуля, добавляет и редактирует C4-диаграммы прямо в интерфейсе статьи. Файл сохраняется в ветке feature/adr-payment-module.Архитектор создает запрос на слияние в master, приглашая менеджера, аналитиков и разработчиков на ревью.Аналитики и разработчики просматривают изменения на диаграмме: сравнивают в виде изображения или в виде кода.После обработки комментариев и правок ADR сливается, становясь частью репозитория.Результат: ADR доступны рядом с кодом, история решений сохранена, а согласование занимает меньше времени благодаря подробному диффу в Gramax.Технические писатели: подготовка пользовательской документацииЗадача: технический писатель должен подготовить гайд по использованию платежного модуля и API-документацию, опубликовать их на портале.Писатель создает инструкции по использованию, кодовые блоки (например, curl для API-запросов) и OpenAPI-спецификацию через встроенный сервис. Файлы публикуются в репозиторий в ветке feature/docs-payment-module.Писатель запускает автоматические проверки на соответствие корпоративному стайлгайду и глоссарию.Менеджер продукта просматривает все изменения по задаче: не отдельные документы, а список всех правок с удобной подсветкой. Затем оставляет комментарии или подтверждает готовность для публикации в master.DevOps разворачивают портал документации с помощью Docker или Gramax CLI. Портал обновляется автоматически каждый раз, когда писатель вносит изменения в master.Результат: пользователи читают документацию на удобном портале с интеллектуальным поиском, чат-ботом на базе ИИ, подсветкой кода и брендированным дизайном. Они могут переключаться разные языки и версии документации — например, если продукт поставляется в разные страны и клиенты используют разные версии продукта.DevOps-инженеры: автоматизация поставки документацииЕсли вы разрабатываете ПО для заказчиков, вместе с автоматической сборкой ПО можно наладить автоматическую сборку PDF, DOCX или HTML-файлов с документацией.DevOps встраивает в пайплайн сборки ПО автоматическую генерацию файла с документацией с помощью Gramax CLI.При сборке релиза пакет (ПО + документация) автоматически передается Delivery-менеджеру для поставки заказчику.Результат: каждая поставка включает актуальную документацию, сгенерированную без ручного труда, что ускоряет релиз.И еще о Gramax Лаконичный интерфейс. Как в приложении, так и на портале документации. Страдать не придется.Абсолютная независимость от нас (разработчиков Gramax). Браузерное и десктопное приложение работают на клиенте, информация хранится в вашем Git-хранилище, портал документации разворачивается на вашем сервере.Регулярные обновления. Да, мы стартап. Да, мы отгружаем много фич каждую версию.Фичи для практического применения Mermaid, Draw.io, PlantUML, Open API. Со встроенным редактором!Мультиязычность. Одну документацию можно отобразить на 17 языках.Версионирование. Одну документацию можно отобразить для разных версий.Развитие ИИ-интеграций. Уже есть свой сервис проверок на соответствие стайлгайду, векторный поиск и чат-бот. Чуть позже появится ИИ-валидация: проверки на дублирование и противоречие информации.Экспорт в PDF, DOCX, HTML. Импорт из Confluence и Notion.Редактор изображение. Обрезаем, добавляем обводки и нумерацию прямо в статье.Открыто, бесплатно, и с сообществомСмотрите наш сайт — https://gram.axПроверяйте исходники в GitHub и GitVerse.Вступайте в комьюнити — https://t.me/gramax_chatДелитесь мнениями в комментариях! Что добавить? Что бесит в текущих инструментах документации? Мы читаем и отвечаем.',), kwargs={}
Результат: привет хабр меня зовут катя я лидирую gramax opensource платформу для управления технической документацией однажды мы с коллегами утонули в хаосе рабочих документов без версий без согласований без истории принятых решений это подтолкнуло нас к созданию gramax  инструмента который интегрирует документацию в процесс разработки делая его прозрачным и управляемымв этой статье расскажем как gramax помогает на каждом этапе разработки по как перейти к документированию в подходе docs as code и шагнуть дальше  к everything as codeкто что когда и зачем меняетчто было у нас и часто бывает у других ктото переписывает требования или инструкцию и никто толком не понимает что именно изменилось почему поменяли что было раньше кто согласовал  найти ответы почти невозможно нет понимания что изменилось документ выглядит так же но внутри могут быть полностью другие требования или описания приходится сравнивать версии вручную если они вообще сохранилисьнеясно зачем внесли правки кто решил переписать требования почему убрали тот пункт что стало основанием для изменения контекст правок теряется в чатах и звонках а спустя неделю об этом никто уже не помнит не видно кто согласовал участники команды не понимают была ли правка согласована или ктото просто внес ее по своей инициативе не отследить какие документы готовы а какие в процессенам было важно видеть кто что предложил как это обсуждали и к какому варианту пришли в итоге без гаданий без лишних вопросов давайте сначала что такое gramaxвизуальный редактор для markdown с поддержкой openapi mermaid plantuml и drawioинтеграция с популярными gitхранилищами встроенный gitклиент запросы на слияние версионированиенезависимость от вендоров потому что gramax это selfhosted решение с открытым исходным кодомпонятный и удобный интерфейс для разработчиков аналитиков и нетехнических специалистовможно посмотреть картинки а лучше  протестировать приложение самостоятельноgramax помогает командам хранить всю документацию рядом с кодом автоматизировать процессы и поддерживать единый источник правдыключевая идея gramax  документация должна быть частью инженерной экосистемы а не отдельным процессом который отнимает время мы целимся в everything as code где код документация архитектурные решения и знания управляются единообразно с использованием лучших инженерных практиктеперь о процессах как использоватьрассмотрим как разные участники itкоманды используют gramax при разработке новой функции  например платежного модулясистемные и бизнесаналитики формирование требованийзадача аналитик должен подготовить постановку задачи для платежного модуля согласовать ее с командой и зафиксировать в репозиториианалитик открывает gramax выбирает шаблон для формирования требований описывает все в визуальном редакторе с mermaidдиаграммами для иллюстрации бизнеспроцессадокумент сохраняется в ветке specpaymentmodule в gitрепозитории аналитик создает запрос на слияние в master назначая архитектора и менеджера на ревьюв интерфейсе gramax команда обсуждает документ с помощью комментариев аналитик вносит правку исправления за минуты обновляя веткупосле согласования документ сливается в masterрезультат постановка оформлена по шаблону история изменений сохранена в gitархитекторы проектирование и adrзадача архитектор должен создать архитектурное решение adr для платежного модуля согласовать его и сохранить рядом с кодомархитектор создает adr в gramax описывает архитектуру платежного модуля добавляет и редактирует c4диаграммы прямо в интерфейсе статьи файл сохраняется в ветке featureadrpaymentmoduleархитектор создает запрос на слияние в master приглашая менеджера аналитиков и разработчиков на ревьюаналитики и разработчики просматривают изменения на диаграмме сравнивают в виде изображения или в виде кодапосле обработки комментариев и правок adr сливается становясь частью репозиториярезультат adr доступны рядом с кодом история решений сохранена а согласование занимает меньше времени благодаря подробному диффу в gramaxтехнические писатели подготовка пользовательской документациизадача технический писатель должен подготовить гайд по использованию платежного модуля и apiдокументацию опубликовать их на порталеписатель создает инструкции по использованию кодовые блоки например curl для apiзапросов и openapiспецификацию через встроенный сервис файлы публикуются в репозиторий в ветке featuredocspaymentmoduleписатель запускает автоматические проверки на соответствие корпоративному стайлгайду и глоссариюменеджер продукта просматривает все изменения по задаче не отдельные документы а список всех правок с удобной подсветкой затем оставляет комментарии или подтверждает готовность для публикации в masterdevops разворачивают портал документации с помощью docker или gramax cli портал обновляется автоматически каждый раз когда писатель вносит изменения в masterрезультат пользователи читают документацию на удобном портале с интеллектуальным поиском чатботом на базе ии подсветкой кода и брендированным дизайном они могут переключаться разные языки и версии документации  например если продукт поставляется в разные страны и клиенты используют разные версии продуктаdevopsинженеры автоматизация поставки документацииесли вы разрабатываете по для заказчиков вместе с автоматической сборкой по можно наладить автоматическую сборку pdf docx или htmlфайлов с документациейdevops встраивает в пайплайн сборки по автоматическую генерацию файла с документацией с помощью gramax cliпри сборке релиза пакет по  документация автоматически передается deliveryменеджеру для поставки заказчикурезультат каждая поставка включает актуальную документацию сгенерированную без ручного труда что ускоряет релизи еще о gramax лаконичный интерфейс как в приложении так и на портале документации страдать не придетсяабсолютная независимость от нас разработчиков gramax браузерное и десктопное приложение работают на клиенте информация хранится в вашем gitхранилище портал документации разворачивается на вашем серверерегулярные обновления да мы стартап да мы отгружаем много фич каждую версиюфичи для практического применения mermaid drawio plantuml open api со встроенным редактороммультиязычность одну документацию можно отобразить на 17 языкахверсионирование одну документацию можно отобразить для разных версийразвитие ииинтеграций уже есть свой сервис проверок на соответствие стайлгайду векторный поиск и чатбот чуть позже появится иивалидация проверки на дублирование и противоречие информацииэкспорт в pdf docx html импорт из confluence и notionредактор изображение обрезаем добавляем обводки и нумерацию прямо в статьеоткрыто бесплатно и с сообществомсмотрите наш сайт  httpsgramaxпроверяйте исходники в github и gitverseвступайте в комьюнити  httpstmegramax_chatделитесь мнениями в комментариях что добавить что бесит в текущих инструментах документации мы читаем и отвечаем
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: contains_keywords
Аргументы: args=('Привет, Хабр! Меня зовут Катя, я лидирую Gramax, open-source платформу для управления технической документацией. Однажды мы с коллегами утонули в хаосе рабочих документов: без версий, без согласований, без истории принятых решений. Это подтолкнуло нас к созданию Gramax — инструмента, который интегрирует документацию в процесс разработки, делая его прозрачным и управляемым.В этой статье расскажем, как Gramax помогает на каждом этапе разработки ПО. Как перейти к документированию в подходе Docs as Code и шагнуть дальше — к Everything as Code.Кто, что, когда и зачем меняетЧто было у нас и часто бывает у других: кто-то переписывает требования или инструкцию, и никто толком не понимает, что именно изменилось. Почему поменяли? Что было раньше? Кто согласовал? — найти ответы почти невозможно. Нет понимания, что изменилось. Документ выглядит так же, но внутри могут быть полностью другие требования или описания. Приходится сравнивать версии вручную (если они вообще сохранились).Неясно, зачем внесли правки. Кто решил переписать требования? Почему убрали тот пункт? Что стало основанием для изменения? Контекст правок теряется в чатах и звонках, а спустя неделю об этом никто уже не помнит. Не видно, кто согласовал. Участники команды не понимают, была ли правка согласована или кто-то просто внес ее по своей инициативе. Не отследить, какие документы готовы, а какие в процессе.Нам было важно видеть, кто что предложил, как это обсуждали и к какому варианту пришли в итоге. Без гаданий, без лишних вопросов. Давайте сначала: что такое GramaxВизуальный редактор для Markdown с поддержкой OpenAPI, Mermaid, PlantUML и Draw.io.Интеграция с популярными Git-хранилищами, встроенный Git-клиент, запросы на слияние, версионирование.Независимость от вендоров. Потому что Gramax это self-hosted решение с открытым исходным кодом.Понятный и удобный интерфейс для разработчиков, аналитиков и нетехнических специалистов.Можно посмотреть картинки, а лучше - протестировать приложение самостоятельно:)Gramax помогает командам хранить всю документацию рядом с кодом, автоматизировать процессы и поддерживать единый источник правды.Ключевая идея Gramax — документация должна быть частью инженерной экосистемы, а не отдельным процессом, который отнимает время. Мы целимся в Everything as Code, где код, документация, архитектурные решения и знания управляются единообразно, с использованием лучших инженерных практик.Теперь о процессах: как использоватьРассмотрим, как разные участники IT-команды используют Gramax при разработке новой функции — например, платежного модуля.Системные и бизнес-аналитики: формирование требованийЗадача: аналитик должен подготовить постановку задачи для платежного модуля, согласовать ее с командой и зафиксировать в репозитории.Аналитик открывает Gramax, выбирает шаблон для формирования требований. Описывает все в визуальном редакторе с Mermaid-диаграммами для иллюстрации бизнес-процесса.Документ сохраняется в ветке spec-payment-module в Git-репозитории. Аналитик создает запрос на слияние в master, назначая архитектора и менеджера на ревью.В интерфейсе Gramax команда обсуждает документ с помощью комментариев. Аналитик вносит правку исправления за минуты, обновляя ветку.После согласования документ сливается в master.Результат: постановка оформлена по шаблону, история изменений сохранена в Git.Архитекторы: проектирование и ADRЗадача: архитектор должен создать архитектурное решение (ADR) для платежного модуля, согласовать его и сохранить рядом с кодом.Архитектор создает ADR в Gramax: описывает архитектуру платежного модуля, добавляет и редактирует C4-диаграммы прямо в интерфейсе статьи. Файл сохраняется в ветке feature/adr-payment-module.Архитектор создает запрос на слияние в master, приглашая менеджера, аналитиков и разработчиков на ревью.Аналитики и разработчики просматривают изменения на диаграмме: сравнивают в виде изображения или в виде кода.После обработки комментариев и правок ADR сливается, становясь частью репозитория.Результат: ADR доступны рядом с кодом, история решений сохранена, а согласование занимает меньше времени благодаря подробному диффу в Gramax.Технические писатели: подготовка пользовательской документацииЗадача: технический писатель должен подготовить гайд по использованию платежного модуля и API-документацию, опубликовать их на портале.Писатель создает инструкции по использованию, кодовые блоки (например, curl для API-запросов) и OpenAPI-спецификацию через встроенный сервис. Файлы публикуются в репозиторий в ветке feature/docs-payment-module.Писатель запускает автоматические проверки на соответствие корпоративному стайлгайду и глоссарию.Менеджер продукта просматривает все изменения по задаче: не отдельные документы, а список всех правок с удобной подсветкой. Затем оставляет комментарии или подтверждает готовность для публикации в master.DevOps разворачивают портал документации с помощью Docker или Gramax CLI. Портал обновляется автоматически каждый раз, когда писатель вносит изменения в master.Результат: пользователи читают документацию на удобном портале с интеллектуальным поиском, чат-ботом на базе ИИ, подсветкой кода и брендированным дизайном. Они могут переключаться разные языки и версии документации — например, если продукт поставляется в разные страны и клиенты используют разные версии продукта.DevOps-инженеры: автоматизация поставки документацииЕсли вы разрабатываете ПО для заказчиков, вместе с автоматической сборкой ПО можно наладить автоматическую сборку PDF, DOCX или HTML-файлов с документацией.DevOps встраивает в пайплайн сборки ПО автоматическую генерацию файла с документацией с помощью Gramax CLI.При сборке релиза пакет (ПО + документация) автоматически передается Delivery-менеджеру для поставки заказчику.Результат: каждая поставка включает актуальную документацию, сгенерированную без ручного труда, что ускоряет релиз.И еще о Gramax Лаконичный интерфейс. Как в приложении, так и на портале документации. Страдать не придется.Абсолютная независимость от нас (разработчиков Gramax). Браузерное и десктопное приложение работают на клиенте, информация хранится в вашем Git-хранилище, портал документации разворачивается на вашем сервере.Регулярные обновления. Да, мы стартап. Да, мы отгружаем много фич каждую версию.Фичи для практического применения Mermaid, Draw.io, PlantUML, Open API. Со встроенным редактором!Мультиязычность. Одну документацию можно отобразить на 17 языках.Версионирование. Одну документацию можно отобразить для разных версий.Развитие ИИ-интеграций. Уже есть свой сервис проверок на соответствие стайлгайду, векторный поиск и чат-бот. Чуть позже появится ИИ-валидация: проверки на дублирование и противоречие информации.Экспорт в PDF, DOCX, HTML. Импорт из Confluence и Notion.Редактор изображение. Обрезаем, добавляем обводки и нумерацию прямо в статье.Открыто, бесплатно, и с сообществомСмотрите наш сайт — https://gram.axПроверяйте исходники в GitHub и GitVerse.Вступайте в комьюнити — https://t.me/gramax_chatДелитесь мнениями в комментариях! Что добавить? Что бесит в текущих инструментах документации? Мы читаем и отвечаем.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('Voyager 1 восстановил резервные двигатели перед командной паузой',), kwargs={}
Результат: voyager 1 восстановил резервные двигатели перед командной паузой
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: contains_keywords
Аргументы: args=('Voyager 1 восстановил резервные двигатели перед командной паузой', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:26 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('14.05.2025, Редакционная Группа NASA ScienceДва космических аппарата-близнеца NASA Voyager, запущенные в 1977 году, сейчас движутся в межзвездном пространстве со скоростью около 35 000 миль в час (56 000 км/ч). Эта концепция художника изображает один из зондов. Credit: NASA/JPL-Caltech    Команда миссии хотела починить двигатели, которые несколько десятилетий назад считались непригодными для использования, прежде чем радиоантенна, посылающая команды на зонд, будет отключена для модернизации.Инженеры Лаборатории реактивного движения NASA в Южной Калифорнии восстановили ряд двигателей на борту космического корабля Voyager 1, которые считались неисправными с 2004 года. Ремонт потребовал креативности и риска, но команда хочет иметь их в качестве резерва для работающих двигателей, в топливных трубках которых накапливается остаток, что может привести к их выходу из строя уже этой осенью.Кроме того, миссии необходимо было обеспечить готовность давно бездействующих двигателей к 4 мая, когда наземная антенна, посылающая команды\xa0Voyager 1 и его близнецу Voyager 2,\xa0будет отключена на несколько месяцев для проведения модернизации.Засорение двигателяVoyagers были запущены в 1977 году и мчатся через межзвездное пространство со скоростью около 35 000 миль в час (56 000 км/ч). Оба космических аппарата используют набор основных двигателей, чтобы плавно поворачивать их вверх и вниз, а также вправо и влево, чтобы удерживать антенны направленными на Землю для отправки данных и получения команд. Внутри основного набора двигателей находятся другие двигатели, которые управляют вращательным движением космического аппарата. Если смотреть с Земли, вращательное движение вращает антенну, как виниловую пластинку, чтобы удерживать каждый Voyager направленным на путеводную звезду, которую он использует для ориентации. Оба космических аппарата имеют основной и резервный набор двигателей для этих вращательных движений.Другой набор двигателей, предназначенных для изменения траектории космических аппаратов\xa0во время пролетов внешних планет,\xa0был восстановлен на космических аппаратах в 2018 и 2019 годах, но они не могут вызывать вращательное движение.Чтобы\xa0справиться с засорением трубок\xa0в двигателях, инженеры переключаются между наборами основных, резервных и траекторных двигателей обоих Voyager. Но на Voyager 1 основные двигатели раскрутки перестали работать в 2004 году после потери питания в двух небольших внутренних нагревателях. Инженеры определили, что сломанные нагреватели, вероятно, не подлежат ремонту, и решили положиться исключительно на резервные двигатели раскрутки Voyager 1, чтобы сориентировать звездный трекер.«Я думаю, в то время команда смирилась с тем, что основные двигатели раскрутки не работают, потому что у них был вполне неплохой резерв, — сказал Карим Бадаруддин, менеджер миссии Voyager в JPL, которая управляет миссией для NASA. — И, честно говоря, они, вероятно, не думали, что Voyager-ы прослужат еще 20 лет».Но без возможности контролировать крен космического корабля возникло бы множество проблем, которые могли бы поставить под угрозу миссию, поэтому инженерная группа решила пересмотреть ситуацию с отказом двигателей в 2004 году. Они начали подозревать, что неожиданное изменение или помеха в цепях, управляющих питанием нагревателей, фактически перевели выключатель в неправильное положение. Если бы они смогли вернуть переключатель в исходное положение, обогреватели могли бы снова работать, что позволило бы им повторно активировать основные двигатели раскрутки и использовать их в случае полного засорения резервных двигателей раскрутки, которые использовались с 2004 года.Пауза в общенииРешение требовало решения головоломок. Команде пришлось бы включить бездействующие двигатели раскрутки, а затем попытаться починить и перезапустить нагреватели. Если в это время звездный трекер космического корабля слишком далеко отклонится от путеводной звезды, автоматически включатся давно бездействующие двигатели раскрутки (благодаря программам космического корабля). А если нагреватели все еще были выключены, когда они включились, это могло спровоцировать небольшой взрыв, поэтому команде нужно было направить звездный трекер как можно точнее.Это была бы гонка в любом случае, но команда столкнулась с дополнительной нехваткой времени: с 4 мая 2025 года по февраль 2026 года станция Deep Space Station 43 (DSS-43), антенна шириной 230 футов (70 метров) в Канберре, Австралия, которая является частью\xa0сети Deep Space Network\xa0NASA, будет проходить модернизацию. Она будет отключена большую часть этого времени, с короткими периодами работы в августе и декабре.Хотя сеть дальней космической связи имеет три комплекса, равномерно распределенных по всему земному шару (в Голдстоуне, Калифорния, и Мадриде, а также в Австралии) для обеспечения постоянного контакта с космическими аппаратами по мере вращения Земли, DSS-43 является единственной антенной с достаточной мощностью сигнала для отправки команд «Вояджерам».«Эти усовершенствования антенн важны для будущих пилотируемых высадок на Луну, а также они увеличивают пропускную способность связи для наших научных миссий в дальнем космосе, некоторые из которых основаны на открытиях, сделанных Voyager, — сказала Сюзанна Додд, менеджер проекта Voyager и директор Межпланетной сети в JPL, которая управляет Сетью дальнего космоса для NASA. — Мы уже\xa0сталкивались с\xa0подобными простоями, поэтому мы просто готовимся настолько, насколько можем».Команда хотела убедиться, что давно бездействующие двигатели будут доступны, когда антенна ненадолго возобновит работу в августе, поскольку к этому времени двигатели, которые в настоящее время используются на Voyager 1, могут быть полностью забиты.Предварительная работа принесла свои плоды: 20 марта команда наблюдала, как космический корабль выполняет команды. Из-за расстояния Voyager радиосигналу требуется более 23 часов, чтобы дойти от космического корабля до Земли, то есть все, что команда увидела, произошло почти на день раньше. Если бы тест не удался, Voyager уже мог бы быть в опасности. Но в течение 20 минут команда увидела, как температура нагревателей двигателей резко возросла, и поняла, что им это удалось.«Это был такой славный момент. В тот день боевой дух команды был очень высок, — сказал Тодд Барбер, руководитель миссии по двигательным установкам в JPL. — Эти двигатели считались неисправными. И это был законный вывод. Просто один из наших инженеров догадался, что, возможно, была другая причина, и ее можно было устранить. Это было еще одно чудо, спасшее Voyager.Подробнее о ВояджереVoyager 1 и 2 находятся примерно в 15 миллиардах миль (25 миллиардах километров) и 13 миллиардах миль (21 миллиарде километров) от Земли соответственно. После исследования четырех внешних планет они стали единственными космическими аппаратами, которые когда-либо отправляли данные из межзвездного пространства, области за пределами планет и за пределами защитного пузыря частиц и магнитных полей, создаваемых Солнцем, называемого гелиосферой.Более подробную информацию о миссии NASA Voyager можно найти на сайте: https://science.nasa.gov/mission/voyagerПеревод: Александр Тарлаковский (блог tay-ceti)Оригинал: NASA’s Voyager 1 Revives Backup Thrusters Before Command Pause',), kwargs={}
Результат: 14052025 редакционная группа nasa scienceдва космических аппаратаблизнеца nasa voyager запущенные в 1977 году сейчас движутся в межзвездном пространстве со скоростью около 35 000 миль в час 56 000 кмч эта концепция художника изображает один из зондов credit nasajplcaltech    команда миссии хотела починить двигатели которые несколько десятилетий назад считались непригодными для использования прежде чем радиоантенна посылающая команды на зонд будет отключена для модернизацииинженеры лаборатории реактивного движения nasa в южной калифорнии восстановили ряд двигателей на борту космического корабля voyager 1 которые считались неисправными с 2004 года ремонт потребовал креативности и риска но команда хочет иметь их в качестве резерва для работающих двигателей в топливных трубках которых накапливается остаток что может привести к их выходу из строя уже этой осеньюкроме того миссии необходимо было обеспечить готовность давно бездействующих двигателей к 4 мая когда наземная антенна посылающая команды voyager 1 и его близнецу voyager 2 будет отключена на несколько месяцев для проведения модернизациизасорение двигателяvoyagers были запущены в 1977 году и мчатся через межзвездное пространство со скоростью около 35 000 миль в час 56 000 кмч оба космических аппарата используют набор основных двигателей чтобы плавно поворачивать их вверх и вниз а также вправо и влево чтобы удерживать антенны направленными на землю для отправки данных и получения команд внутри основного набора двигателей находятся другие двигатели которые управляют вращательным движением космического аппарата если смотреть с земли вращательное движение вращает антенну как виниловую пластинку чтобы удерживать каждый voyager направленным на путеводную звезду которую он использует для ориентации оба космических аппарата имеют основной и резервный набор двигателей для этих вращательных движенийдругой набор двигателей предназначенных для изменения траектории космических аппаратов во время пролетов внешних планет был восстановлен на космических аппаратах в 2018 и 2019 годах но они не могут вызывать вращательное движениечтобы справиться с засорением трубок в двигателях инженеры переключаются между наборами основных резервных и траекторных двигателей обоих voyager но на voyager 1 основные двигатели раскрутки перестали работать в 2004 году после потери питания в двух небольших внутренних нагревателях инженеры определили что сломанные нагреватели вероятно не подлежат ремонту и решили положиться исключительно на резервные двигатели раскрутки voyager 1 чтобы сориентировать звездный трекеря думаю в то время команда смирилась с тем что основные двигатели раскрутки не работают потому что у них был вполне неплохой резерв  сказал карим бадаруддин менеджер миссии voyager в jpl которая управляет миссией для nasa  и честно говоря они вероятно не думали что voyagerы прослужат еще 20 летно без возможности контролировать крен космического корабля возникло бы множество проблем которые могли бы поставить под угрозу миссию поэтому инженерная группа решила пересмотреть ситуацию с отказом двигателей в 2004 году они начали подозревать что неожиданное изменение или помеха в цепях управляющих питанием нагревателей фактически перевели выключатель в неправильное положение если бы они смогли вернуть переключатель в исходное положение обогреватели могли бы снова работать что позволило бы им повторно активировать основные двигатели раскрутки и использовать их в случае полного засорения резервных двигателей раскрутки которые использовались с 2004 годапауза в общениирешение требовало решения головоломок команде пришлось бы включить бездействующие двигатели раскрутки а затем попытаться починить и перезапустить нагреватели если в это время звездный трекер космического корабля слишком далеко отклонится от путеводной звезды автоматически включатся давно бездействующие двигатели раскрутки благодаря программам космического корабля а если нагреватели все еще были выключены когда они включились это могло спровоцировать небольшой взрыв поэтому команде нужно было направить звездный трекер как можно точнееэто была бы гонка в любом случае но команда столкнулась с дополнительной нехваткой времени с 4 мая 2025 года по февраль 2026 года станция deep space station 43 dss43 антенна шириной 230 футов 70 метров в канберре австралия которая является частью сети deep space network nasa будет проходить модернизацию она будет отключена большую часть этого времени с короткими периодами работы в августе и декабрехотя сеть дальней космической связи имеет три комплекса равномерно распределенных по всему земному шару в голдстоуне калифорния и мадриде а также в австралии для обеспечения постоянного контакта с космическими аппаратами по мере вращения земли dss43 является единственной антенной с достаточной мощностью сигнала для отправки команд вояджерамэти усовершенствования антенн важны для будущих пилотируемых высадок на луну а также они увеличивают пропускную способность связи для наших научных миссий в дальнем космосе некоторые из которых основаны на открытиях сделанных voyager  сказала сюзанна додд менеджер проекта voyager и директор межпланетной сети в jpl которая управляет сетью дальнего космоса для nasa  мы уже сталкивались с подобными простоями поэтому мы просто готовимся настолько насколько можемкоманда хотела убедиться что давно бездействующие двигатели будут доступны когда антенна ненадолго возобновит работу в августе поскольку к этому времени двигатели которые в настоящее время используются на voyager 1 могут быть полностью забитыпредварительная работа принесла свои плоды 20 марта команда наблюдала как космический корабль выполняет команды изза расстояния voyager радиосигналу требуется более 23 часов чтобы дойти от космического корабля до земли то есть все что команда увидела произошло почти на день раньше если бы тест не удался voyager уже мог бы быть в опасности но в течение 20 минут команда увидела как температура нагревателей двигателей резко возросла и поняла что им это удалосьэто был такой славный момент в тот день боевой дух команды был очень высок  сказал тодд барбер руководитель миссии по двигательным установкам в jpl  эти двигатели считались неисправными и это был законный вывод просто один из наших инженеров догадался что возможно была другая причина и ее можно было устранить это было еще одно чудо спасшее voyagerподробнее о вояджереvoyager 1 и 2 находятся примерно в 15 миллиардах миль 25 миллиардах километров и 13 миллиардах миль 21 миллиарде километров от земли соответственно после исследования четырех внешних планет они стали единственными космическими аппаратами которые когдалибо отправляли данные из межзвездного пространства области за пределами планет и за пределами защитного пузыря частиц и магнитных полей создаваемых солнцем называемого гелиосферойболее подробную информацию о миссии nasa voyager можно найти на сайте httpssciencenasagovmissionvoyagerперевод александр тарлаковский блог taycetiоригинал nasas voyager 1 revives backup thrusters before command pause
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: contains_keywords
Аргументы: args=('14.05.2025, Редакционная Группа NASA ScienceДва космических аппарата-близнеца NASA Voyager, запущенные в 1977 году, сейчас движутся в межзвездном пространстве со скоростью около 35 000 миль в час (56 000 км/ч). Эта концепция художника изображает один из зондов. Credit: NASA/JPL-Caltech    Команда миссии хотела починить двигатели, которые несколько десятилетий назад считались непригодными для использования, прежде чем радиоантенна, посылающая команды на зонд, будет отключена для модернизации.Инженеры Лаборатории реактивного движения NASA в Южной Калифорнии восстановили ряд двигателей на борту космического корабля Voyager 1, которые считались неисправными с 2004 года. Ремонт потребовал креативности и риска, но команда хочет иметь их в качестве резерва для работающих двигателей, в топливных трубках которых накапливается остаток, что может привести к их выходу из строя уже этой осенью.Кроме того, миссии необходимо было обеспечить готовность давно бездействующих двигателей к 4 мая, когда наземная антенна, посылающая команды\xa0Voyager 1 и его близнецу Voyager 2,\xa0будет отключена на несколько месяцев для проведения модернизации.Засорение двигателяVoyagers были запущены в 1977 году и мчатся через межзвездное пространство со скоростью около 35 000 миль в час (56 000 км/ч). Оба космических аппарата используют набор основных двигателей, чтобы плавно поворачивать их вверх и вниз, а также вправо и влево, чтобы удерживать антенны направленными на Землю для отправки данных и получения команд. Внутри основного набора двигателей находятся другие двигатели, которые управляют вращательным движением космического аппарата. Если смотреть с Земли, вращательное движение вращает антенну, как виниловую пластинку, чтобы удерживать каждый Voyager направленным на путеводную звезду, которую он использует для ориентации. Оба космических аппарата имеют основной и резервный набор двигателей для этих вращательных движений.Другой набор двигателей, предназначенных для изменения траектории космических аппаратов\xa0во время пролетов внешних планет,\xa0был восстановлен на космических аппаратах в 2018 и 2019 годах, но они не могут вызывать вращательное движение.Чтобы\xa0справиться с засорением трубок\xa0в двигателях, инженеры переключаются между наборами основных, резервных и траекторных двигателей обоих Voyager. Но на Voyager 1 основные двигатели раскрутки перестали работать в 2004 году после потери питания в двух небольших внутренних нагревателях. Инженеры определили, что сломанные нагреватели, вероятно, не подлежат ремонту, и решили положиться исключительно на резервные двигатели раскрутки Voyager 1, чтобы сориентировать звездный трекер.«Я думаю, в то время команда смирилась с тем, что основные двигатели раскрутки не работают, потому что у них был вполне неплохой резерв, — сказал Карим Бадаруддин, менеджер миссии Voyager в JPL, которая управляет миссией для NASA. — И, честно говоря, они, вероятно, не думали, что Voyager-ы прослужат еще 20 лет».Но без возможности контролировать крен космического корабля возникло бы множество проблем, которые могли бы поставить под угрозу миссию, поэтому инженерная группа решила пересмотреть ситуацию с отказом двигателей в 2004 году. Они начали подозревать, что неожиданное изменение или помеха в цепях, управляющих питанием нагревателей, фактически перевели выключатель в неправильное положение. Если бы они смогли вернуть переключатель в исходное положение, обогреватели могли бы снова работать, что позволило бы им повторно активировать основные двигатели раскрутки и использовать их в случае полного засорения резервных двигателей раскрутки, которые использовались с 2004 года.Пауза в общенииРешение требовало решения головоломок. Команде пришлось бы включить бездействующие двигатели раскрутки, а затем попытаться починить и перезапустить нагреватели. Если в это время звездный трекер космического корабля слишком далеко отклонится от путеводной звезды, автоматически включатся давно бездействующие двигатели раскрутки (благодаря программам космического корабля). А если нагреватели все еще были выключены, когда они включились, это могло спровоцировать небольшой взрыв, поэтому команде нужно было направить звездный трекер как можно точнее.Это была бы гонка в любом случае, но команда столкнулась с дополнительной нехваткой времени: с 4 мая 2025 года по февраль 2026 года станция Deep Space Station 43 (DSS-43), антенна шириной 230 футов (70 метров) в Канберре, Австралия, которая является частью\xa0сети Deep Space Network\xa0NASA, будет проходить модернизацию. Она будет отключена большую часть этого времени, с короткими периодами работы в августе и декабре.Хотя сеть дальней космической связи имеет три комплекса, равномерно распределенных по всему земному шару (в Голдстоуне, Калифорния, и Мадриде, а также в Австралии) для обеспечения постоянного контакта с космическими аппаратами по мере вращения Земли, DSS-43 является единственной антенной с достаточной мощностью сигнала для отправки команд «Вояджерам».«Эти усовершенствования антенн важны для будущих пилотируемых высадок на Луну, а также они увеличивают пропускную способность связи для наших научных миссий в дальнем космосе, некоторые из которых основаны на открытиях, сделанных Voyager, — сказала Сюзанна Додд, менеджер проекта Voyager и директор Межпланетной сети в JPL, которая управляет Сетью дальнего космоса для NASA. — Мы уже\xa0сталкивались с\xa0подобными простоями, поэтому мы просто готовимся настолько, насколько можем».Команда хотела убедиться, что давно бездействующие двигатели будут доступны, когда антенна ненадолго возобновит работу в августе, поскольку к этому времени двигатели, которые в настоящее время используются на Voyager 1, могут быть полностью забиты.Предварительная работа принесла свои плоды: 20 марта команда наблюдала, как космический корабль выполняет команды. Из-за расстояния Voyager радиосигналу требуется более 23 часов, чтобы дойти от космического корабля до Земли, то есть все, что команда увидела, произошло почти на день раньше. Если бы тест не удался, Voyager уже мог бы быть в опасности. Но в течение 20 минут команда увидела, как температура нагревателей двигателей резко возросла, и поняла, что им это удалось.«Это был такой славный момент. В тот день боевой дух команды был очень высок, — сказал Тодд Барбер, руководитель миссии по двигательным установкам в JPL. — Эти двигатели считались неисправными. И это был законный вывод. Просто один из наших инженеров догадался, что, возможно, была другая причина, и ее можно было устранить. Это было еще одно чудо, спасшее Voyager.Подробнее о ВояджереVoyager 1 и 2 находятся примерно в 15 миллиардах миль (25 миллиардах километров) и 13 миллиардах миль (21 миллиарде километров) от Земли соответственно. После исследования четырех внешних планет они стали единственными космическими аппаратами, которые когда-либо отправляли данные из межзвездного пространства, области за пределами планет и за пределами защитного пузыря частиц и магнитных полей, создаваемых Солнцем, называемого гелиосферой.Более подробную информацию о миссии NASA Voyager можно найти на сайте: https://science.nasa.gov/mission/voyagerПеревод: Александр Тарлаковский (блог tay-ceti)Оригинал: NASA’s Voyager 1 Revives Backup Thrusters Before Command Pause', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('Приходят как-то аналитики на офисную кухню, а там дата-инженеры в нарды играют…',), kwargs={}
Результат: приходят както аналитики на офисную кухню а там датаинженеры в нарды играют
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: contains_keywords
Аргументы: args=('Приходят как-то аналитики на офисную кухню, а там дата-инженеры в нарды играют…', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:27 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('Один из игроков — я, Кирилл Красновид, тимлид BI-команды в Профи.ру. Наша задача — делать так, чтобы каждый быстро и удобно получал нужную информацию без лишней суеты и ожиданий.\xa0Поэтому мы стараемся все автоматизировать и оптимизировать. Сегодня расскажу, как решаем эти задачи, а ещё про собственные хранилища аналитиков и bus-фактор.Bus-фактор показывает, не провалится ли проект, если кого-то из членов команды собьёт автобус. Чем выше фактор, тем меньше в этом случае пострадает работа.Например, если вся информация по проекту лежит в голове одного человека и никто не знает, чем занимается этот коллега, bus-фактор = 1. Сотрудник выпадёт из работы, и она остановится. Лучше, когда показатель равен хотя бы пяти.Главное, чтобы всем было удобно\xa0Сейчас в нашей BI-команде шесть человек: четыре дата-инженера, один архитектор данных и BI-аналитик. Мы не сторонники жёсткой специализации, но по естественному стечению обстоятельств — у каждого своё направление. Например, один человек занимается хранилищем: задаёт стандарты, формализует продуктовые требования и на их основе формирует подходы к фильтрации данных. Кто-то занимается A/B-платформой и тестами, кто-то — BI и визуализацией.\xa0Но бывает и так, что вся команда в рамках одного спринта делает один проект. В результате нет такого, что «работает специалист по A/B-платформе и он никогда голову из неё не высовывает». Нет, лучше, когда команда делится экспертизой внутри. Это улучшает и настроение, и bus-фактор.\xa0Вшестером мы решаем задачи от аналитиков. Раньше они сами копались в копии (aka реплике) мастер-базы продукта, иногда перегружали систему. Да и в целом мастер-база крайне плохо подходит для аналитических исследований. Для таких задачи сильно эффективнее использовать специальные СУБД.\xa0Сейчас мы делаем так, чтобы нужные аналитикам данные уже были загружены, структурированы и задокументированы на начало рабочего дня, а наша помощь требовалась только при нештатных ситуацияхМы не просто так строим удобную систему для аналитиков. Когда они ждут данные месяцами, то начинают делать свои «мини-хранилища». Ничего другого им не остается.\xa0Личные хранилища аналитиков дублируют основную систему и создают хаос. Повышают риски:\xa0Вся экспертиза остается у одного человека. Часто нет ни документации, ни исходного кода. Если специалист уходит — данные и логика расчётов теряются. Вспоминаем про bus-фактор.Такие расчёты не резервируются как положено. Риск потери данных выше, чем при работе через штатные механизмы загрузки.Чтобы этого не происходило и аналитики не томились в ожидании, мы максимально автоматизировали постановку задач. После каждого спринта коллегам приходит сообщение: «Накидывайте задачи BI-команде на следующий спринт».\xa0Люди оставляют запросы. В течение текущего спринта мы в фоновом режиме внимательно всё читаем и задаём уточняющие вопросы. Это нужно, чтобы к началу следующего спринта задача была чётко сформулирована и готова к разработке.Стандартные задачи идут в спринт по обычному процессу. Глобальные запросы, например, внедрение новых инструментов, концептуальные изменения или просто ресурсоемкие задачи, мы обсуждаем отдельно.Как работает на практике в потоковой аналитике. Аналитики уведомляют нас об отправке продуктовых событий — нажатиях кнопок, показах экранов.\xa0\n\nМы проводим ревью изменений в конфигурации. Данные поступают в базу и появляются на витринах. Больше нашего участия в процессе нет. Аналитики сами решают, как работать с информацией.\xa0Но коммуникация между командами — половина дела. Вторая часть — техническая. Мы построили систему, она уже неплохо работает. Теперь хотим делать её лучше: снижать вычислительную нагрузку, предоставлять данные и вносить изменения быстрее, быть готовыми к кратному росту количества данных. Сейчас расскажу, как к этому идём.Что есть сейчас и что планируемУ нас в BI-команде две СУБД. Первая — Greenplum. Её используем для сложных джоинов. В ближайшем будущем будем переходить на CloudberryDB. Вторая — ClickHouse. Она лучше справляется с одной широкой таблицей и быстрыми агрегациями.Данные собираем из разных источников: объединённой продуктовой базы, потоковой аналитики (в режиме реального времени и по расписанию), внешних источников, статических данных, а также через ручной ввод пользователями.Всё складывается слоями: сначала поступают сырые данные. Затем мы формируем трансформационный слой — очищаем данные от тестовых и ошибочных записей, структурируем их. В исходном виде с ними не всегда удобно работать. Затем формируем слой витрин данных для аналитиков. Получается три слоя: исходные данные, фильтрованные сущности и готовые витрины.\xa0Благодаря такой архитектуре аналитики могут не ходить в исходные данные. Всё уже структурировано, данные размечены, и коллеги видят нормальные колонки с готовыми метриками.\xa0Витрины данных формируются на основе таблиц, часть из которых обновляются целиком. Там, где это возможно, мы уже реализуем инкрементальную загрузку — забираем только новые или изменённые записи. Однако универсального и надежного инструмента такой работы со всеми сущностями сейчас нет.\xa0Есть проблема историзации данных. История изменений параметров сущностей важна и для аналитики, и для расследования инцидентов. Сейчас, если в источнике данных не предусмотрено хранение истории изменений атрибутов (SCD1), мы со своей стороны можем лишь делать слепки состояний на определенные моменты времени. Но нас это не устраивает по двум причинам:Между моментами снятия слепков происходит множество изменений. Они остаются незамеченными.Невозможно сделать слепок всех атрибутов всех сущностей на один момент времени. Зачем это нужно? Вот пример: есть две связанные сущности. Данные по первой сущности извлекаются в момент времени Т1, а по второй — в момент Т2. Данные по первой сущности к моменту Т2 могли претерпеть изменения. Из-за этого связность данных может нарушиться.Мы хотим обойти все ограничения и сделать так, чтобы работа с витринами данных шла быстрее. Для этого внедряем механизм наполнения слоя сырых данных с помощью Change Data Capture или CDC — захвата изменения информации.\xa0Так мы сможем в реальном времени получать все факты изменения данных в мастер-базе и из них восстанавливать таблицы. Не нужно будет повторно читать всю информацию, обработка будет происходить только для новых значений. Мы будем получать максимально детальную историю изменения любых сущностей.\xa0После внедрения CDC в слой сырых данных мы сможем формировать инкрементально и следующие слои. В отдельных случаях даже работать с ними в режиме реального времени.Есть ещё один вопрос — о вычислительных ресурсах. Пересчитывать витрины напрямую — долго и дорого. Поэтому мы планируем добавить промежуточные слои. Одно из решений — activity schema. В ней все события, от размещения заказов до действий специалистов, будут собираться в несколько больших широких таблиц по ключевым сущностям. Это снизит нагрузку, так как избавит от тяжёлых джоинов, а также упростит написание кода запросов для аналитиков.Звучит как утопия. На самом деле есть и минусы. Такие решения, как правило, требуют большего объема дискового пространства, причём диски должны быть быстрыми. Но для нас покупать диски все равно оказывается дешевле.Мы нашли такое решение, но с радостью почитаем и про другие практики. Ваш ход, читатели — ждём комментарии.',), kwargs={}
Результат: один из игроков  я кирилл красновид тимлид biкоманды в профиру наша задача  делать так чтобы каждый быстро и удобно получал нужную информацию без лишней суеты и ожиданий поэтому мы стараемся все автоматизировать и оптимизировать сегодня расскажу как решаем эти задачи а ещё про собственные хранилища аналитиков и busфакторbusфактор показывает не провалится ли проект если когото из членов команды собьёт автобус чем выше фактор тем меньше в этом случае пострадает работанапример если вся информация по проекту лежит в голове одного человека и никто не знает чем занимается этот коллега busфактор  1 сотрудник выпадёт из работы и она остановится лучше когда показатель равен хотя бы пятиглавное чтобы всем было удобно сейчас в нашей biкоманде шесть человек четыре датаинженера один архитектор данных и biаналитик мы не сторонники жёсткой специализации но по естественному стечению обстоятельств  у каждого своё направление например один человек занимается хранилищем задаёт стандарты формализует продуктовые требования и на их основе формирует подходы к фильтрации данных ктото занимается abплатформой и тестами ктото  bi и визуализацией но бывает и так что вся команда в рамках одного спринта делает один проект в результате нет такого что работает специалист по abплатформе и он никогда голову из неё не высовывает нет лучше когда команда делится экспертизой внутри это улучшает и настроение и busфактор вшестером мы решаем задачи от аналитиков раньше они сами копались в копии aka реплике мастербазы продукта иногда перегружали систему да и в целом мастербаза крайне плохо подходит для аналитических исследований для таких задачи сильно эффективнее использовать специальные субд сейчас мы делаем так чтобы нужные аналитикам данные уже были загружены структурированы и задокументированы на начало рабочего дня а наша помощь требовалась только при нештатных ситуацияхмы не просто так строим удобную систему для аналитиков когда они ждут данные месяцами то начинают делать свои минихранилища ничего другого им не остается личные хранилища аналитиков дублируют основную систему и создают хаос повышают риски вся экспертиза остается у одного человека часто нет ни документации ни исходного кода если специалист уходит  данные и логика расчётов теряются вспоминаем про busфактортакие расчёты не резервируются как положено риск потери данных выше чем при работе через штатные механизмы загрузкичтобы этого не происходило и аналитики не томились в ожидании мы максимально автоматизировали постановку задач после каждого спринта коллегам приходит сообщение накидывайте задачи biкоманде на следующий спринт люди оставляют запросы в течение текущего спринта мы в фоновом режиме внимательно всё читаем и задаём уточняющие вопросы это нужно чтобы к началу следующего спринта задача была чётко сформулирована и готова к разработкестандартные задачи идут в спринт по обычному процессу глобальные запросы например внедрение новых инструментов концептуальные изменения или просто ресурсоемкие задачи мы обсуждаем отдельнокак работает на практике в потоковой аналитике аналитики уведомляют нас об отправке продуктовых событий  нажатиях кнопок показах экранов 

мы проводим ревью изменений в конфигурации данные поступают в базу и появляются на витринах больше нашего участия в процессе нет аналитики сами решают как работать с информацией но коммуникация между командами  половина дела вторая часть  техническая мы построили систему она уже неплохо работает теперь хотим делать её лучше снижать вычислительную нагрузку предоставлять данные и вносить изменения быстрее быть готовыми к кратному росту количества данных сейчас расскажу как к этому идёмчто есть сейчас и что планируему нас в biкоманде две субд первая  greenplum её используем для сложных джоинов в ближайшем будущем будем переходить на cloudberrydb вторая  clickhouse она лучше справляется с одной широкой таблицей и быстрыми агрегациямиданные собираем из разных источников объединённой продуктовой базы потоковой аналитики в режиме реального времени и по расписанию внешних источников статических данных а также через ручной ввод пользователямивсё складывается слоями сначала поступают сырые данные затем мы формируем трансформационный слой  очищаем данные от тестовых и ошибочных записей структурируем их в исходном виде с ними не всегда удобно работать затем формируем слой витрин данных для аналитиков получается три слоя исходные данные фильтрованные сущности и готовые витрины благодаря такой архитектуре аналитики могут не ходить в исходные данные всё уже структурировано данные размечены и коллеги видят нормальные колонки с готовыми метриками витрины данных формируются на основе таблиц часть из которых обновляются целиком там где это возможно мы уже реализуем инкрементальную загрузку  забираем только новые или изменённые записи однако универсального и надежного инструмента такой работы со всеми сущностями сейчас нет есть проблема историзации данных история изменений параметров сущностей важна и для аналитики и для расследования инцидентов сейчас если в источнике данных не предусмотрено хранение истории изменений атрибутов scd1 мы со своей стороны можем лишь делать слепки состояний на определенные моменты времени но нас это не устраивает по двум причинаммежду моментами снятия слепков происходит множество изменений они остаются незамеченныминевозможно сделать слепок всех атрибутов всех сущностей на один момент времени зачем это нужно вот пример есть две связанные сущности данные по первой сущности извлекаются в момент времени т1 а по второй  в момент т2 данные по первой сущности к моменту т2 могли претерпеть изменения изза этого связность данных может нарушитьсямы хотим обойти все ограничения и сделать так чтобы работа с витринами данных шла быстрее для этого внедряем механизм наполнения слоя сырых данных с помощью change data capture или cdc  захвата изменения информации так мы сможем в реальном времени получать все факты изменения данных в мастербазе и из них восстанавливать таблицы не нужно будет повторно читать всю информацию обработка будет происходить только для новых значений мы будем получать максимально детальную историю изменения любых сущностей после внедрения cdc в слой сырых данных мы сможем формировать инкрементально и следующие слои в отдельных случаях даже работать с ними в режиме реального времениесть ещё один вопрос  о вычислительных ресурсах пересчитывать витрины напрямую  долго и дорого поэтому мы планируем добавить промежуточные слои одно из решений  activity schema в ней все события от размещения заказов до действий специалистов будут собираться в несколько больших широких таблиц по ключевым сущностям это снизит нагрузку так как избавит от тяжёлых джоинов а также упростит написание кода запросов для аналитиковзвучит как утопия на самом деле есть и минусы такие решения как правило требуют большего объема дискового пространства причём диски должны быть быстрыми но для нас покупать диски все равно оказывается дешевлемы нашли такое решение но с радостью почитаем и про другие практики ваш ход читатели  ждём комментарии
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: contains_keywords
Аргументы: args=('Один из игроков — я, Кирилл Красновид, тимлид BI-команды в Профи.ру. Наша задача — делать так, чтобы каждый быстро и удобно получал нужную информацию без лишней суеты и ожиданий.\xa0Поэтому мы стараемся все автоматизировать и оптимизировать. Сегодня расскажу, как решаем эти задачи, а ещё про собственные хранилища аналитиков и bus-фактор.Bus-фактор показывает, не провалится ли проект, если кого-то из членов команды собьёт автобус. Чем выше фактор, тем меньше в этом случае пострадает работа.Например, если вся информация по проекту лежит в голове одного человека и никто не знает, чем занимается этот коллега, bus-фактор = 1. Сотрудник выпадёт из работы, и она остановится. Лучше, когда показатель равен хотя бы пяти.Главное, чтобы всем было удобно\xa0Сейчас в нашей BI-команде шесть человек: четыре дата-инженера, один архитектор данных и BI-аналитик. Мы не сторонники жёсткой специализации, но по естественному стечению обстоятельств — у каждого своё направление. Например, один человек занимается хранилищем: задаёт стандарты, формализует продуктовые требования и на их основе формирует подходы к фильтрации данных. Кто-то занимается A/B-платформой и тестами, кто-то — BI и визуализацией.\xa0Но бывает и так, что вся команда в рамках одного спринта делает один проект. В результате нет такого, что «работает специалист по A/B-платформе и он никогда голову из неё не высовывает». Нет, лучше, когда команда делится экспертизой внутри. Это улучшает и настроение, и bus-фактор.\xa0Вшестером мы решаем задачи от аналитиков. Раньше они сами копались в копии (aka реплике) мастер-базы продукта, иногда перегружали систему. Да и в целом мастер-база крайне плохо подходит для аналитических исследований. Для таких задачи сильно эффективнее использовать специальные СУБД.\xa0Сейчас мы делаем так, чтобы нужные аналитикам данные уже были загружены, структурированы и задокументированы на начало рабочего дня, а наша помощь требовалась только при нештатных ситуацияхМы не просто так строим удобную систему для аналитиков. Когда они ждут данные месяцами, то начинают делать свои «мини-хранилища». Ничего другого им не остается.\xa0Личные хранилища аналитиков дублируют основную систему и создают хаос. Повышают риски:\xa0Вся экспертиза остается у одного человека. Часто нет ни документации, ни исходного кода. Если специалист уходит — данные и логика расчётов теряются. Вспоминаем про bus-фактор.Такие расчёты не резервируются как положено. Риск потери данных выше, чем при работе через штатные механизмы загрузки.Чтобы этого не происходило и аналитики не томились в ожидании, мы максимально автоматизировали постановку задач. После каждого спринта коллегам приходит сообщение: «Накидывайте задачи BI-команде на следующий спринт».\xa0Люди оставляют запросы. В течение текущего спринта мы в фоновом режиме внимательно всё читаем и задаём уточняющие вопросы. Это нужно, чтобы к началу следующего спринта задача была чётко сформулирована и готова к разработке.Стандартные задачи идут в спринт по обычному процессу. Глобальные запросы, например, внедрение новых инструментов, концептуальные изменения или просто ресурсоемкие задачи, мы обсуждаем отдельно.Как работает на практике в потоковой аналитике. Аналитики уведомляют нас об отправке продуктовых событий — нажатиях кнопок, показах экранов.\xa0\n\nМы проводим ревью изменений в конфигурации. Данные поступают в базу и появляются на витринах. Больше нашего участия в процессе нет. Аналитики сами решают, как работать с информацией.\xa0Но коммуникация между командами — половина дела. Вторая часть — техническая. Мы построили систему, она уже неплохо работает. Теперь хотим делать её лучше: снижать вычислительную нагрузку, предоставлять данные и вносить изменения быстрее, быть готовыми к кратному росту количества данных. Сейчас расскажу, как к этому идём.Что есть сейчас и что планируемУ нас в BI-команде две СУБД. Первая — Greenplum. Её используем для сложных джоинов. В ближайшем будущем будем переходить на CloudberryDB. Вторая — ClickHouse. Она лучше справляется с одной широкой таблицей и быстрыми агрегациями.Данные собираем из разных источников: объединённой продуктовой базы, потоковой аналитики (в режиме реального времени и по расписанию), внешних источников, статических данных, а также через ручной ввод пользователями.Всё складывается слоями: сначала поступают сырые данные. Затем мы формируем трансформационный слой — очищаем данные от тестовых и ошибочных записей, структурируем их. В исходном виде с ними не всегда удобно работать. Затем формируем слой витрин данных для аналитиков. Получается три слоя: исходные данные, фильтрованные сущности и готовые витрины.\xa0Благодаря такой архитектуре аналитики могут не ходить в исходные данные. Всё уже структурировано, данные размечены, и коллеги видят нормальные колонки с готовыми метриками.\xa0Витрины данных формируются на основе таблиц, часть из которых обновляются целиком. Там, где это возможно, мы уже реализуем инкрементальную загрузку — забираем только новые или изменённые записи. Однако универсального и надежного инструмента такой работы со всеми сущностями сейчас нет.\xa0Есть проблема историзации данных. История изменений параметров сущностей важна и для аналитики, и для расследования инцидентов. Сейчас, если в источнике данных не предусмотрено хранение истории изменений атрибутов (SCD1), мы со своей стороны можем лишь делать слепки состояний на определенные моменты времени. Но нас это не устраивает по двум причинам:Между моментами снятия слепков происходит множество изменений. Они остаются незамеченными.Невозможно сделать слепок всех атрибутов всех сущностей на один момент времени. Зачем это нужно? Вот пример: есть две связанные сущности. Данные по первой сущности извлекаются в момент времени Т1, а по второй — в момент Т2. Данные по первой сущности к моменту Т2 могли претерпеть изменения. Из-за этого связность данных может нарушиться.Мы хотим обойти все ограничения и сделать так, чтобы работа с витринами данных шла быстрее. Для этого внедряем механизм наполнения слоя сырых данных с помощью Change Data Capture или CDC — захвата изменения информации.\xa0Так мы сможем в реальном времени получать все факты изменения данных в мастер-базе и из них восстанавливать таблицы. Не нужно будет повторно читать всю информацию, обработка будет происходить только для новых значений. Мы будем получать максимально детальную историю изменения любых сущностей.\xa0После внедрения CDC в слой сырых данных мы сможем формировать инкрементально и следующие слои. В отдельных случаях даже работать с ними в режиме реального времени.Есть ещё один вопрос — о вычислительных ресурсах. Пересчитывать витрины напрямую — долго и дорого. Поэтому мы планируем добавить промежуточные слои. Одно из решений — activity schema. В ней все события, от размещения заказов до действий специалистов, будут собираться в несколько больших широких таблиц по ключевым сущностям. Это снизит нагрузку, так как избавит от тяжёлых джоинов, а также упростит написание кода запросов для аналитиков.Звучит как утопия. На самом деле есть и минусы. Такие решения, как правило, требуют большего объема дискового пространства, причём диски должны быть быстрыми. Но для нас покупать диски все равно оказывается дешевле.Мы нашли такое решение, но с радостью почитаем и про другие практики. Ваш ход, читатели — ждём комментарии.', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('Веб-разработка на ванильном HTML, CSS и JavaScript: стилизация и сайты',), kwargs={}
Результат: вебразработка на ванильном html css и javascript стилизация и сайты
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: contains_keywords
Аргументы: args=('Веб-разработка на ванильном HTML, CSS и JavaScript: стилизация и сайты', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:28 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('\nЭто вторая статья из цикла переводов о веб-разработке на чистых (ванильных) технологиях — без фреймворков и сторонних инструментов, только HTML, CSS и JavaScript. В первой части мы обсудили, почему такой подход может быть разумной альтернативой современным фреймворкам и рассмотрели использование веб-компонентов в качестве базовых строительных блоков для создания более сложных примитивов. В этот раз поговорим про стилизацию, а также деплой компонентов в продакшен без использования сборщиков, фреймворков или серверной логики.\n\nСовременный CSS\nСовременные веб-приложения построены на основе богатого инструментария работы с CSS, связанного со множеством пакетов NPM и этапов сборки. Ванильное же веб-приложение может выбрать более легковесный путь, отказавшись от современных методик с предварительно обработанным CSS и выбрав нативные для браузеров стратегии.\n\nСброс\nСброс стилей до общего для всех браузеров среднего — стандартная практика в веб-разработке, и ванильные веб-приложения в этом ничем не отличаются.\n\nМинимальный сброс используется следующим сайтом:\n\nreset.css\n\n/* обобщённый минималистичный сброс CSS\n   источник вдохновения: https://www.digitalocean.com/community/tutorials/css-minimal-css-reset */\n\n:root {\n    box-sizing: border-box;\n    line-height: 1.4;\n    /* https://kilianvalkhof.com/2022/css-html/your-css-reset-needs-text-size-adjust-probably/ */\n    -moz-text-size-adjust: none;\n    -webkit-text-size-adjust: none;\n    text-size-adjust: none;\n}\n\n*, *::before, *::after {\n    box-sizing: inherit;\n}\n\nbody, h1, h2, h3, h4, h5, h6, p {\n    margin: 0;\n    padding: 0;\n    font-weight: normal;\n}\n\nimg {\n    max-width:100%;\n    height:auto;\n}\nВот другие варианты в порядке по возрастанию сложности:\n\nmodern-normalize — более подробное решение для сброса CSS в современных браузерах. Включение из CDN\n\nKraken — начальная точка для проектов фронтенда. Включает в себя сброс CSS, типографику, сетку и другие удобные инструменты. Включение из CDN\n\nPico CSS — готовый набор начинающего для стилизации семантического HTML, в том числе и для сброса CSS. Включение из CDN\n\nTailwind — если вы всё равно будете использовать Tailwind, то можете и использовать его сброс CSS. Включение из CDN\n\nШрифты\nТипографика — фундамент веб-сайта или приложения. Такой легковесный подход, как ванильная веб-разработка, должен согласоваться с легковесным подходом к типографике.\n\nВ Modern Font Stacks описываются разнообразные популярные шрифты и варианты отката, позволяющие не загружать пользовательские шрифты и не добавлять внешние зависимости.\n\nНа нашем сайте используется стек Geometric Humanist для обычного текста и стек Monospace Code для исходного кода.\n\nИнструментарий\nВ реальном веб-проекте в случае отсутствия правильной структуры объём CSS быстро становится огромным. Давайте рассмотрим инструментарий для создания такой структуры, который предоставляет нам CSS в современных браузерах.\n\n@import — самая базовая техника структурирования — это разбиение CSS на несколько файлов. Мы можем добавлять все эти файлы по порядку как теги <link> в index.html, но это быстро становится неудобным, если мы работаем с несколькими HTML-страницами. Вместо этого лучше импортировать их в index.css.\n\nНапример, вот основной файл CSS нашего сайта:\n\nindex.css\n\n@import url("./styles/reset.css");\n@import url("./styles/variables.css");\n@import url("./styles/global.css");\n@import url("./components/code-viewer/code-viewer.css");\n@import url("./components/tab-panel/tab-panel.css");\nНиже показан рекомендованный способ упорядочивания файлов CSS.\n\nПользовательские свойства (переменные) — переменные CSS можно использовать для централизованного определения шрифта и темы сайта.\n\nНапример, вот переменные для нашего сайта:\n\nvariables.css\n\n:root {\n    /* https://modernfontstacks.com/\n       geometric humanist font */\n    --font-system: Avenir, Montserrat, Corbel, source-sans-pro, sans-serif;\n    /* monospace code font */\n    --font-system-code: ui-monospace, \'Cascadia Code\', \'Source Code Pro\', Menlo, Consolas, \'DejaVu Sans Mono\', monospace;\n    --font-system-code-size: 0.8rem;\n\n    --background-color: white;\n\n    --text-color: black;\n    --text-color-mute: hsl(0, 0%, 40%);\n\n    --link-color: darkblue;\n\n    --nav-separator-color: goldenrod;\n    --nav-background-color: hsl(50, 50%, 95%);\n\n    --border-color: black;\n\n    --code-text-color: var(--text-color);\n    --code-text-color-bg: inherit;\n\n    --panel-title-color: black;\n    --panel-title-color-bg: cornsilk;\n}\nЕщё более мощными переменные CSS становятся в сочетании с calc().\n\nПользовательские элементы — область видимости стилей легко можно ограничить тегом пользовательского элемента. Например, все стили компонента аватара из предыдущей части статьи имеют в качестве префикса селектор x-avatar:\n\navatar.css\n\nx-avatar {\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    width: 2.5rem;\n    height: 2.5rem;\n}\n\nx-avatar[size=lg] {\n    width: 3.5rem;\n    height: 3.5rem;\n}\n\nx-avatar img {\n    border-radius: 9999px;\n    width: 100%;\n    height: 100%;\n    vertical-align: middle;\n    object-fit: cover;\n}\nПользовательские элементы также могут иметь произвольные атрибуты, которые могут использоваться селекторами, как в случае со стилем [size=lg] из этого примера.\n\nShadow DOM — добавление shadow DOM к веб-компоненту ещё сильнее изолирует его стили от остальной части страницы. Например, компонент x-header из предыдущей части стилизует свой элемент h1 внутри своего CSS, не влияя на содержащую его страницу и на дочерние элементы заголовка.\n\nВсе файлы CSS, которые нужно применить к shadow DOM, должны загружаться в неё явным образом, однако переменные CSS передаются в shadow DOM.\n\nОграничение shadow DOM заключается в том, что для использования внутри них пользовательских шрифтов их сначала нужно загрузить в «светлую» DOM.\n\nФайлы\nСуществует множество способов упорядочивания файлов CSS в репозитории; на нашем сайте применён такой:\n\n/index.css — корневой файл CSS, который импортирует все остальные при помощи @import.\n\n/styles/reset.css — первым делом импортируется сброс таблицы стилей.\n\n/styles/variables.css — все переменные CSS определены в отдельном файле, в том числе и система шрифтов.\n\n/styles/global.css — глобальные стили, применяемые для веб-страниц сайта.\n\n/components/example/example.css — все неглобальные стили относятся к конкретным компонентам и находятся в файле CSS, расположенном рядом с файлом JS компонента.\n\nОбласть видимости\nЧтобы избежать конфликта стилей между страницами и компонентами, по умолчанию у стилей должна быть локальная область видимости. В ванильной веб-разработке есть два основных механизма реализации этого.\n\n▍ Селекторы с префиксами\nВ случае пользовательских элементов, не имеющих shadow DOM, можно добавлять в стили префиксы с тегом пользовательского элемента. Например, вот простой веб-компонент, использующий селекторы с префиксами для создания локальной области видимости:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <link rel="stylesheet" href="index.css">\n</head>\n<body>\n    <x-example></x-example>\n    <p>This <p> is not affected, because it is outside the custom element.</p>\n    <script type="module" src="index.js"></script>\n</html>\nindex.js\n\nimport { registerExampleComponent } from \'./components/example/example.js\';\nconst app = () => {\n    registerExampleComponent();\n}\ndocument.addEventListener(\'DOMContentLoaded\', app);\nindex.css\n\n@import url("./components/example/example.css");\ncomponents/example/example.js\n\nclass ExampleComponent extends HTMLElement {\n    connectedCallback() {\n        this.innerHTML = \'<p>For example...</p>\';\n    }\n}\nexport const registerExampleComponent = () => {\n    customElements.define(\'x-example\', ExampleComponent);\n}\ncomponents/example/example.css\n\nx-example p {\n    font-family: casual, cursive;\n    color: darkblue;\n}\n\n▍ Подсказка: вложенность CSS\nЕсли вам нужен более чистый синтаксис и вас устраивает браузерная поддержка, то подумайте над использованием вложенности CSS.\n\ncomponents/example/example.css\n\nx-example {\n    p {\n        font-family: casual, cursive;\n        color: darkblue;\n    }\n}\n▍ Импорт Shadow DOM\nПользовательские элементы, использующие shadow DOM, изначально не стилизованы и имеют локальную область видимости, а все стили необходимо явным образом импортировать в них. Вот переработанный пример с префиксами для использования shadow DOM.\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<body>\n    <x-example>\n        <p>This <p> is not affected, even though it is slotted.</p>\n    </x-example>\n    <script type="module" src="index.js"></script>\n</body>\n</html>\nindex.js\n\nimport { registerExampleComponent } from \'./components/example/example.js\';\nconst app = () => {\n    registerExampleComponent();\n}\ndocument.addEventListener(\'DOMContentLoaded\', app);\ncomponents/example/example.js\n\nclass ExampleComponent extends HTMLElement {\n    constructor() {\n        super();\n        this.attachShadow({mode: \'open\'});\n        this.shadowRoot.innerHTML = `\n            <link rel="stylesheet" href="${import.meta.resolve(\'./example.css\')}">\n            <p>For example...</p>\n            <slot></slot>\n        `;\n    }\n}\nexport const registerExampleComponent = () => {\n    customElements.define(\'x-example\', ExampleComponent);\n}\ncomponents/example/example.css\n\np {\n    font-family: casual, cursive;\n    color: darkblue;\n}\n\nЧтобы использовать стили из окружающей страницы внутри shadow DOM, можно выбрать один из вариантов:\n\n\nОбщие файлы CSS можно импортировать внутрь shadow DOM при помощи тегов <link> или @import.\nНа переменные CSS, определённые на окружающей странице, можно ссылаться изнутри стилей shadow DOM.\nДля доминирования shadow DOM можно использовать псевдоэлемент ::part, чтобы раскрыть API для стилизации.\n\nЗамена модулей CSS\nЛокальную область видимости модулей CSS можно заменить одним из описанных выше способов изменения области видимости. Для образца возьмём каноничный пример модулей CSS из документации Next.JS:\n\napp/dashboard/layout.tsx\n\nimport styles from \'./styles.module.css\'\n \nexport default function DashboardLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return <section className={styles.dashboard}>{children}</section>\n}\napp/dashboard/styles.module.css\n.dashboard {\n    padding: 24px;\n}\nВ качестве ванильного веб-компонента он бы выглядел так:\n\ncomponents/dashboard/layout.js\n\nclass Layout extends HTMLElement {\n    constructor() {\n        super();\n        this.attachShadow({ mode: \'open\' });\n        this.shadowRoot.innerHTML = `\n            <link rel="stylesheet" href="${import.meta.resolve(\'styles.css\')}">\n            <section class="dashboard"><slot></slot></section>\n        `;\n    }\n}\n\nexport const registerLayoutComponent = \n    () => customElements.define(\'x-layout\', Layout);\ncomponents/dashboard/styles.css\n\n@import url("../shared.css");\n\n.dashboard {\n    padding: 24px;\n}\nТак как shadow DOM не наследует стили страницы, styles.css должен сначала импортировать стили, общие для страницы и «теневого» веб-компонента.\n\nЗамена PostCSS\nДавайте рассмотрим список возможностей на главной станице PostCSS.\n\nДобавление префиксов поставщика к правилам CSS с использованием значений из Can I Use — в большинстве сценариев использования префиксы поставщика больше не требуются. Показанный в примере псевдокласс :fullscreen теперь работает в браузерах без префиксов.\n\nПреобразование современного CSS в то, что может понимать большинство браузеров — современный CSS, который вы хотите использовать, скорее всего, уже поддерживается. Показанное в примере правило color: oklch() теперь работает во всех популярных браузерах.\n\nМодули CSS — см. альтернативы, описанные в предыдущем разделе. Организуйте согласованные форматы и избегайте ошибок в таблицах стилей при помощи stylelint. Можно добавить в Visual Studio Code расширение vscode-stylelint для выполнения того же линтинга во время разработки без необходимости встраивания его в этап сборки.\n\nПодведём итог: из-за отказа Microsoft от поддержки IE11 и постоянного совершенствования актуальных браузеров PostCSS по большей мере стал ненужным.\n\nЗамена SASS\nАналогично PostCSS, давайте разберём список основных возможностей SASS:\n\nПеременные — заменены пользовательскими свойствами CSS.\n\nВложенность — вложенность CSS недавно стала поддерживаться всеми популярными браузерами, что вполне может покрыть ваши потребности.\n\nМодули — можно аппроксимировать сочетанием @import, переменных CSS и описанных выше способов управления областями видимости.\n\nПримеси (mixin) — к сожалению, функция CSS-примесей, которая может заменить их, по-прежнему находится на этапе спецификации.\n\nОператоры — во многих случаях могут быть заменены встроенной функцией calc().\n\nПодведём итог: SASS намного мощнее, чем PostCSS, и хотя у многих его возможностей есть ванильные альтернативы, заменить его полностью не так легко. Вам самим решать, стоит ли увеличение сложности из-за препроцессора SASS его дополнительных возможностей.\n\nВанильные страницы\nДля веб-сайтов с большим количеством контента и низкой интерактивностью предпочтительна многостраничная структура.\n\nОтказавшись от использования фреймворков, мы должны будем писать эти HTML-страницы с нуля. При этом важно понимать, как должна выглядеть хорошая минимальная HTML-страница.\n\nexample.html\n\n<!doctype html>\n<html lang="en">\n    <head>\n        <title>Example</title>\n        <meta charset="utf-8">\n        <meta name="viewport" content="width=device-width" />\n        <link rel="stylesheet" href="index.css">\n    </head>\n    <body>\n        <noscript><strong><font color="#3AC1EF">Please enable JavaScript to view this page correctly.</font></strong></noscript>\n        <header>\n            title and navigation ...\n        </header>\n        <main>\n            main content ...\n        </main>\n        <footer>\n            byline and copyright ...\n        </footer>    \n        <script type="module" src="index.js"></script>\n    </body>\n</html>\nОбъяснение каждого элемента:\n\n<!doctype html> — требуется, чтобы HTML парсился как HTML5, а не как более старая версия.\n\n<html lang="en"> — атрибут lang рекомендован, чтобы язык страницы не определялся ошибочно.\n\n<head><title> — используется для вкладки браузера и сохранения в закладки; то есть, по сути, он обязателен.\n\n<head><meta charset="utf-8"> — это почти не требуется, но эту строку нужно добавить, чтобы страница точно интерпретировалась, как UTF-8. Очевидно, что в редакторе, используемом для создания этой страницы, тоже должна быть выбрана UTF-8.\n\n<head><meta name="viewport"> — необходимо для того, чтобы структура страницы удобно просматривалась на мобильных устройствах.\n\n<head><link rel="stylesheet" href="index.css"> — по стандарту таблица стилей загружается из <head> блокирующим образом, чтобы не возникала вспышка нестилизованного контента разметки страницы.\n\n<body><noscript> — так как веб-компоненты не работают JavaScript, обычно рекомендуется добавлять уведомление noscript для пользователей, у которых отключен JavaScript. Это уведомление должно присутствовать только на страницах с веб-компонентами. Если вы не хотите показывать ничего, кроме уведомления, то см. показанный ниже шаблонный паттерн.\n\n<body><header/main/footer> — разметка страницы должна быть упорядочена при помощи HTML-маркеров (landmark). При правильном использовании landmark помогают в разбиении страницы на логические блоки и обеспечении accessibility структуры страницы. Так как они созданы на основе стандартов, повышается вероятность их совместимости с уже существующими и новыми инструментами accessibility.\n\n<body><script type="module" src="index.js"> — основной файл JavaScript находится в конце, он загружает веб-компоненты.\n\nНа страницах, где содержимое должно отображаться только при включенном JavaScript, можно использовать следующий шаблонный паттерн:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n    <head>\n        <title>Example</title>\n        <meta charset="utf-8">\n        <meta name="viewport" content="width=device-width" />\n        <link rel="stylesheet" href="index.css">\n    </head>\n    <body>\n        <noscript><strong><font color="#3AC1EF">Please enable JavaScript to view this page.</font></strong></noscript>\n        <template id="page">\n            <header>\n                title and navigation ...\n            </header>\n            <main>\n                main content ...\n            </main>\n            <footer>\n                byline and copyright ...\n            </footer>    \n        </template>\n        <script type="module" src="index.js"></script>\n    </body>\n</html>\nindex.js\n\nconst app = () => {\n    const template = document.querySelector(\'template#page\');\n    if (template) document.body.appendChild(template.content, true);\n}\n\ndocument.addEventListener(\'DOMContentLoaded\', app);\n▍ Важность семантики\nВ разметке страницы по умолчанию должен использоваться семантический HTML для повышения accessibility и улучшения SEO. Веб-компоненты следует использовать только в тех случаях, когда сложность и степень взаимодействий превышает возможности стандартной HTML-разметки.\n\nОсвойте следующие аспекты семантического HTML:\n\nLandmark (маркеры) — как говорилось выше, landmark — это фундамент структуры страницы, по умолчанию обеспечивающие качественную структуру и accessibility.\n\nЭлементы — хорошее знание множества встроенных элементов HTML сэкономит вам время благодаря отсутствию необходимости пользовательских элементов и упрощению реализации в случае необходимости пользовательских элементов. При правильном использовании HTML-элементов они по умолчанию обеспечивают accessibility.\n\nФормы — при их полнофункциональном использовании встроенные формы HTML способны реализовывать множество сценариев применения интерактивности. Изучите такие их возможности, как разнообразные типы ввода, валидация на стороне клиента и псевдоклассы UI. Если вы не можете найти подходящего для себя типа ввода, то можете использовать связанные с формами пользовательские элементы, но учитывайте поддержку браузерами ElementInternals.\n\n▍ Фавиконки\nВероятно, вам захочется добавить в HTML элемент, не основанный на стандартах, а именно ссылку на фавиконку:\n\n\nЧтобы не усложнять, поместите favicon.ico в корень сайта и добавьте на неё ссылку в свой HTML: <link rel="icon" href="favicon.ico">\nМожете попробовать использовать фавиконки в SVG, но помните, что Safari их не поддерживает. Встройте тёмный режим в сам SVG фавиконки или для большего удобства воспользуйтесь генератором наподобие RealFaviconGenerator.\nУчтите, что поскольку фавиконки не основаны на опубликованных стандартах веба, будет довольно сложно полностью реализовать стандарт де-факто.\n\nПроект\nРекомендуемая структура проекта для ванильного многостраничного веб-сайта такова:\n\n/ — в корне проекта находятся файлы, которые не будут публиковаться, например, README.md, LICENSE и .gitignore.\n\n/public — папка public публикуется в неизменном виде, без этапов сборки. В ней заключается весь веб-сайт.\n\n/public/index.html — главная лендинг-страница веб-сайта, не особо отличающаяся от других страниц, за исключением пути.\n\n/public/index.[js/css] — основная таблица стилей и javascript. Они содержат общие для всех страниц стили и код.\n\nindex.js загружает и регистрирует веб-компоненты, используемые на всех страницах. Если сделать его общим для нескольких HTML-страниц, то можно избежать ненужного дублирования и рассогласованности между страницами.\n\n/public/pages/[имя].html — все прочие страницы сайта, каждая из которых включает в себя одинаковые index.js и index.css и, разумеется, содержит непосредственно контент в виде разметки HTML с использованием веб-компонентов.\n\npublic/components/[name]/ — по одной папке на каждый веб-компонент, содержащей файлы [имя].js и [имя].css. Файл .js импортируется в файл index.js для регистрации веб-компонента. Файл .css, как говорилось выше, импортируется в глобальный index.css или в shadow DOM.\n\n/public/lib/ — для всех внешних библиотек, используемых как зависимости. Ниже мы расскажем о том, как добавлять и использовать эти зависимости.\n\n/public/styles/ — глобальные стили, на которые ссылается index.css.\n\nФайлы конфигурации для повышения удобства работы в редакторах программиста тоже размещаются в корне проекта. Благодаря расширениям редактора основная часть процесса разработки возможна без этапа сборки. Пример см. в статье о настройке Visual Studio Code.\n\nМаршрутизация\n«Олдскульный» способ маршрутизации стандартных HTML-страниц и связующих их тегов <a> обладает следующими преимуществами: простое индексирование поисковыми движками и изначальная полная поддержка функциональности истории браузера и закладок.\n\nЗависимости\nВ процессе разработки вам могут потребоваться сторонние библиотеки. Их можно использовать без npm и бандлера.\n\nUnpkg\nЧтобы использовать библиотеки без бандлера, их предварительно нужно собрать в формат ESM или UMD. Такие библиотеки можно скачать с unpkg.com:\n\n\nЗайдите на unpkg.com/[library]/ (последняя косая черта важна), например, на unpkg.com/microlight/\nНайдите и скачайте файл библиотеки js, который может находиться в подпапке, например, в dist, esm или umd\nПоместите файл библиотеки в папку lib/\n\nИли же библиотеку можно загрузить напрямую из CDN.\n\n▍ UMD\nФормат модулей UMD — это старый формат для библиотек, загружаемых из тега script; он обладает самой широкой поддержкой, особенно среди старых библиотек. Его можно распознать по наличию typeof define === \'function\' && define.amd в JS библиотеки.\n\nЧтобы включить его в свой проект, нужно выполнить следующие действия:\n\n\nВключить его в теге script: <script src="lib/microlight.js"></script>\nПолучить его у окна: const { microlight } = window;\n\n▍ ESM\nФормат модулей ESM (также называемый модулями JavaScript) — это формат, определённый стандартом ECMAScript; у новых и популярных библиотек обычно есть ESM-сборка. Её можно распознать по использованию ключевого слова export.\n\nЧтобы включить его в свой проект, нужно выполнить следующие действия:\n\n\nЗагрузить его из CDN:\n\nimport(\'https://unpkg.com/web-vitals@4.2.2/dist/web-vitals.js\').then((webVitals) => ...)\nИли загрузить из локальной копии:\n\nimport webVitals from \'lib/web-vitals.js\'\n\n▍ imports.js\nДля удобного упорядочивания библиотек и отделения их от остальной кодовой базы их можно загружать и экспортировать из файла imports.js.\n\nНапример, вот страница, на которой используется UMD-сборка Day.js и ESM-сборка web-vitals:\n\n\nРендеринг текста выполнен компонентом <x-metrics>:\n\ncomponents/metrics.js\n\nimport { dayjs, webVitals } from \'../lib/imports.js\';\n\nclass MetricsComponent extends HTMLElement {\n    #now = dayjs();\n    #ttfb;\n    #interval;\n\n    connectedCallback() {\n        webVitals.onTTFB(_ => this.#ttfb = Math.round(_.value));\n        this.#interval = setInterval(() => this.update(), 500);\n    }\n\n    disconnectedCallback() {\n        clearInterval(this.#interval);\n        this.#interval = null;\n    }\n\n    update() {\n        this.innerHTML = `\n            <p>Page loaded ${this.#now.fromNow()}, TTFB ${this.#ttfb} milliseconds</p>\n        `;\n    }\n}\n\nexport const registerMetricsComponent = () => {\n    customElements.define(\'x-metrics\', MetricsComponent);\n}\nВ папке /lib находятся следующие файлы:\n\n\nweb-vitals.js — ESM-сборка web-vitals\ndayjs/\n\ndayjs.min.js — UMD-сборка Day.js\nrelativeTime.js — UMD-сборка этого плагина Day.js\n\nimports.js\n\nИзучив глубже последний файл, мы увидим, как он выполняет загрузку сторонних зависимостей:\n\nlib/imports.js\n\n// UMD-версия dayjs с https://unpkg.com/dayjs/\nconst dayjs = window.dayjs;\nconst dayjsRelativeTime = window.dayjs_plugin_relativeTime;\ndayjs.extend(dayjsRelativeTime);\n\n// ESM-версия web-vitals с https://unpkg.com/web-vitals/dist/web-vitals.js\nimport * as webVitals from \'./web-vitals.js\';\n\nexport { dayjs, webVitals };\nОн импортирует ESM-библиотеку напрямую, но подтягивает UMD-библиотеки из объекта Window. Они загружаются в HTML.\n\nВот объединённый пример:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <link rel="stylesheet" href="index.css">\n</head>\n<body>\n    <script src="./lib/dayjs/dayjs.min.js"></script>\n    <script src="./lib/dayjs/relativeTime.js"></script>\n\n    <script type="module" src="index.js"></script>\n    <x-metrics></x-metrics>\n</body>\n</html>\nindex.css\n\nbody { font-family: sans-serif; }\nindex.js\nimport { registerMetricsComponent } from \'./components/metrics.js\';\n\nconst app = () => {\n    registerMetricsComponent();\n};\n\ndocument.addEventListener(\'DOMContentLoaded\', app);\ncomponents/metrics.js\nimport { dayjs, webVitals } from \'../lib/imports.js\';\n\nclass MetricsComponent extends HTMLElement {\n    #now = dayjs();\n    #ttfb;\n    #interval;\n\n    connectedCallback() {\n        webVitals.onTTFB(_ => this.#ttfb = Math.round(_.value));\n        this.#interval = setInterval(() => this.update(), 500);\n    }\n\n    disconnectedCallback() {\n        clearInterval(this.#interval);\n        this.#interval = null;\n    }\n\n    update() {\n        this.innerHTML = `\n            <p>Page loaded ${this.#now.fromNow()}, TTFB ${this.#ttfb} milliseconds</p>\n        `;\n    }\n}\n\nexport const registerMetricsComponent = () => {\n    customElements.define(\'x-metrics\', MetricsComponent);\n}\nlib/imports.js\n\n// UMD-версия dayjs с https://unpkg.com/dayjs/\nconst dayjs = window.dayjs;\nconst dayjsRelativeTime = window.dayjs_plugin_relativeTime;\ndayjs.extend(dayjsRelativeTime);\n\n// ESM-версия web-vitals с https://unpkg.com/web-vitals/dist/web-vitals.js\nimport * as webVitals from \'./web-vitals.js\';\n\nexport { dayjs, webVitals };\nК сожалению, не у всех библиотек есть UMD- или ESM-сборки, но их становится всё больше.\n\n▍ Import Map\nАльтернативой способу с imports.js могут стать import map. Они определяют уникальное отображение между именем модуля, который можно импортировать, и соответствующим файлом библиотеки в особом теге script в head HTML. Они позволяют использовать в остальной части кодовой базы более традиционный синтаксис импорта на основе модулей.\n\nВот, как будет выглядеть предыдущий пример, адаптированный под использование import map:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <link rel="stylesheet" href="index.css">\n    <script src="./lib/dayjs/dayjs.min.js"></script>\n    <script src="./lib/dayjs/relativeTime.js"></script>\n    <script type="importmap">\n        {\n            "imports": {\n                "dayjs": "./lib/dayjs/module.js",\n                "web-vitals": "./lib/web-vitals.js"\n            }\n        }\n    </script>\n</head>\n<body>\n    <script type="module" src="index.js"></script>\n    <x-metrics></x-metrics>\n</body>\n</html>\nlib/dayjs/module.js\n\n// UMD-версия dayjs с https://unpkg.com/dayjs/\nconst dayjs = window.dayjs;\nconst dayjsRelativeTime = window.dayjs_plugin_relativeTime;\ndayjs.extend(dayjsRelativeTime);\n\nexport default dayjs;\ncomponents/metrics.js\n\nimport dayjs from \'dayjs\';\nimport * as webVitals from \'web-vitals\';\n\nclass MetricsComponent extends HTMLElement {\n    #now = dayjs();\n    #ttfb;\n    #interval;\n\n    connectedCallback() {\n        webVitals.onTTFB(_ => this.#ttfb = Math.round(_.value));\n        this.#interval = setInterval(() => this.update(), 500);\n    }\n\n    disconnectedCallback() {\n        clearInterval(this.#interval);\n        this.#interval = null;\n    }\n\n    update() {\n        this.innerHTML = `\n            <p>Page loaded ${this.#now.fromNow()}, TTFB ${this.#ttfb} milliseconds</p>\n        `;\n    }\n}\n\nexport const registerMetricsComponent = () => {\n    customElements.define(\'x-metrics\', MetricsComponent);\n}\nПри использовании import map нужно учитывать следующие аспекты:\n\n\nImport map могут отображаться только на ESM-модули, поэтому для библиотек UMD необходимы обёртки, как в случае с обёрткой module.js для dayjs в этом примере.\nВнешние import map вида <script type="importmap" src="importmap.json"> пока поддерживаются не всеми браузерами. Из-за этого import map должны дублироваться на каждой HTML-странице.\nImport map должна определяться до загрузки скрипта index.js, предпочтительно из раздела &lthead>.\nImport map можно использовать для более простой загрузки библиотек из папки node_modules или из CDN. Можно использовать JSPM generator для быстрого создания import map для зависимостей for CDN. Однако при этом стоит иметь в виду, что из-за добавления таких внешних зависимостей ванильная кодовая база будет зависеть от постоянной доступности соответствующего сервиса.\n\nБраузерная поддержка\nВанильные веб-сайты поддерживаются всеми современными браузерами. Но что это значит?\n\n\nВесь наш сайт работает в текущих версиях Safari, Chrome, Edge и Firefox.\nВесь наш сайт имеет уровень поддержки 95% или выше на caniuse.com, за исключением Import Map (92%), декларативных Shadow DOM (89%) и вложенности CSS (88%), но вскоре их поддержка расширится.\nВ свою очередь, это означает, что можно без проблем использовать HTTP/2, семантические элементы HTML5, пользовательские элементы, шаблоны, Shadow DOM, MutationObserver, CustomEvent, FormData и API Element.closest.\nТакже можно гарантированно использовать модули JavaScript, ECMAScript 6 / 2015, ECMAScript 8 / 2017 и ECMAScript 11 / 2020.\nВ CSS можно гарантированно использовать @import, переменные, calc(), flexbox, grid, display: contents и многое другое.\n\nЧтобы следить за новыми веб-стандартами, изучайте следующие проекты:\n\n\nBaseline отслеживает фичи, широко доступные в браузерах, а также сообщает, когда их безопасно использовать.\nInterop — это ежегодная инициатива разработчиков браузеров по внедрению новых фич веб-платформы во все браузеры. Можно считать её предварительным обзором того, что вскоре войдёт в baseline.\n\nРазвёртывание\nДля развёртывания сайта можно выбрать любого провайдера, способного хостить статические веб-сайты.\n\nНа примере GitHub Pages:\n\n\nЗагрузите проект как репозиторий на GitHub\nПерейдите в Settings, Pages\nSource: GitHub Actions\nStatic Website, Configure\nПерейдите к path и измените его на ./public\nВыполните коммит изменений...\nЗайдите на страницу Actions репозитория и дождитесь развёртывания сайта\n\nТестирование\nВсе популярные фреймворки тестирования предназначены для работы в конвейерах сборки.\nОднако у ванильного веб-сайта нет этапа сборки. Для тестирования веб-компонентов можно применить старомодный подход: тестирование в браузере при помощи фреймворка Mocha.\n\nНапример, вот юнит-тесты для компонента <x-tab-panel>, использованного для отображения вкладок панелей исходного кода на нашем веб-сайте:\n\n\nА для того, чтобы ещё глубже разобраться в коде, покажу, как выглядит тестирование исходного кода:\n\ntests/index.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <title>Plain Vanilla - Tests</title>\n    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />\n    <link rel="icon" href="../favicon.ico">\n    <link rel="stylesheet" href="../index.css">\n    <!-- https://unpkg.com/mocha@9.2.2/mocha.css -->\n    <link rel="stylesheet" href="./lib/mocha/mocha.css" />\n    <!-- https://unpkg.com/chai@4.3.6/chai.js -->\n    <script src="./lib/mocha/chai.js"></script>\n    <!-- https://unpkg.com/mocha@9.2.2/mocha.js -->\n    <script src="./lib/mocha/mocha.js"></script>\n    <!-- https://unpkg.com/@testing-library/dom@8.17.1/dist/@testing-library/dom.umd.js -->\n    <script src="./lib/@testing-library/dom.umd.js"></script>\n</head>\n<body>\n    <div id="mocha"></div>\n\n    <script type="module" class="mocha-init">\n        mocha.setup(\'bdd\');\n        mocha.checkLeaks();\n    </script>\n\n    <script type="module" src="./tabpanel.test.js"></script>\n    \n    <!-- здесь другие тесты -->\n\n    <script type="module" class="mocha-exec" src="./index.js"></script>\n</body>\n</html>\ntests/index.js\n\nimport { registerTabPanelComponent } from "../components/tab-panel/tab-panel.js";\n\nconst app = () => {\n    registerTabPanelComponent();\n    mocha.run();\n}\n\ndocument.addEventListener(\'DOMContentLoaded\', app);\ntests/tabpanel.test.js\n\nimport { render, screen, waitFor, expect, fireEvent } from \'./imports-test.js\';\n\nconst renderTabPanel = () => {\n    const div = document.createElement(\'div\');\n    div.innerHTML = `\n        <x-tab-panel>\n            <x-tab title="Tab 1" active>\n                <p>Tab 1 content</p> \n            </x-tab>\n            <x-tab title="Tab 2">\n                <p>Tab 2 content</p>\n            </x-tab>\n        </x-tab-panel>\n    `;\n    render(div);\n}\n\ndescribe(\'tabpanel\', () => {\n    it("renders a tabpanel with active tab", async () => {\n        // ARRANGE\n        renderTabPanel();\n    \n        // ASSERT\n        // выбрана активная вкладка\n        const activeTab = await screen.findByRole(\'tab\', { name: \'Tab 1\', selected: true });\n        expect(activeTab).to.not.be.undefined;\n        // активная tabpanel видима\n        const activePanel = screen.getByText(/Tab 1 content/);\n        expect(activePanel).to.not.be.undefined;\n        // контент неактивной tabpanel скрыт\n        const tab2 = screen.getByTitle(\'Tab 2\');\n        await waitFor(() => expect(tab2.offsetParent).to.be.null);\n    });\n    \n    it("activates a different tab on click", async () => {\n        // ARRANGE\n        renderTabPanel();\n        const tab2 = screen.getByTitle(\'Tab 2\');\n    \n        // ASSERT\n        // контент неактивной tabpanel скрыт\n        await waitFor(() => expect(tab2.offsetParent).to.be.null);\n        // находим кнопку неактивной вкладки и нажимаем на неё\n        const tab2Button = await screen.findByRole(\'tab\', { name: \'Tab 2\' });\n        expect(tab2Button).not.to.be.undefined;\n        fireEvent.click(tab2Button);\n        // делаем видимым контент неактивной tabpanel\n        await waitFor(() => expect(tab2.offsetParent).not.to.be.null);\n    });\n});\ntests/imports-test.js\n\nconst { expect } = window.chai;\nconst { getByText, queries, within, waitFor, fireEvent } = window.TestingLibraryDom;\n\nlet rootContainer;\nlet screen;\n\nbeforeEach(() => {\n    // скрытый div, в который тест может рендерить элементы\n    rootContainer = document.createElement("div");\n    rootContainer.style.position = \'absolute\';\n    rootContainer.style.left = \'-10000px\';\n    document.body.appendChild(rootContainer);\n    // предварительная привязка вспомогательных @testing-library/dom к rootContainer\n    screen = Object.keys(queries).reduce((helpers, key) => {\n        const fn = queries[key]\n        helpers[key] = fn.bind(null, rootContainer)\n        return helpers\n    }, {});\n});\n\nafterEach(() => {\n    document.body.removeChild(rootContainer);\n    rootContainer = null;\n});\n\nfunction render(el) {\n    rootContainer.appendChild(el);\n}\n\nexport { \n    rootContainer, \n    expect, \n    render, \n    getByText, screen, within, waitFor, fireEvent\n};\nПримечания по работе с таким подходом:\n\n\nВесь код для юнит-тестов, в том числе и библиотеки тестирования, выделен в подпапку public/tests/. Поэтому тесты будут доступны интерактивно, если добавить /tests к URL развёрнутого сайта. Если вы не хотите развёртывать тесты на работающем веб-сайте, то исключите папку тестов на этапе развёртывания.\nВ качестве фреймворков тестирования и проверки применяются Mocha и Chai, потому что они работают в браузере без этапа сборки.\nДля более удобных запросов к DOM используется DOM Testing Library. Файл imports-test.js конфигурирует её для ванильного использования.\nВажное ограничение заключается в том, что DOM Testing Library не может выполнять запросы внутри корней shadow. Чтобы выполнять тестирование внутри корней shadow, необходимо сначала выполнить запрос к содержащему их веб-компоненту, получить дескриптор его свойства shadowRoot, а затем выполнить запрос внутри него.\nВеб-компоненты инициализируются асинхронным образом, поэтому тестировать их может быть непросто. Используйте методы async DOM Testing Library.\n\nПример\nПримером разработки может быть наш веб-сайт. Его проект есть на GitHub.\n\nTelegram-канал со скидками, розыгрышами призов и новостями IT 💻',), kwargs={}
Результат: 
это вторая статья из цикла переводов о вебразработке на чистых ванильных технологиях  без фреймворков и сторонних инструментов только html css и javascript в первой части мы обсудили почему такой подход может быть разумной альтернативой современным фреймворкам и рассмотрели использование вебкомпонентов в качестве базовых строительных блоков для создания более сложных примитивов в этот раз поговорим про стилизацию а также деплой компонентов в продакшен без использования сборщиков фреймворков или серверной логики

современный css
современные вебприложения построены на основе богатого инструментария работы с css связанного со множеством пакетов npm и этапов сборки ванильное же вебприложение может выбрать более легковесный путь отказавшись от современных методик с предварительно обработанным css и выбрав нативные для браузеров стратегии

сброс
сброс стилей до общего для всех браузеров среднего  стандартная практика в вебразработке и ванильные вебприложения в этом ничем не отличаются

минимальный сброс используется следующим сайтом

resetcss

 обобщённый минималистичный сброс css
   источник вдохновения httpswwwdigitaloceancomcommunitytutorialscssminimalcssreset 

root 
    boxsizing borderbox
    lineheight 14
     httpskilianvalkhofcom2022csshtmlyourcssresetneedstextsizeadjustprobably 
    moztextsizeadjust none
    webkittextsizeadjust none
    textsizeadjust none


 before after 
    boxsizing inherit


body h1 h2 h3 h4 h5 h6 p 
    margin 0
    padding 0
    fontweight normal


img 
    maxwidth100
    heightauto

вот другие варианты в порядке по возрастанию сложности

modernnormalize  более подробное решение для сброса css в современных браузерах включение из cdn

kraken  начальная точка для проектов фронтенда включает в себя сброс css типографику сетку и другие удобные инструменты включение из cdn

pico css  готовый набор начинающего для стилизации семантического html в том числе и для сброса css включение из cdn

tailwind  если вы всё равно будете использовать tailwind то можете и использовать его сброс css включение из cdn

шрифты
типографика  фундамент вебсайта или приложения такой легковесный подход как ванильная вебразработка должен согласоваться с легковесным подходом к типографике

в modern font stacks описываются разнообразные популярные шрифты и варианты отката позволяющие не загружать пользовательские шрифты и не добавлять внешние зависимости

на нашем сайте используется стек geometric humanist для обычного текста и стек monospace code для исходного кода

инструментарий
в реальном вебпроекте в случае отсутствия правильной структуры объём css быстро становится огромным давайте рассмотрим инструментарий для создания такой структуры который предоставляет нам css в современных браузерах

import  самая базовая техника структурирования  это разбиение css на несколько файлов мы можем добавлять все эти файлы по порядку как теги link в indexhtml но это быстро становится неудобным если мы работаем с несколькими htmlстраницами вместо этого лучше импортировать их в indexcss

например вот основной файл css нашего сайта

indexcss

import urlstylesresetcss
import urlstylesvariablescss
import urlstylesglobalcss
import urlcomponentscodeviewercodeviewercss
import urlcomponentstabpaneltabpanelcss
ниже показан рекомендованный способ упорядочивания файлов css

пользовательские свойства переменные  переменные css можно использовать для централизованного определения шрифта и темы сайта

например вот переменные для нашего сайта

variablescss

root 
     httpsmodernfontstackscom
       geometric humanist font 
    fontsystem avenir montserrat corbel sourcesanspro sansserif
     monospace code font 
    fontsystemcode uimonospace cascadia code source code pro menlo consolas dejavu sans mono monospace
    fontsystemcodesize 08rem

    backgroundcolor white

    textcolor black
    textcolormute hsl0 0 40

    linkcolor darkblue

    navseparatorcolor goldenrod
    navbackgroundcolor hsl50 50 95

    bordercolor black

    codetextcolor vartextcolor
    codetextcolorbg inherit

    paneltitlecolor black
    paneltitlecolorbg cornsilk

ещё более мощными переменные css становятся в сочетании с calc

пользовательские элементы  область видимости стилей легко можно ограничить тегом пользовательского элемента например все стили компонента аватара из предыдущей части статьи имеют в качестве префикса селектор xavatar

avatarcss

xavatar 
    display flex
    alignitems center
    justifycontent center
    width 25rem
    height 25rem


xavatarsizelg 
    width 35rem
    height 35rem


xavatar img 
    borderradius 9999px
    width 100
    height 100
    verticalalign middle
    objectfit cover

пользовательские элементы также могут иметь произвольные атрибуты которые могут использоваться селекторами как в случае со стилем sizelg из этого примера

shadow dom  добавление shadow dom к вебкомпоненту ещё сильнее изолирует его стили от остальной части страницы например компонент xheader из предыдущей части стилизует свой элемент h1 внутри своего css не влияя на содержащую его страницу и на дочерние элементы заголовка

все файлы css которые нужно применить к shadow dom должны загружаться в неё явным образом однако переменные css передаются в shadow dom

ограничение shadow dom заключается в том что для использования внутри них пользовательских шрифтов их сначала нужно загрузить в светлую dom

файлы
существует множество способов упорядочивания файлов css в репозитории на нашем сайте применён такой

indexcss  корневой файл css который импортирует все остальные при помощи import

stylesresetcss  первым делом импортируется сброс таблицы стилей

stylesvariablescss  все переменные css определены в отдельном файле в том числе и система шрифтов

stylesglobalcss  глобальные стили применяемые для вебстраниц сайта

componentsexampleexamplecss  все неглобальные стили относятся к конкретным компонентам и находятся в файле css расположенном рядом с файлом js компонента

область видимости
чтобы избежать конфликта стилей между страницами и компонентами по умолчанию у стилей должна быть локальная область видимости в ванильной вебразработке есть два основных механизма реализации этого

 селекторы с префиксами
в случае пользовательских элементов не имеющих shadow dom можно добавлять в стили префиксы с тегом пользовательского элемента например вот простой вебкомпонент использующий селекторы с префиксами для создания локальной области видимости

indexhtml

doctype html
html langen
head
    link relstylesheet hrefindexcss
head
body
    xexamplexexample
    pthis p is not affected because it is outside the custom elementp
    script typemodule srcindexjsscript
html
indexjs

import  registerexamplecomponent  from componentsexampleexamplejs
const app    
    registerexamplecomponent

documentaddeventlistenerdomcontentloaded app
indexcss

import urlcomponentsexampleexamplecss
componentsexampleexamplejs

class examplecomponent extends htmlelement 
    connectedcallback 
        thisinnerhtml  pfor examplep
    

export const registerexamplecomponent    
    customelementsdefinexexample examplecomponent

componentsexampleexamplecss

xexample p 
    fontfamily casual cursive
    color darkblue


 подсказка вложенность css
если вам нужен более чистый синтаксис и вас устраивает браузерная поддержка то подумайте над использованием вложенности css

componentsexampleexamplecss

xexample 
    p 
        fontfamily casual cursive
        color darkblue
    

 импорт shadow dom
пользовательские элементы использующие shadow dom изначально не стилизованы и имеют локальную область видимости а все стили необходимо явным образом импортировать в них вот переработанный пример с префиксами для использования shadow dom

indexhtml

doctype html
html langen
body
    xexample
        pthis p is not affected even though it is slottedp
    xexample
    script typemodule srcindexjsscript
body
html
indexjs

import  registerexamplecomponent  from componentsexampleexamplejs
const app    
    registerexamplecomponent

documentaddeventlistenerdomcontentloaded app
componentsexampleexamplejs

class examplecomponent extends htmlelement 
    constructor 
        super
        thisattachshadowmode open
        thisshadowrootinnerhtml  
            link relstylesheet hrefimportmetaresolveexamplecss
            pfor examplep
            slotslot
        
    

export const registerexamplecomponent    
    customelementsdefinexexample examplecomponent

componentsexampleexamplecss

p 
    fontfamily casual cursive
    color darkblue


чтобы использовать стили из окружающей страницы внутри shadow dom можно выбрать один из вариантов


общие файлы css можно импортировать внутрь shadow dom при помощи тегов link или import
на переменные css определённые на окружающей странице можно ссылаться изнутри стилей shadow dom
для доминирования shadow dom можно использовать псевдоэлемент part чтобы раскрыть api для стилизации

замена модулей css
локальную область видимости модулей css можно заменить одним из описанных выше способов изменения области видимости для образца возьмём каноничный пример модулей css из документации nextjs

appdashboardlayouttsx

import styles from stylesmodulecss
 
export default function dashboardlayout
  children
 
  children reactreactnode
 
  return section classnamestylesdashboardchildrensection

appdashboardstylesmodulecss
dashboard 
    padding 24px

в качестве ванильного вебкомпонента он бы выглядел так

componentsdashboardlayoutjs

class layout extends htmlelement 
    constructor 
        super
        thisattachshadow mode open 
        thisshadowrootinnerhtml  
            link relstylesheet hrefimportmetaresolvestylescss
            section classdashboardslotslotsection
        
    


export const registerlayoutcomponent  
      customelementsdefinexlayout layout
componentsdashboardstylescss

import urlsharedcss

dashboard 
    padding 24px

так как shadow dom не наследует стили страницы stylescss должен сначала импортировать стили общие для страницы и теневого вебкомпонента

замена postcss
давайте рассмотрим список возможностей на главной станице postcss

добавление префиксов поставщика к правилам css с использованием значений из can i use  в большинстве сценариев использования префиксы поставщика больше не требуются показанный в примере псевдокласс fullscreen теперь работает в браузерах без префиксов

преобразование современного css в то что может понимать большинство браузеров  современный css который вы хотите использовать скорее всего уже поддерживается показанное в примере правило color oklch теперь работает во всех популярных браузерах

модули css  см альтернативы описанные в предыдущем разделе организуйте согласованные форматы и избегайте ошибок в таблицах стилей при помощи stylelint можно добавить в visual studio code расширение vscodestylelint для выполнения того же линтинга во время разработки без необходимости встраивания его в этап сборки

подведём итог изза отказа microsoft от поддержки ie11 и постоянного совершенствования актуальных браузеров postcss по большей мере стал ненужным

замена sass
аналогично postcss давайте разберём список основных возможностей sass

переменные  заменены пользовательскими свойствами css

вложенность  вложенность css недавно стала поддерживаться всеми популярными браузерами что вполне может покрыть ваши потребности

модули  можно аппроксимировать сочетанием import переменных css и описанных выше способов управления областями видимости

примеси mixin  к сожалению функция cssпримесей которая может заменить их попрежнему находится на этапе спецификации

операторы  во многих случаях могут быть заменены встроенной функцией calc

подведём итог sass намного мощнее чем postcss и хотя у многих его возможностей есть ванильные альтернативы заменить его полностью не так легко вам самим решать стоит ли увеличение сложности изза препроцессора sass его дополнительных возможностей

ванильные страницы
для вебсайтов с большим количеством контента и низкой интерактивностью предпочтительна многостраничная структура

отказавшись от использования фреймворков мы должны будем писать эти htmlстраницы с нуля при этом важно понимать как должна выглядеть хорошая минимальная htmlстраница

examplehtml

doctype html
html langen
    head
        titleexampletitle
        meta charsetutf8
        meta nameviewport contentwidthdevicewidth 
        link relstylesheet hrefindexcss
    head
    body
        noscriptstrongfont color3ac1efplease enable javascript to view this page correctlyfontstrongnoscript
        header
            title and navigation 
        header
        main
            main content 
        main
        footer
            byline and copyright 
        footer    
        script typemodule srcindexjsscript
    body
html
объяснение каждого элемента

doctype html  требуется чтобы html парсился как html5 а не как более старая версия

html langen  атрибут lang рекомендован чтобы язык страницы не определялся ошибочно

headtitle  используется для вкладки браузера и сохранения в закладки то есть по сути он обязателен

headmeta charsetutf8  это почти не требуется но эту строку нужно добавить чтобы страница точно интерпретировалась как utf8 очевидно что в редакторе используемом для создания этой страницы тоже должна быть выбрана utf8

headmeta nameviewport  необходимо для того чтобы структура страницы удобно просматривалась на мобильных устройствах

headlink relstylesheet hrefindexcss  по стандарту таблица стилей загружается из head блокирующим образом чтобы не возникала вспышка нестилизованного контента разметки страницы

bodynoscript  так как вебкомпоненты не работают javascript обычно рекомендуется добавлять уведомление noscript для пользователей у которых отключен javascript это уведомление должно присутствовать только на страницах с вебкомпонентами если вы не хотите показывать ничего кроме уведомления то см показанный ниже шаблонный паттерн

bodyheadermainfooter  разметка страницы должна быть упорядочена при помощи htmlмаркеров landmark при правильном использовании landmark помогают в разбиении страницы на логические блоки и обеспечении accessibility структуры страницы так как они созданы на основе стандартов повышается вероятность их совместимости с уже существующими и новыми инструментами accessibility

bodyscript typemodule srcindexjs  основной файл javascript находится в конце он загружает вебкомпоненты

на страницах где содержимое должно отображаться только при включенном javascript можно использовать следующий шаблонный паттерн

indexhtml

doctype html
html langen
    head
        titleexampletitle
        meta charsetutf8
        meta nameviewport contentwidthdevicewidth 
        link relstylesheet hrefindexcss
    head
    body
        noscriptstrongfont color3ac1efplease enable javascript to view this pagefontstrongnoscript
        template idpage
            header
                title and navigation 
            header
            main
                main content 
            main
            footer
                byline and copyright 
            footer    
        template
        script typemodule srcindexjsscript
    body
html
indexjs

const app    
    const template  documentqueryselectortemplatepage
    if template documentbodyappendchildtemplatecontent true


documentaddeventlistenerdomcontentloaded app
 важность семантики
в разметке страницы по умолчанию должен использоваться семантический html для повышения accessibility и улучшения seo вебкомпоненты следует использовать только в тех случаях когда сложность и степень взаимодействий превышает возможности стандартной htmlразметки

освойте следующие аспекты семантического html

landmark маркеры  как говорилось выше landmark  это фундамент структуры страницы по умолчанию обеспечивающие качественную структуру и accessibility

элементы  хорошее знание множества встроенных элементов html сэкономит вам время благодаря отсутствию необходимости пользовательских элементов и упрощению реализации в случае необходимости пользовательских элементов при правильном использовании htmlэлементов они по умолчанию обеспечивают accessibility

формы  при их полнофункциональном использовании встроенные формы html способны реализовывать множество сценариев применения интерактивности изучите такие их возможности как разнообразные типы ввода валидация на стороне клиента и псевдоклассы ui если вы не можете найти подходящего для себя типа ввода то можете использовать связанные с формами пользовательские элементы но учитывайте поддержку браузерами elementinternals

 фавиконки
вероятно вам захочется добавить в html элемент не основанный на стандартах а именно ссылку на фавиконку


чтобы не усложнять поместите faviconico в корень сайта и добавьте на неё ссылку в свой html link relicon hreffaviconico
можете попробовать использовать фавиконки в svg но помните что safari их не поддерживает встройте тёмный режим в сам svg фавиконки или для большего удобства воспользуйтесь генератором наподобие realfavicongenerator
учтите что поскольку фавиконки не основаны на опубликованных стандартах веба будет довольно сложно полностью реализовать стандарт дефакто

проект
рекомендуемая структура проекта для ванильного многостраничного вебсайта такова

  в корне проекта находятся файлы которые не будут публиковаться например readmemd license и gitignore

public  папка public публикуется в неизменном виде без этапов сборки в ней заключается весь вебсайт

publicindexhtml  главная лендингстраница вебсайта не особо отличающаяся от других страниц за исключением пути

publicindexjscss  основная таблица стилей и javascript они содержат общие для всех страниц стили и код

indexjs загружает и регистрирует вебкомпоненты используемые на всех страницах если сделать его общим для нескольких htmlстраниц то можно избежать ненужного дублирования и рассогласованности между страницами

publicpagesимяhtml  все прочие страницы сайта каждая из которых включает в себя одинаковые indexjs и indexcss и разумеется содержит непосредственно контент в виде разметки html с использованием вебкомпонентов

publiccomponentsname  по одной папке на каждый вебкомпонент содержащей файлы имяjs и имяcss файл js импортируется в файл indexjs для регистрации вебкомпонента файл css как говорилось выше импортируется в глобальный indexcss или в shadow dom

publiclib  для всех внешних библиотек используемых как зависимости ниже мы расскажем о том как добавлять и использовать эти зависимости

publicstyles  глобальные стили на которые ссылается indexcss

файлы конфигурации для повышения удобства работы в редакторах программиста тоже размещаются в корне проекта благодаря расширениям редактора основная часть процесса разработки возможна без этапа сборки пример см в статье о настройке visual studio code

маршрутизация
олдскульный способ маршрутизации стандартных htmlстраниц и связующих их тегов a обладает следующими преимуществами простое индексирование поисковыми движками и изначальная полная поддержка функциональности истории браузера и закладок

зависимости
в процессе разработки вам могут потребоваться сторонние библиотеки их можно использовать без npm и бандлера

unpkg
чтобы использовать библиотеки без бандлера их предварительно нужно собрать в формат esm или umd такие библиотеки можно скачать с unpkgcom


зайдите на unpkgcomlibrary последняя косая черта важна например на unpkgcommicrolight
найдите и скачайте файл библиотеки js который может находиться в подпапке например в dist esm или umd
поместите файл библиотеки в папку lib

или же библиотеку можно загрузить напрямую из cdn

 umd
формат модулей umd  это старый формат для библиотек загружаемых из тега script он обладает самой широкой поддержкой особенно среди старых библиотек его можно распознать по наличию typeof define  function  defineamd в js библиотеки

чтобы включить его в свой проект нужно выполнить следующие действия


включить его в теге script script srclibmicrolightjsscript
получить его у окна const  microlight   window

 esm
формат модулей esm также называемый модулями javascript  это формат определённый стандартом ecmascript у новых и популярных библиотек обычно есть esmсборка её можно распознать по использованию ключевого слова export

чтобы включить его в свой проект нужно выполнить следующие действия


загрузить его из cdn

importhttpsunpkgcomwebvitals422distwebvitalsjsthenwebvitals  
или загрузить из локальной копии

import webvitals from libwebvitalsjs

 importsjs
для удобного упорядочивания библиотек и отделения их от остальной кодовой базы их можно загружать и экспортировать из файла importsjs

например вот страница на которой используется umdсборка dayjs и esmсборка webvitals


рендеринг текста выполнен компонентом xmetrics

componentsmetricsjs

import  dayjs webvitals  from libimportsjs

class metricscomponent extends htmlelement 
    now  dayjs
    ttfb
    interval

    connectedcallback 
        webvitalsonttfb_  thisttfb  mathround_value
        thisinterval  setinterval  thisupdate 500
    

    disconnectedcallback 
        clearintervalthisinterval
        thisinterval  null
    

    update 
        thisinnerhtml  
            ppage loaded thisnowfromnow ttfb thisttfb millisecondsp
        
    


export const registermetricscomponent    
    customelementsdefinexmetrics metricscomponent

в папке lib находятся следующие файлы


webvitalsjs  esmсборка webvitals
dayjs

dayjsminjs  umdсборка dayjs
relativetimejs  umdсборка этого плагина dayjs

importsjs

изучив глубже последний файл мы увидим как он выполняет загрузку сторонних зависимостей

libimportsjs

 umdверсия dayjs с httpsunpkgcomdayjs
const dayjs  windowdayjs
const dayjsrelativetime  windowdayjs_plugin_relativetime
dayjsextenddayjsrelativetime

 esmверсия webvitals с httpsunpkgcomwebvitalsdistwebvitalsjs
import  as webvitals from webvitalsjs

export  dayjs webvitals 
он импортирует esmбиблиотеку напрямую но подтягивает umdбиблиотеки из объекта window они загружаются в html

вот объединённый пример

indexhtml

doctype html
html langen
head
    link relstylesheet hrefindexcss
head
body
    script srclibdayjsdayjsminjsscript
    script srclibdayjsrelativetimejsscript

    script typemodule srcindexjsscript
    xmetricsxmetrics
body
html
indexcss

body  fontfamily sansserif 
indexjs
import  registermetricscomponent  from componentsmetricsjs

const app    
    registermetricscomponent


documentaddeventlistenerdomcontentloaded app
componentsmetricsjs
import  dayjs webvitals  from libimportsjs

class metricscomponent extends htmlelement 
    now  dayjs
    ttfb
    interval

    connectedcallback 
        webvitalsonttfb_  thisttfb  mathround_value
        thisinterval  setinterval  thisupdate 500
    

    disconnectedcallback 
        clearintervalthisinterval
        thisinterval  null
    

    update 
        thisinnerhtml  
            ppage loaded thisnowfromnow ttfb thisttfb millisecondsp
        
    


export const registermetricscomponent    
    customelementsdefinexmetrics metricscomponent

libimportsjs

 umdверсия dayjs с httpsunpkgcomdayjs
const dayjs  windowdayjs
const dayjsrelativetime  windowdayjs_plugin_relativetime
dayjsextenddayjsrelativetime

 esmверсия webvitals с httpsunpkgcomwebvitalsdistwebvitalsjs
import  as webvitals from webvitalsjs

export  dayjs webvitals 
к сожалению не у всех библиотек есть umd или esmсборки но их становится всё больше

 import map
альтернативой способу с importsjs могут стать import map они определяют уникальное отображение между именем модуля который можно импортировать и соответствующим файлом библиотеки в особом теге script в head html они позволяют использовать в остальной части кодовой базы более традиционный синтаксис импорта на основе модулей

вот как будет выглядеть предыдущий пример адаптированный под использование import map

indexhtml

doctype html
html langen
head
    link relstylesheet hrefindexcss
    script srclibdayjsdayjsminjsscript
    script srclibdayjsrelativetimejsscript
    script typeimportmap
        
            imports 
                dayjs libdayjsmodulejs
                webvitals libwebvitalsjs
            
        
    script
head
body
    script typemodule srcindexjsscript
    xmetricsxmetrics
body
html
libdayjsmodulejs

 umdверсия dayjs с httpsunpkgcomdayjs
const dayjs  windowdayjs
const dayjsrelativetime  windowdayjs_plugin_relativetime
dayjsextenddayjsrelativetime

export default dayjs
componentsmetricsjs

import dayjs from dayjs
import  as webvitals from webvitals

class metricscomponent extends htmlelement 
    now  dayjs
    ttfb
    interval

    connectedcallback 
        webvitalsonttfb_  thisttfb  mathround_value
        thisinterval  setinterval  thisupdate 500
    

    disconnectedcallback 
        clearintervalthisinterval
        thisinterval  null
    

    update 
        thisinnerhtml  
            ppage loaded thisnowfromnow ttfb thisttfb millisecondsp
        
    


export const registermetricscomponent    
    customelementsdefinexmetrics metricscomponent

при использовании import map нужно учитывать следующие аспекты


import map могут отображаться только на esmмодули поэтому для библиотек umd необходимы обёртки как в случае с обёрткой modulejs для dayjs в этом примере
внешние import map вида script typeimportmap srcimportmapjson пока поддерживаются не всеми браузерами изза этого import map должны дублироваться на каждой htmlстранице
import map должна определяться до загрузки скрипта indexjs предпочтительно из раздела lthead
import map можно использовать для более простой загрузки библиотек из папки node_modules или из cdn можно использовать jspm generator для быстрого создания import map для зависимостей for cdn однако при этом стоит иметь в виду что изза добавления таких внешних зависимостей ванильная кодовая база будет зависеть от постоянной доступности соответствующего сервиса

браузерная поддержка
ванильные вебсайты поддерживаются всеми современными браузерами но что это значит


весь наш сайт работает в текущих версиях safari chrome edge и firefox
весь наш сайт имеет уровень поддержки 95 или выше на caniusecom за исключением import map 92 декларативных shadow dom 89 и вложенности css 88 но вскоре их поддержка расширится
в свою очередь это означает что можно без проблем использовать http2 семантические элементы html5 пользовательские элементы шаблоны shadow dom mutationobserver customevent formdata и api elementclosest
также можно гарантированно использовать модули javascript ecmascript 6  2015 ecmascript 8  2017 и ecmascript 11  2020
в css можно гарантированно использовать import переменные calc flexbox grid display contents и многое другое

чтобы следить за новыми вебстандартами изучайте следующие проекты


baseline отслеживает фичи широко доступные в браузерах а также сообщает когда их безопасно использовать
interop  это ежегодная инициатива разработчиков браузеров по внедрению новых фич вебплатформы во все браузеры можно считать её предварительным обзором того что вскоре войдёт в baseline

развёртывание
для развёртывания сайта можно выбрать любого провайдера способного хостить статические вебсайты

на примере github pages


загрузите проект как репозиторий на github
перейдите в settings pages
source github actions
static website configure
перейдите к path и измените его на public
выполните коммит изменений
зайдите на страницу actions репозитория и дождитесь развёртывания сайта

тестирование
все популярные фреймворки тестирования предназначены для работы в конвейерах сборки
однако у ванильного вебсайта нет этапа сборки для тестирования вебкомпонентов можно применить старомодный подход тестирование в браузере при помощи фреймворка mocha

например вот юниттесты для компонента xtabpanel использованного для отображения вкладок панелей исходного кода на нашем вебсайте


а для того чтобы ещё глубже разобраться в коде покажу как выглядит тестирование исходного кода

testsindexhtml

doctype html
html langen
head
    titleplain vanilla  teststitle
    meta nameviewport contentwidthdevicewidth initialscale1 minimumscale1 
    link relicon hreffaviconico
    link relstylesheet hrefindexcss
     httpsunpkgcommocha922mochacss 
    link relstylesheet hreflibmochamochacss 
     httpsunpkgcomchai436chaijs 
    script srclibmochachaijsscript
     httpsunpkgcommocha922mochajs 
    script srclibmochamochajsscript
     httpsunpkgcomtestinglibrarydom8171disttestinglibrarydomumdjs 
    script srclibtestinglibrarydomumdjsscript
head
body
    div idmochadiv

    script typemodule classmochainit
        mochasetupbdd
        mochacheckleaks
    script

    script typemodule srctabpaneltestjsscript
    
     здесь другие тесты 

    script typemodule classmochaexec srcindexjsscript
body
html
testsindexjs

import  registertabpanelcomponent  from componentstabpaneltabpaneljs

const app    
    registertabpanelcomponent
    mocharun


documentaddeventlistenerdomcontentloaded app
teststabpaneltestjs

import  render screen waitfor expect fireevent  from importstestjs

const rendertabpanel    
    const div  documentcreateelementdiv
    divinnerhtml  
        xtabpanel
            xtab titletab 1 active
                ptab 1 contentp 
            xtab
            xtab titletab 2
                ptab 2 contentp
            xtab
        xtabpanel
    
    renderdiv


describetabpanel   
    itrenders a tabpanel with active tab async   
         arrange
        rendertabpanel
    
         assert
         выбрана активная вкладка
        const activetab  await screenfindbyroletab  name tab 1 selected true 
        expectactivetabtonotbeundefined
         активная tabpanel видима
        const activepanel  screengetbytexttab 1 content
        expectactivepaneltonotbeundefined
         контент неактивной tabpanel скрыт
        const tab2  screengetbytitletab 2
        await waitfor  expecttab2offsetparenttobenull
    
    
    itactivates a different tab on click async   
         arrange
        rendertabpanel
        const tab2  screengetbytitletab 2
    
         assert
         контент неактивной tabpanel скрыт
        await waitfor  expecttab2offsetparenttobenull
         находим кнопку неактивной вкладки и нажимаем на неё
        const tab2button  await screenfindbyroletab  name tab 2 
        expecttab2buttonnottobeundefined
        fireeventclicktab2button
         делаем видимым контент неактивной tabpanel
        await waitfor  expecttab2offsetparentnottobenull
    

testsimportstestjs

const  expect   windowchai
const  getbytext queries within waitfor fireevent   windowtestinglibrarydom

let rootcontainer
let screen

beforeeach  
     скрытый div в который тест может рендерить элементы
    rootcontainer  documentcreateelementdiv
    rootcontainerstyleposition  absolute
    rootcontainerstyleleft  10000px
    documentbodyappendchildrootcontainer
     предварительная привязка вспомогательных testinglibrarydom к rootcontainer
    screen  objectkeysqueriesreducehelpers key  
        const fn  querieskey
        helperskey  fnbindnull rootcontainer
        return helpers
     


aftereach  
    documentbodyremovechildrootcontainer
    rootcontainer  null


function renderel 
    rootcontainerappendchildel


export  
    rootcontainer 
    expect 
    render 
    getbytext screen within waitfor fireevent

примечания по работе с таким подходом


весь код для юниттестов в том числе и библиотеки тестирования выделен в подпапку publictests поэтому тесты будут доступны интерактивно если добавить tests к url развёрнутого сайта если вы не хотите развёртывать тесты на работающем вебсайте то исключите папку тестов на этапе развёртывания
в качестве фреймворков тестирования и проверки применяются mocha и chai потому что они работают в браузере без этапа сборки
для более удобных запросов к dom используется dom testing library файл importstestjs конфигурирует её для ванильного использования
важное ограничение заключается в том что dom testing library не может выполнять запросы внутри корней shadow чтобы выполнять тестирование внутри корней shadow необходимо сначала выполнить запрос к содержащему их вебкомпоненту получить дескриптор его свойства shadowroot а затем выполнить запрос внутри него
вебкомпоненты инициализируются асинхронным образом поэтому тестировать их может быть непросто используйте методы async dom testing library

пример
примером разработки может быть наш вебсайт его проект есть на github

telegramканал со скидками розыгрышами призов и новостями it 
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: contains_keywords
Аргументы: args=('\nЭто вторая статья из цикла переводов о веб-разработке на чистых (ванильных) технологиях — без фреймворков и сторонних инструментов, только HTML, CSS и JavaScript. В первой части мы обсудили, почему такой подход может быть разумной альтернативой современным фреймворкам и рассмотрели использование веб-компонентов в качестве базовых строительных блоков для создания более сложных примитивов. В этот раз поговорим про стилизацию, а также деплой компонентов в продакшен без использования сборщиков, фреймворков или серверной логики.\n\nСовременный CSS\nСовременные веб-приложения построены на основе богатого инструментария работы с CSS, связанного со множеством пакетов NPM и этапов сборки. Ванильное же веб-приложение может выбрать более легковесный путь, отказавшись от современных методик с предварительно обработанным CSS и выбрав нативные для браузеров стратегии.\n\nСброс\nСброс стилей до общего для всех браузеров среднего — стандартная практика в веб-разработке, и ванильные веб-приложения в этом ничем не отличаются.\n\nМинимальный сброс используется следующим сайтом:\n\nreset.css\n\n/* обобщённый минималистичный сброс CSS\n   источник вдохновения: https://www.digitalocean.com/community/tutorials/css-minimal-css-reset */\n\n:root {\n    box-sizing: border-box;\n    line-height: 1.4;\n    /* https://kilianvalkhof.com/2022/css-html/your-css-reset-needs-text-size-adjust-probably/ */\n    -moz-text-size-adjust: none;\n    -webkit-text-size-adjust: none;\n    text-size-adjust: none;\n}\n\n*, *::before, *::after {\n    box-sizing: inherit;\n}\n\nbody, h1, h2, h3, h4, h5, h6, p {\n    margin: 0;\n    padding: 0;\n    font-weight: normal;\n}\n\nimg {\n    max-width:100%;\n    height:auto;\n}\nВот другие варианты в порядке по возрастанию сложности:\n\nmodern-normalize — более подробное решение для сброса CSS в современных браузерах. Включение из CDN\n\nKraken — начальная точка для проектов фронтенда. Включает в себя сброс CSS, типографику, сетку и другие удобные инструменты. Включение из CDN\n\nPico CSS — готовый набор начинающего для стилизации семантического HTML, в том числе и для сброса CSS. Включение из CDN\n\nTailwind — если вы всё равно будете использовать Tailwind, то можете и использовать его сброс CSS. Включение из CDN\n\nШрифты\nТипографика — фундамент веб-сайта или приложения. Такой легковесный подход, как ванильная веб-разработка, должен согласоваться с легковесным подходом к типографике.\n\nВ Modern Font Stacks описываются разнообразные популярные шрифты и варианты отката, позволяющие не загружать пользовательские шрифты и не добавлять внешние зависимости.\n\nНа нашем сайте используется стек Geometric Humanist для обычного текста и стек Monospace Code для исходного кода.\n\nИнструментарий\nВ реальном веб-проекте в случае отсутствия правильной структуры объём CSS быстро становится огромным. Давайте рассмотрим инструментарий для создания такой структуры, который предоставляет нам CSS в современных браузерах.\n\n@import — самая базовая техника структурирования — это разбиение CSS на несколько файлов. Мы можем добавлять все эти файлы по порядку как теги <link> в index.html, но это быстро становится неудобным, если мы работаем с несколькими HTML-страницами. Вместо этого лучше импортировать их в index.css.\n\nНапример, вот основной файл CSS нашего сайта:\n\nindex.css\n\n@import url("./styles/reset.css");\n@import url("./styles/variables.css");\n@import url("./styles/global.css");\n@import url("./components/code-viewer/code-viewer.css");\n@import url("./components/tab-panel/tab-panel.css");\nНиже показан рекомендованный способ упорядочивания файлов CSS.\n\nПользовательские свойства (переменные) — переменные CSS можно использовать для централизованного определения шрифта и темы сайта.\n\nНапример, вот переменные для нашего сайта:\n\nvariables.css\n\n:root {\n    /* https://modernfontstacks.com/\n       geometric humanist font */\n    --font-system: Avenir, Montserrat, Corbel, source-sans-pro, sans-serif;\n    /* monospace code font */\n    --font-system-code: ui-monospace, \'Cascadia Code\', \'Source Code Pro\', Menlo, Consolas, \'DejaVu Sans Mono\', monospace;\n    --font-system-code-size: 0.8rem;\n\n    --background-color: white;\n\n    --text-color: black;\n    --text-color-mute: hsl(0, 0%, 40%);\n\n    --link-color: darkblue;\n\n    --nav-separator-color: goldenrod;\n    --nav-background-color: hsl(50, 50%, 95%);\n\n    --border-color: black;\n\n    --code-text-color: var(--text-color);\n    --code-text-color-bg: inherit;\n\n    --panel-title-color: black;\n    --panel-title-color-bg: cornsilk;\n}\nЕщё более мощными переменные CSS становятся в сочетании с calc().\n\nПользовательские элементы — область видимости стилей легко можно ограничить тегом пользовательского элемента. Например, все стили компонента аватара из предыдущей части статьи имеют в качестве префикса селектор x-avatar:\n\navatar.css\n\nx-avatar {\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    width: 2.5rem;\n    height: 2.5rem;\n}\n\nx-avatar[size=lg] {\n    width: 3.5rem;\n    height: 3.5rem;\n}\n\nx-avatar img {\n    border-radius: 9999px;\n    width: 100%;\n    height: 100%;\n    vertical-align: middle;\n    object-fit: cover;\n}\nПользовательские элементы также могут иметь произвольные атрибуты, которые могут использоваться селекторами, как в случае со стилем [size=lg] из этого примера.\n\nShadow DOM — добавление shadow DOM к веб-компоненту ещё сильнее изолирует его стили от остальной части страницы. Например, компонент x-header из предыдущей части стилизует свой элемент h1 внутри своего CSS, не влияя на содержащую его страницу и на дочерние элементы заголовка.\n\nВсе файлы CSS, которые нужно применить к shadow DOM, должны загружаться в неё явным образом, однако переменные CSS передаются в shadow DOM.\n\nОграничение shadow DOM заключается в том, что для использования внутри них пользовательских шрифтов их сначала нужно загрузить в «светлую» DOM.\n\nФайлы\nСуществует множество способов упорядочивания файлов CSS в репозитории; на нашем сайте применён такой:\n\n/index.css — корневой файл CSS, который импортирует все остальные при помощи @import.\n\n/styles/reset.css — первым делом импортируется сброс таблицы стилей.\n\n/styles/variables.css — все переменные CSS определены в отдельном файле, в том числе и система шрифтов.\n\n/styles/global.css — глобальные стили, применяемые для веб-страниц сайта.\n\n/components/example/example.css — все неглобальные стили относятся к конкретным компонентам и находятся в файле CSS, расположенном рядом с файлом JS компонента.\n\nОбласть видимости\nЧтобы избежать конфликта стилей между страницами и компонентами, по умолчанию у стилей должна быть локальная область видимости. В ванильной веб-разработке есть два основных механизма реализации этого.\n\n▍ Селекторы с префиксами\nВ случае пользовательских элементов, не имеющих shadow DOM, можно добавлять в стили префиксы с тегом пользовательского элемента. Например, вот простой веб-компонент, использующий селекторы с префиксами для создания локальной области видимости:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <link rel="stylesheet" href="index.css">\n</head>\n<body>\n    <x-example></x-example>\n    <p>This <p> is not affected, because it is outside the custom element.</p>\n    <script type="module" src="index.js"></script>\n</html>\nindex.js\n\nimport { registerExampleComponent } from \'./components/example/example.js\';\nconst app = () => {\n    registerExampleComponent();\n}\ndocument.addEventListener(\'DOMContentLoaded\', app);\nindex.css\n\n@import url("./components/example/example.css");\ncomponents/example/example.js\n\nclass ExampleComponent extends HTMLElement {\n    connectedCallback() {\n        this.innerHTML = \'<p>For example...</p>\';\n    }\n}\nexport const registerExampleComponent = () => {\n    customElements.define(\'x-example\', ExampleComponent);\n}\ncomponents/example/example.css\n\nx-example p {\n    font-family: casual, cursive;\n    color: darkblue;\n}\n\n▍ Подсказка: вложенность CSS\nЕсли вам нужен более чистый синтаксис и вас устраивает браузерная поддержка, то подумайте над использованием вложенности CSS.\n\ncomponents/example/example.css\n\nx-example {\n    p {\n        font-family: casual, cursive;\n        color: darkblue;\n    }\n}\n▍ Импорт Shadow DOM\nПользовательские элементы, использующие shadow DOM, изначально не стилизованы и имеют локальную область видимости, а все стили необходимо явным образом импортировать в них. Вот переработанный пример с префиксами для использования shadow DOM.\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<body>\n    <x-example>\n        <p>This <p> is not affected, even though it is slotted.</p>\n    </x-example>\n    <script type="module" src="index.js"></script>\n</body>\n</html>\nindex.js\n\nimport { registerExampleComponent } from \'./components/example/example.js\';\nconst app = () => {\n    registerExampleComponent();\n}\ndocument.addEventListener(\'DOMContentLoaded\', app);\ncomponents/example/example.js\n\nclass ExampleComponent extends HTMLElement {\n    constructor() {\n        super();\n        this.attachShadow({mode: \'open\'});\n        this.shadowRoot.innerHTML = `\n            <link rel="stylesheet" href="${import.meta.resolve(\'./example.css\')}">\n            <p>For example...</p>\n            <slot></slot>\n        `;\n    }\n}\nexport const registerExampleComponent = () => {\n    customElements.define(\'x-example\', ExampleComponent);\n}\ncomponents/example/example.css\n\np {\n    font-family: casual, cursive;\n    color: darkblue;\n}\n\nЧтобы использовать стили из окружающей страницы внутри shadow DOM, можно выбрать один из вариантов:\n\n\nОбщие файлы CSS можно импортировать внутрь shadow DOM при помощи тегов <link> или @import.\nНа переменные CSS, определённые на окружающей странице, можно ссылаться изнутри стилей shadow DOM.\nДля доминирования shadow DOM можно использовать псевдоэлемент ::part, чтобы раскрыть API для стилизации.\n\nЗамена модулей CSS\nЛокальную область видимости модулей CSS можно заменить одним из описанных выше способов изменения области видимости. Для образца возьмём каноничный пример модулей CSS из документации Next.JS:\n\napp/dashboard/layout.tsx\n\nimport styles from \'./styles.module.css\'\n \nexport default function DashboardLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return <section className={styles.dashboard}>{children}</section>\n}\napp/dashboard/styles.module.css\n.dashboard {\n    padding: 24px;\n}\nВ качестве ванильного веб-компонента он бы выглядел так:\n\ncomponents/dashboard/layout.js\n\nclass Layout extends HTMLElement {\n    constructor() {\n        super();\n        this.attachShadow({ mode: \'open\' });\n        this.shadowRoot.innerHTML = `\n            <link rel="stylesheet" href="${import.meta.resolve(\'styles.css\')}">\n            <section class="dashboard"><slot></slot></section>\n        `;\n    }\n}\n\nexport const registerLayoutComponent = \n    () => customElements.define(\'x-layout\', Layout);\ncomponents/dashboard/styles.css\n\n@import url("../shared.css");\n\n.dashboard {\n    padding: 24px;\n}\nТак как shadow DOM не наследует стили страницы, styles.css должен сначала импортировать стили, общие для страницы и «теневого» веб-компонента.\n\nЗамена PostCSS\nДавайте рассмотрим список возможностей на главной станице PostCSS.\n\nДобавление префиксов поставщика к правилам CSS с использованием значений из Can I Use — в большинстве сценариев использования префиксы поставщика больше не требуются. Показанный в примере псевдокласс :fullscreen теперь работает в браузерах без префиксов.\n\nПреобразование современного CSS в то, что может понимать большинство браузеров — современный CSS, который вы хотите использовать, скорее всего, уже поддерживается. Показанное в примере правило color: oklch() теперь работает во всех популярных браузерах.\n\nМодули CSS — см. альтернативы, описанные в предыдущем разделе. Организуйте согласованные форматы и избегайте ошибок в таблицах стилей при помощи stylelint. Можно добавить в Visual Studio Code расширение vscode-stylelint для выполнения того же линтинга во время разработки без необходимости встраивания его в этап сборки.\n\nПодведём итог: из-за отказа Microsoft от поддержки IE11 и постоянного совершенствования актуальных браузеров PostCSS по большей мере стал ненужным.\n\nЗамена SASS\nАналогично PostCSS, давайте разберём список основных возможностей SASS:\n\nПеременные — заменены пользовательскими свойствами CSS.\n\nВложенность — вложенность CSS недавно стала поддерживаться всеми популярными браузерами, что вполне может покрыть ваши потребности.\n\nМодули — можно аппроксимировать сочетанием @import, переменных CSS и описанных выше способов управления областями видимости.\n\nПримеси (mixin) — к сожалению, функция CSS-примесей, которая может заменить их, по-прежнему находится на этапе спецификации.\n\nОператоры — во многих случаях могут быть заменены встроенной функцией calc().\n\nПодведём итог: SASS намного мощнее, чем PostCSS, и хотя у многих его возможностей есть ванильные альтернативы, заменить его полностью не так легко. Вам самим решать, стоит ли увеличение сложности из-за препроцессора SASS его дополнительных возможностей.\n\nВанильные страницы\nДля веб-сайтов с большим количеством контента и низкой интерактивностью предпочтительна многостраничная структура.\n\nОтказавшись от использования фреймворков, мы должны будем писать эти HTML-страницы с нуля. При этом важно понимать, как должна выглядеть хорошая минимальная HTML-страница.\n\nexample.html\n\n<!doctype html>\n<html lang="en">\n    <head>\n        <title>Example</title>\n        <meta charset="utf-8">\n        <meta name="viewport" content="width=device-width" />\n        <link rel="stylesheet" href="index.css">\n    </head>\n    <body>\n        <noscript><strong><font color="#3AC1EF">Please enable JavaScript to view this page correctly.</font></strong></noscript>\n        <header>\n            title and navigation ...\n        </header>\n        <main>\n            main content ...\n        </main>\n        <footer>\n            byline and copyright ...\n        </footer>    \n        <script type="module" src="index.js"></script>\n    </body>\n</html>\nОбъяснение каждого элемента:\n\n<!doctype html> — требуется, чтобы HTML парсился как HTML5, а не как более старая версия.\n\n<html lang="en"> — атрибут lang рекомендован, чтобы язык страницы не определялся ошибочно.\n\n<head><title> — используется для вкладки браузера и сохранения в закладки; то есть, по сути, он обязателен.\n\n<head><meta charset="utf-8"> — это почти не требуется, но эту строку нужно добавить, чтобы страница точно интерпретировалась, как UTF-8. Очевидно, что в редакторе, используемом для создания этой страницы, тоже должна быть выбрана UTF-8.\n\n<head><meta name="viewport"> — необходимо для того, чтобы структура страницы удобно просматривалась на мобильных устройствах.\n\n<head><link rel="stylesheet" href="index.css"> — по стандарту таблица стилей загружается из <head> блокирующим образом, чтобы не возникала вспышка нестилизованного контента разметки страницы.\n\n<body><noscript> — так как веб-компоненты не работают JavaScript, обычно рекомендуется добавлять уведомление noscript для пользователей, у которых отключен JavaScript. Это уведомление должно присутствовать только на страницах с веб-компонентами. Если вы не хотите показывать ничего, кроме уведомления, то см. показанный ниже шаблонный паттерн.\n\n<body><header/main/footer> — разметка страницы должна быть упорядочена при помощи HTML-маркеров (landmark). При правильном использовании landmark помогают в разбиении страницы на логические блоки и обеспечении accessibility структуры страницы. Так как они созданы на основе стандартов, повышается вероятность их совместимости с уже существующими и новыми инструментами accessibility.\n\n<body><script type="module" src="index.js"> — основной файл JavaScript находится в конце, он загружает веб-компоненты.\n\nНа страницах, где содержимое должно отображаться только при включенном JavaScript, можно использовать следующий шаблонный паттерн:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n    <head>\n        <title>Example</title>\n        <meta charset="utf-8">\n        <meta name="viewport" content="width=device-width" />\n        <link rel="stylesheet" href="index.css">\n    </head>\n    <body>\n        <noscript><strong><font color="#3AC1EF">Please enable JavaScript to view this page.</font></strong></noscript>\n        <template id="page">\n            <header>\n                title and navigation ...\n            </header>\n            <main>\n                main content ...\n            </main>\n            <footer>\n                byline and copyright ...\n            </footer>    \n        </template>\n        <script type="module" src="index.js"></script>\n    </body>\n</html>\nindex.js\n\nconst app = () => {\n    const template = document.querySelector(\'template#page\');\n    if (template) document.body.appendChild(template.content, true);\n}\n\ndocument.addEventListener(\'DOMContentLoaded\', app);\n▍ Важность семантики\nВ разметке страницы по умолчанию должен использоваться семантический HTML для повышения accessibility и улучшения SEO. Веб-компоненты следует использовать только в тех случаях, когда сложность и степень взаимодействий превышает возможности стандартной HTML-разметки.\n\nОсвойте следующие аспекты семантического HTML:\n\nLandmark (маркеры) — как говорилось выше, landmark — это фундамент структуры страницы, по умолчанию обеспечивающие качественную структуру и accessibility.\n\nЭлементы — хорошее знание множества встроенных элементов HTML сэкономит вам время благодаря отсутствию необходимости пользовательских элементов и упрощению реализации в случае необходимости пользовательских элементов. При правильном использовании HTML-элементов они по умолчанию обеспечивают accessibility.\n\nФормы — при их полнофункциональном использовании встроенные формы HTML способны реализовывать множество сценариев применения интерактивности. Изучите такие их возможности, как разнообразные типы ввода, валидация на стороне клиента и псевдоклассы UI. Если вы не можете найти подходящего для себя типа ввода, то можете использовать связанные с формами пользовательские элементы, но учитывайте поддержку браузерами ElementInternals.\n\n▍ Фавиконки\nВероятно, вам захочется добавить в HTML элемент, не основанный на стандартах, а именно ссылку на фавиконку:\n\n\nЧтобы не усложнять, поместите favicon.ico в корень сайта и добавьте на неё ссылку в свой HTML: <link rel="icon" href="favicon.ico">\nМожете попробовать использовать фавиконки в SVG, но помните, что Safari их не поддерживает. Встройте тёмный режим в сам SVG фавиконки или для большего удобства воспользуйтесь генератором наподобие RealFaviconGenerator.\nУчтите, что поскольку фавиконки не основаны на опубликованных стандартах веба, будет довольно сложно полностью реализовать стандарт де-факто.\n\nПроект\nРекомендуемая структура проекта для ванильного многостраничного веб-сайта такова:\n\n/ — в корне проекта находятся файлы, которые не будут публиковаться, например, README.md, LICENSE и .gitignore.\n\n/public — папка public публикуется в неизменном виде, без этапов сборки. В ней заключается весь веб-сайт.\n\n/public/index.html — главная лендинг-страница веб-сайта, не особо отличающаяся от других страниц, за исключением пути.\n\n/public/index.[js/css] — основная таблица стилей и javascript. Они содержат общие для всех страниц стили и код.\n\nindex.js загружает и регистрирует веб-компоненты, используемые на всех страницах. Если сделать его общим для нескольких HTML-страниц, то можно избежать ненужного дублирования и рассогласованности между страницами.\n\n/public/pages/[имя].html — все прочие страницы сайта, каждая из которых включает в себя одинаковые index.js и index.css и, разумеется, содержит непосредственно контент в виде разметки HTML с использованием веб-компонентов.\n\npublic/components/[name]/ — по одной папке на каждый веб-компонент, содержащей файлы [имя].js и [имя].css. Файл .js импортируется в файл index.js для регистрации веб-компонента. Файл .css, как говорилось выше, импортируется в глобальный index.css или в shadow DOM.\n\n/public/lib/ — для всех внешних библиотек, используемых как зависимости. Ниже мы расскажем о том, как добавлять и использовать эти зависимости.\n\n/public/styles/ — глобальные стили, на которые ссылается index.css.\n\nФайлы конфигурации для повышения удобства работы в редакторах программиста тоже размещаются в корне проекта. Благодаря расширениям редактора основная часть процесса разработки возможна без этапа сборки. Пример см. в статье о настройке Visual Studio Code.\n\nМаршрутизация\n«Олдскульный» способ маршрутизации стандартных HTML-страниц и связующих их тегов <a> обладает следующими преимуществами: простое индексирование поисковыми движками и изначальная полная поддержка функциональности истории браузера и закладок.\n\nЗависимости\nВ процессе разработки вам могут потребоваться сторонние библиотеки. Их можно использовать без npm и бандлера.\n\nUnpkg\nЧтобы использовать библиотеки без бандлера, их предварительно нужно собрать в формат ESM или UMD. Такие библиотеки можно скачать с unpkg.com:\n\n\nЗайдите на unpkg.com/[library]/ (последняя косая черта важна), например, на unpkg.com/microlight/\nНайдите и скачайте файл библиотеки js, который может находиться в подпапке, например, в dist, esm или umd\nПоместите файл библиотеки в папку lib/\n\nИли же библиотеку можно загрузить напрямую из CDN.\n\n▍ UMD\nФормат модулей UMD — это старый формат для библиотек, загружаемых из тега script; он обладает самой широкой поддержкой, особенно среди старых библиотек. Его можно распознать по наличию typeof define === \'function\' && define.amd в JS библиотеки.\n\nЧтобы включить его в свой проект, нужно выполнить следующие действия:\n\n\nВключить его в теге script: <script src="lib/microlight.js"></script>\nПолучить его у окна: const { microlight } = window;\n\n▍ ESM\nФормат модулей ESM (также называемый модулями JavaScript) — это формат, определённый стандартом ECMAScript; у новых и популярных библиотек обычно есть ESM-сборка. Её можно распознать по использованию ключевого слова export.\n\nЧтобы включить его в свой проект, нужно выполнить следующие действия:\n\n\nЗагрузить его из CDN:\n\nimport(\'https://unpkg.com/web-vitals@4.2.2/dist/web-vitals.js\').then((webVitals) => ...)\nИли загрузить из локальной копии:\n\nimport webVitals from \'lib/web-vitals.js\'\n\n▍ imports.js\nДля удобного упорядочивания библиотек и отделения их от остальной кодовой базы их можно загружать и экспортировать из файла imports.js.\n\nНапример, вот страница, на которой используется UMD-сборка Day.js и ESM-сборка web-vitals:\n\n\nРендеринг текста выполнен компонентом <x-metrics>:\n\ncomponents/metrics.js\n\nimport { dayjs, webVitals } from \'../lib/imports.js\';\n\nclass MetricsComponent extends HTMLElement {\n    #now = dayjs();\n    #ttfb;\n    #interval;\n\n    connectedCallback() {\n        webVitals.onTTFB(_ => this.#ttfb = Math.round(_.value));\n        this.#interval = setInterval(() => this.update(), 500);\n    }\n\n    disconnectedCallback() {\n        clearInterval(this.#interval);\n        this.#interval = null;\n    }\n\n    update() {\n        this.innerHTML = `\n            <p>Page loaded ${this.#now.fromNow()}, TTFB ${this.#ttfb} milliseconds</p>\n        `;\n    }\n}\n\nexport const registerMetricsComponent = () => {\n    customElements.define(\'x-metrics\', MetricsComponent);\n}\nВ папке /lib находятся следующие файлы:\n\n\nweb-vitals.js — ESM-сборка web-vitals\ndayjs/\n\ndayjs.min.js — UMD-сборка Day.js\nrelativeTime.js — UMD-сборка этого плагина Day.js\n\nimports.js\n\nИзучив глубже последний файл, мы увидим, как он выполняет загрузку сторонних зависимостей:\n\nlib/imports.js\n\n// UMD-версия dayjs с https://unpkg.com/dayjs/\nconst dayjs = window.dayjs;\nconst dayjsRelativeTime = window.dayjs_plugin_relativeTime;\ndayjs.extend(dayjsRelativeTime);\n\n// ESM-версия web-vitals с https://unpkg.com/web-vitals/dist/web-vitals.js\nimport * as webVitals from \'./web-vitals.js\';\n\nexport { dayjs, webVitals };\nОн импортирует ESM-библиотеку напрямую, но подтягивает UMD-библиотеки из объекта Window. Они загружаются в HTML.\n\nВот объединённый пример:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <link rel="stylesheet" href="index.css">\n</head>\n<body>\n    <script src="./lib/dayjs/dayjs.min.js"></script>\n    <script src="./lib/dayjs/relativeTime.js"></script>\n\n    <script type="module" src="index.js"></script>\n    <x-metrics></x-metrics>\n</body>\n</html>\nindex.css\n\nbody { font-family: sans-serif; }\nindex.js\nimport { registerMetricsComponent } from \'./components/metrics.js\';\n\nconst app = () => {\n    registerMetricsComponent();\n};\n\ndocument.addEventListener(\'DOMContentLoaded\', app);\ncomponents/metrics.js\nimport { dayjs, webVitals } from \'../lib/imports.js\';\n\nclass MetricsComponent extends HTMLElement {\n    #now = dayjs();\n    #ttfb;\n    #interval;\n\n    connectedCallback() {\n        webVitals.onTTFB(_ => this.#ttfb = Math.round(_.value));\n        this.#interval = setInterval(() => this.update(), 500);\n    }\n\n    disconnectedCallback() {\n        clearInterval(this.#interval);\n        this.#interval = null;\n    }\n\n    update() {\n        this.innerHTML = `\n            <p>Page loaded ${this.#now.fromNow()}, TTFB ${this.#ttfb} milliseconds</p>\n        `;\n    }\n}\n\nexport const registerMetricsComponent = () => {\n    customElements.define(\'x-metrics\', MetricsComponent);\n}\nlib/imports.js\n\n// UMD-версия dayjs с https://unpkg.com/dayjs/\nconst dayjs = window.dayjs;\nconst dayjsRelativeTime = window.dayjs_plugin_relativeTime;\ndayjs.extend(dayjsRelativeTime);\n\n// ESM-версия web-vitals с https://unpkg.com/web-vitals/dist/web-vitals.js\nimport * as webVitals from \'./web-vitals.js\';\n\nexport { dayjs, webVitals };\nК сожалению, не у всех библиотек есть UMD- или ESM-сборки, но их становится всё больше.\n\n▍ Import Map\nАльтернативой способу с imports.js могут стать import map. Они определяют уникальное отображение между именем модуля, который можно импортировать, и соответствующим файлом библиотеки в особом теге script в head HTML. Они позволяют использовать в остальной части кодовой базы более традиционный синтаксис импорта на основе модулей.\n\nВот, как будет выглядеть предыдущий пример, адаптированный под использование import map:\n\nindex.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <link rel="stylesheet" href="index.css">\n    <script src="./lib/dayjs/dayjs.min.js"></script>\n    <script src="./lib/dayjs/relativeTime.js"></script>\n    <script type="importmap">\n        {\n            "imports": {\n                "dayjs": "./lib/dayjs/module.js",\n                "web-vitals": "./lib/web-vitals.js"\n            }\n        }\n    </script>\n</head>\n<body>\n    <script type="module" src="index.js"></script>\n    <x-metrics></x-metrics>\n</body>\n</html>\nlib/dayjs/module.js\n\n// UMD-версия dayjs с https://unpkg.com/dayjs/\nconst dayjs = window.dayjs;\nconst dayjsRelativeTime = window.dayjs_plugin_relativeTime;\ndayjs.extend(dayjsRelativeTime);\n\nexport default dayjs;\ncomponents/metrics.js\n\nimport dayjs from \'dayjs\';\nimport * as webVitals from \'web-vitals\';\n\nclass MetricsComponent extends HTMLElement {\n    #now = dayjs();\n    #ttfb;\n    #interval;\n\n    connectedCallback() {\n        webVitals.onTTFB(_ => this.#ttfb = Math.round(_.value));\n        this.#interval = setInterval(() => this.update(), 500);\n    }\n\n    disconnectedCallback() {\n        clearInterval(this.#interval);\n        this.#interval = null;\n    }\n\n    update() {\n        this.innerHTML = `\n            <p>Page loaded ${this.#now.fromNow()}, TTFB ${this.#ttfb} milliseconds</p>\n        `;\n    }\n}\n\nexport const registerMetricsComponent = () => {\n    customElements.define(\'x-metrics\', MetricsComponent);\n}\nПри использовании import map нужно учитывать следующие аспекты:\n\n\nImport map могут отображаться только на ESM-модули, поэтому для библиотек UMD необходимы обёртки, как в случае с обёрткой module.js для dayjs в этом примере.\nВнешние import map вида <script type="importmap" src="importmap.json"> пока поддерживаются не всеми браузерами. Из-за этого import map должны дублироваться на каждой HTML-странице.\nImport map должна определяться до загрузки скрипта index.js, предпочтительно из раздела &lthead>.\nImport map можно использовать для более простой загрузки библиотек из папки node_modules или из CDN. Можно использовать JSPM generator для быстрого создания import map для зависимостей for CDN. Однако при этом стоит иметь в виду, что из-за добавления таких внешних зависимостей ванильная кодовая база будет зависеть от постоянной доступности соответствующего сервиса.\n\nБраузерная поддержка\nВанильные веб-сайты поддерживаются всеми современными браузерами. Но что это значит?\n\n\nВесь наш сайт работает в текущих версиях Safari, Chrome, Edge и Firefox.\nВесь наш сайт имеет уровень поддержки 95% или выше на caniuse.com, за исключением Import Map (92%), декларативных Shadow DOM (89%) и вложенности CSS (88%), но вскоре их поддержка расширится.\nВ свою очередь, это означает, что можно без проблем использовать HTTP/2, семантические элементы HTML5, пользовательские элементы, шаблоны, Shadow DOM, MutationObserver, CustomEvent, FormData и API Element.closest.\nТакже можно гарантированно использовать модули JavaScript, ECMAScript 6 / 2015, ECMAScript 8 / 2017 и ECMAScript 11 / 2020.\nВ CSS можно гарантированно использовать @import, переменные, calc(), flexbox, grid, display: contents и многое другое.\n\nЧтобы следить за новыми веб-стандартами, изучайте следующие проекты:\n\n\nBaseline отслеживает фичи, широко доступные в браузерах, а также сообщает, когда их безопасно использовать.\nInterop — это ежегодная инициатива разработчиков браузеров по внедрению новых фич веб-платформы во все браузеры. Можно считать её предварительным обзором того, что вскоре войдёт в baseline.\n\nРазвёртывание\nДля развёртывания сайта можно выбрать любого провайдера, способного хостить статические веб-сайты.\n\nНа примере GitHub Pages:\n\n\nЗагрузите проект как репозиторий на GitHub\nПерейдите в Settings, Pages\nSource: GitHub Actions\nStatic Website, Configure\nПерейдите к path и измените его на ./public\nВыполните коммит изменений...\nЗайдите на страницу Actions репозитория и дождитесь развёртывания сайта\n\nТестирование\nВсе популярные фреймворки тестирования предназначены для работы в конвейерах сборки.\nОднако у ванильного веб-сайта нет этапа сборки. Для тестирования веб-компонентов можно применить старомодный подход: тестирование в браузере при помощи фреймворка Mocha.\n\nНапример, вот юнит-тесты для компонента <x-tab-panel>, использованного для отображения вкладок панелей исходного кода на нашем веб-сайте:\n\n\nА для того, чтобы ещё глубже разобраться в коде, покажу, как выглядит тестирование исходного кода:\n\ntests/index.html\n\n<!doctype html>\n<html lang="en">\n<head>\n    <title>Plain Vanilla - Tests</title>\n    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />\n    <link rel="icon" href="../favicon.ico">\n    <link rel="stylesheet" href="../index.css">\n    <!-- https://unpkg.com/mocha@9.2.2/mocha.css -->\n    <link rel="stylesheet" href="./lib/mocha/mocha.css" />\n    <!-- https://unpkg.com/chai@4.3.6/chai.js -->\n    <script src="./lib/mocha/chai.js"></script>\n    <!-- https://unpkg.com/mocha@9.2.2/mocha.js -->\n    <script src="./lib/mocha/mocha.js"></script>\n    <!-- https://unpkg.com/@testing-library/dom@8.17.1/dist/@testing-library/dom.umd.js -->\n    <script src="./lib/@testing-library/dom.umd.js"></script>\n</head>\n<body>\n    <div id="mocha"></div>\n\n    <script type="module" class="mocha-init">\n        mocha.setup(\'bdd\');\n        mocha.checkLeaks();\n    </script>\n\n    <script type="module" src="./tabpanel.test.js"></script>\n    \n    <!-- здесь другие тесты -->\n\n    <script type="module" class="mocha-exec" src="./index.js"></script>\n</body>\n</html>\ntests/index.js\n\nimport { registerTabPanelComponent } from "../components/tab-panel/tab-panel.js";\n\nconst app = () => {\n    registerTabPanelComponent();\n    mocha.run();\n}\n\ndocument.addEventListener(\'DOMContentLoaded\', app);\ntests/tabpanel.test.js\n\nimport { render, screen, waitFor, expect, fireEvent } from \'./imports-test.js\';\n\nconst renderTabPanel = () => {\n    const div = document.createElement(\'div\');\n    div.innerHTML = `\n        <x-tab-panel>\n            <x-tab title="Tab 1" active>\n                <p>Tab 1 content</p> \n            </x-tab>\n            <x-tab title="Tab 2">\n                <p>Tab 2 content</p>\n            </x-tab>\n        </x-tab-panel>\n    `;\n    render(div);\n}\n\ndescribe(\'tabpanel\', () => {\n    it("renders a tabpanel with active tab", async () => {\n        // ARRANGE\n        renderTabPanel();\n    \n        // ASSERT\n        // выбрана активная вкладка\n        const activeTab = await screen.findByRole(\'tab\', { name: \'Tab 1\', selected: true });\n        expect(activeTab).to.not.be.undefined;\n        // активная tabpanel видима\n        const activePanel = screen.getByText(/Tab 1 content/);\n        expect(activePanel).to.not.be.undefined;\n        // контент неактивной tabpanel скрыт\n        const tab2 = screen.getByTitle(\'Tab 2\');\n        await waitFor(() => expect(tab2.offsetParent).to.be.null);\n    });\n    \n    it("activates a different tab on click", async () => {\n        // ARRANGE\n        renderTabPanel();\n        const tab2 = screen.getByTitle(\'Tab 2\');\n    \n        // ASSERT\n        // контент неактивной tabpanel скрыт\n        await waitFor(() => expect(tab2.offsetParent).to.be.null);\n        // находим кнопку неактивной вкладки и нажимаем на неё\n        const tab2Button = await screen.findByRole(\'tab\', { name: \'Tab 2\' });\n        expect(tab2Button).not.to.be.undefined;\n        fireEvent.click(tab2Button);\n        // делаем видимым контент неактивной tabpanel\n        await waitFor(() => expect(tab2.offsetParent).not.to.be.null);\n    });\n});\ntests/imports-test.js\n\nconst { expect } = window.chai;\nconst { getByText, queries, within, waitFor, fireEvent } = window.TestingLibraryDom;\n\nlet rootContainer;\nlet screen;\n\nbeforeEach(() => {\n    // скрытый div, в который тест может рендерить элементы\n    rootContainer = document.createElement("div");\n    rootContainer.style.position = \'absolute\';\n    rootContainer.style.left = \'-10000px\';\n    document.body.appendChild(rootContainer);\n    // предварительная привязка вспомогательных @testing-library/dom к rootContainer\n    screen = Object.keys(queries).reduce((helpers, key) => {\n        const fn = queries[key]\n        helpers[key] = fn.bind(null, rootContainer)\n        return helpers\n    }, {});\n});\n\nafterEach(() => {\n    document.body.removeChild(rootContainer);\n    rootContainer = null;\n});\n\nfunction render(el) {\n    rootContainer.appendChild(el);\n}\n\nexport { \n    rootContainer, \n    expect, \n    render, \n    getByText, screen, within, waitFor, fireEvent\n};\nПримечания по работе с таким подходом:\n\n\nВесь код для юнит-тестов, в том числе и библиотеки тестирования, выделен в подпапку public/tests/. Поэтому тесты будут доступны интерактивно, если добавить /tests к URL развёрнутого сайта. Если вы не хотите развёртывать тесты на работающем веб-сайте, то исключите папку тестов на этапе развёртывания.\nВ качестве фреймворков тестирования и проверки применяются Mocha и Chai, потому что они работают в браузере без этапа сборки.\nДля более удобных запросов к DOM используется DOM Testing Library. Файл imports-test.js конфигурирует её для ванильного использования.\nВажное ограничение заключается в том, что DOM Testing Library не может выполнять запросы внутри корней shadow. Чтобы выполнять тестирование внутри корней shadow, необходимо сначала выполнить запрос к содержащему их веб-компоненту, получить дескриптор его свойства shadowRoot, а затем выполнить запрос внутри него.\nВеб-компоненты инициализируются асинхронным образом, поэтому тестировать их может быть непросто. Используйте методы async DOM Testing Library.\n\nПример\nПримером разработки может быть наш веб-сайт. Его проект есть на GitHub.\n\nTelegram-канал со скидками, розыгрышами призов и новостями IT 💻', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('Патентная гонка за квантовым компьютером',), kwargs={}
Результат: патентная гонка за квантовым компьютером
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: contains_keywords
Аргументы: args=('Патентная гонка за квантовым компьютером', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('',), kwargs={}
Результат: 
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('web',), kwargs={}
Результат: web
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: normalize_text
Аргументы: args=('python',), kwargs={}
Результат: python
----------------------------------------
2025-05-19 17:36:30 - Вызов функции: contains_keywords
Аргументы: args=('', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: False
----------------------------------------
2025-05-19 17:36:31 - Вызов функции: normalize_text
Аргументы: args=('Вторая половина 1990-х и начало нулевых годов нашего века было временем, когда физики перешли от теории к практике.\xa0Были опробованы технологии манипуляции лазером с удерживаемыми ионами (ионами бериллия, удерживаемые в электромагнитной ловушке), которые выполняли роль кубитов, фундаментальных единиц квантовой информации. Также был реализован на практике первый квантовый логический вентиль. Появились сверхпроводящие кубиты, основанные на эффекте Джозефсона, с достаточно длительным временем когерентности и, главное, возможностью контролировать их квантовую когерентность. Были проведены эксперименты с использованием фотонов в качестве кубитов, которые демонстрировали относительно низкую скорость декогеренции, поскольку они слабо взаимодействуют с окружающей средой. Ими легче было манипулировать, передавать их на большие расстояния и использовать даже при комнатной температуре.\xa0Дальнейшая история квантового компьютера описана в деталях много раз и профессиональными IT-историками, и копирайтерами вовлеченных в процесс компаний, и в масс-медиа с фотографиями квантового холодильника, создающего внутри температуру близкую к абсолютному нулю, в виде люстры в стиле техно. Опубликованы десятки выверенных таймлайнов эволюции квантового компьютера на любой вкус — и длинные, и короткие. А если считать публикации в СМИ по поводу каждого шага в масштабировании числа кубитов и прочих инноваций в области квантовых компьютеров, то число этих публикаций уже можно измерять сотнями. Добавлять сюда еще одну нет смысла.Что же касается длившейся ровно 20 лет теоретической эпохи квантового компьютера, то итог ее подводит статья Дэвида ДиВинценцо, сотрудника IBM Research, R&D подразделения корпорации\xa0IBM, опубликованной\xa0им в 2000 году в журнале «Fortschritte der Physik» («Достижения физики»). В ней он перечислил пять основных требований к реальному (в «железе») квантовому компьютеру и два дополнительных для квантовой связи. Желающие могут посмотреть их самостоятельно, сейчас они выглядят само собой разумеющимися, да и число требований с тех пор выросло.\xa0С точки зрения истории квантового компьютера интересно в его статье другое. Его исследование выполнено на грант Army Research Office, директората в составе Армейской исследовательской лаборатории Командования по развитию боевых возможностей армии США\xa0(DEVCOM ARL), который отвечал за программу «внешних исследований армии», то есть исследований, которые Пентагон заказывал гражданским ученым, если компетентных армейских в данной области не имелось. Иными словами, военное ведомство США поинтересовалось мнением IBM насчет перспектив квантового компьютера. И Дэвид ДиВинценцо по поручению своего начальства в IBM в довольно сдержанных тонах, с оговорками (типа «пока конечная вычислительная мощность классических машин остается неизвестной»), изложил это мнение: при соблюдении определенных условий квантовый компьютер «имеет реальную перспективу с точки зрения научных исследований в области квантовой физики».\xa0А это — интерес ВПК к квантовому компьютеру — в свою очередь, означало господдержку разработчикам квантовых компьютеров, оживление у конкурентов IBM в предвидении скорого появления нового рынка и у венчурных фондов в ожидании новых стартапов, даром что все это происходило на фоне пика кризиса доткомов (их пузырь лопнул в марте 2000 года, а статья ДиВинценцо вышла в апреле того же года).\xa0Впрочем, единственным объективным показателем резкого нарастания интереса к квантовому компьютеру было оживление инженерно-изобретательской мысли в этой области. Это продемонстрировал скачок числа патентных заявок в 2001 году сразу на 70% по сравнению с 2000 годом. А ведь это были не научные статьи, а заявки на изобретение или усовершенствование конкретного квантового компьютера.\xa0Еще десять лет после этого инженеры и изобретатели работали, что называется, в кредит. Только в начале десятых годов нашего века состоялись первые купли-продажи реального квантового компьютера, правда, этот новый рынок и по сей день находится в зачаточном состоянии. Но жить можно и в кредит, особенно когда «запутанность денег», расходуемых на создание квантовых компьютеров (КК), и их «телепортация» из госбюджетов развитых стран (т.е. кармана тамошнего налогоплательщика) и из бюджетов частных компаний в карманы разработчиков и производителей КК достигла сотен миллионов долларов в год, приближаясь к миллиарду.\xa0До «квантового превосходства» в IT-секторе было еще очень далеко, но динамика трат на КК явно не подчинялась закону Мура, характеризовавшему ситуацию на рынке обычного компьютера полвека назад, когда он начал расти экспоненциально. Памятуя предупреждение Фейнмана, финансисты не углублялись в дебри квантовых парадоксов, а попытались понять, что происходит по косвенному показателю — ретроспективной динамике патентов на разновидности КК, ее географии и основным патентодержателям, то есть «патентному ландшафту», как удачно назвал этот инструмент патентной аналитики в 2015 году доцент Иллинойского технологического института Энтони Трипп.\xa0Подобных региональных ландшафтов нарисовано уже много, но, пожалуй, первый внятный общемировой ландшафт опубликовал в 2020 году французский финансовый аналитик Мишель Курек, проработавший четверть века в крупных французских банках и, главное, по первой своей специальности инженер-электронщик. Эта публикация свободно доступна в интернете, желающие могут почитать ее сами или хотя бы глянуть в ней на графики и гистограммы, чтобы увидеть, как быстро и причудливо менялся этот ландшафт.\xa0Если же коротко, то в Курек в основном анализирует патенты за период 2010-2020 гг. (всего он нашел их 9905 штук). Почему именно за этот период? Скорее всего потому, именно в это десятилетие среднегодовой их прирост составлял 18,8% (или 371% за десятилетие), а после 2015 года возрос до 27,15%. То есть шел уже по экспоненте. Тут, впрочем, надо делать поправку на то, что задержка с публикацией патентов после подачи патентной заявки обычно составляет 18 месяцев, то есть фактически это была статистика изобретений и усовершенствований в области КК-технологий за 2008-2018 гг.\xa0Кроме этого, в то десятилетие правительства Китая, США, Канады, Великобритании, стран ЕС (и отдельно ещё Германии) приступили к реализации крупных многолетних планов с объемом финансирования свыше $1 миллиарда. В частном секторе в 2018 году было осуществлено 32 операции по венчурному финансированию стартапов на общую сумму $173 млн в год. В 2019 году эти цифры были еще больше, а 2020 год с $479 млн только за первое полугодие стал рекордным. В конце 2019 года и наша страна объявила о своем пятилетнем плане в области квантовых технологий, собираясь выделить на них около $1млрд (было и такое!) из пакета общей программы исследований и разработок в области цифровых технологий (на том момент $3,7 млрд).И, наконец, в начале проанализированного Мишелем Куреком десятилетия, 2011 году, произошла первая купля-продажа реального, в «железе», а не чертежах, квантового компьютера канадской компании D-Wave Quantum Systems Inc.\xa0Его купила аэрокосмическая корпорация Lockheed Martin. В 2013 году следующую модель КК той же компании на пару приобрели NASA и Google Inc. Потом к ним прибавились новые покупатели — Университет Южной Калифорнии\xa0и Лос-Аламосская национальная лаборатория\xa0министерства энергетики США. Говорят, что Lockheed Martin заплатила за свою машину около 10 миллионов долларов, и «Гуглу» их КК обошелся в такую же сумму. Но покупатели про сумму заплаченных ими денег молчали, только сказали, что в нее входит обслуживание и ремонт их КК. Однако деньги явно были большими, тем более что это были не универсальные компьютеры (у «Гугла» помощнее, чем у «Локхид-Мартин»), а заточенные на только на одну разновидность квантового исчисления.Континентальная географии тоже была показательной. В это десятилетие на долю Азии (Китая с Японией, Южной Кореей, Тайванем, Индией и Малайзией) пришлось 64% патентов, на США вместе с Канадой — 21,6%, а на Европу в целом (включая ЕС, Великобританию, Швейцарию и Россию) — 13,5%. Вклад других континентов был минимален, только Австралия выделялась как место активных инноваций в этой области. Если смотреть по странам, то на долю США и Китая приходится более 75% всех патентов. Как раз в это десятилетие КНР обогнала Америку (5161 патент против 2401). Россия занимала 8 место (82 патента) после Австралии (104) и перед Францией (71). Всего же 32 страны подали заявки по крайней мере на один патент с датой приоритета после 2010 года.\xa0Что касается статистики подачи патентных заявок, то в ТОП-20 заявителей в 2010-2020 гг. вошли 11 китайских организаций, а именно: пять китайских компаний во главе с Ruban\xa0Quantum\xa0Technology Со. (1-е место в ТОП-20) и еще четыре компании (6-е, 9-е, 12-е и 18-е места); четыре университета (7-е, 8-е, 10-е и 19-е места) и два НИИ (12-е и 20-е места). Американских организаций там только шесть: IBM, Intel, Micromass, Thermo\xa0Fisher\xa0Scientific\xa0Inc. (в такой последовательности они занимают в ТОП-20 со 2-го по 5- место) и Google с Microsoft Technology Licensing (дочкой Microsoft Corporation), занимающих 14 и 15 место. Кроме китайцев и американцев в ТОП-20 японские Toshiba\xa0Corp. (11-место) и Shimadzu\xa0Corp. (13-е место), а также упоминавшаяся выше канадская компания D-Wave Quantum Systems Inc (16-е место).Разумеется, подать заявку на патент на КК и собрать его, поставить на поток и продавать — очень разные вещи, равно как и понятия заявителя на патент и его правообладателя, но картинка весьма показательная. Оказывается, по крайней мере в предыдущее нынешнему десятилетие, весьма активными генераторами патентных заявок в области КК были китайские университеты, почти наравне конкурируя в этом плане с такими IT-гигантам США, как IBM, Intel, Microsoft, Google. Что, как считает автор публикации, было результатом их стимуляции (в первую очередь бюджетными вливаниями, разумеется) партией и правительством КНР.Следующий патентный ландшафт КК подобного масштаба обрисовал в прошлом году Фанчжоу (Фред) Цю, тоже весьма опытный патентовед, штатный сотрудник отделения юридической компании Sheppard Mullin в Кремниевой Долине. Общая выручка Sheppard Mullin превышает $1 млрд в год, неопытных в таких фирмах не держат. Он рассматривал патенты во временном отрезке с 2004-го по 2023-й год включительно. Но если не считать всплеска патентной активности в последние годы, когда порог патентных заявок превысил 18 тыс. в год в целом картина оставалась такой же, как у Курека. По количеству опубликованных патентных заявок на КК лидировало Национальное управление интеллектуальной собственности Китая (CNIPA), за ним следовали Управление по патентам и товарным знакам США (USPTO), Европейское патентное ведомство (EPO) и Японское патентное ведомство (JPO) и далее остальные.Но на данном ландшафте есть весьма важное отличие. Здесь, образно говоря, появился рельеф «ведущих модальностей квантовых вычислений», то есть прослеживалась динамика патентов на разные физические подходы к реализации КК. И сразу стало видно, что, например,\xa0число патентных заявок на сверхпроводящие квантовые вычисления почти соответствует общему количеству патентных заявок на другие квантовые технологии вместе взятых.\xa0Интерпретировать это можно по-разному. В данном исследовании предлагается такое объяснение. Сверхпроводящие квантовые вычисления являются наиболее коммерчески зрелым подходом и отражают влияние богатых крупных корпораций, которые лидируют в этой области. Со стороны это выглядит немного смешно: получается, что им, крупным корпорациям, жалко уже потраченных ими денег на разработку сверхпроводящих КК, причем больших денег, и они полны решимости довести дело конца, чтобы вернуть свои затраты.После сверхпроводящих квантовых вычислений наибольшее количество патентных заявок приходится на технологии, основанные на фотонных, квантовых точечных, ионных ловушках и топологических методах.\xa0Относительно небольшое число патентных заявок на квантовые вычисления с использованием нейтральных атомов, ядерного магнитного резонанса и азотных вакансий, по той же финансовой логике, указывает на то, что эти технологии разрабатываются в основном академическими учреждениями и компаниями на ранних стадиях их, компаний, развития, то есть пока это хлеб бедных.\xa0Но что касается инженерно-изобретательской логики, особенно если она не ставится в рамки начальством, то несмотря на ранее сравнительно небольшое число патентных заявок на квантовые вычисления с нейтральным атомом, ЯМР и азотной вакансией в самые последние годы наблюдается их быстрый рост. При этом график ретроспективной динамики роста квантовых вычислений на нейтральных атомах точь-в-точь повторяет таковой для квантовых вычислений на фотонах и захваченных ионах, но с трехлетней задержкой. Что указывает на потенциал квантовых вычислений на нейтральных атомах стать основным подходом в создании универсального КК.Как образно писали в IT-блогах в прошлом году: «Сверхпроводящие кубиты до сих пор были зайцем в гонке за полномасштабными квантовыми вычислениями. Но теперь сзади приближается черепаха: кубиты, состоящие из нейтральных атомов. Недавние достижения превратили эти «кубиты на нейтральных атомах» из аутсайдеров в ведущих соперников». И добавляли, что «уже как минимум пять компаний стремятся коммерциализировать квантовые вычисления на нейтральных атомах».\xa0Впрочем, лучше самостоятельно посмотреть графики патентной динамики по всем 8 основным «модальностям квантовых вычислений» и, соответственно, «модальностям КК». Ландшафт Фреда Цю тоже свободно доступен в интернете. Тогда, наверное, вспомнится, что в 2015 году те же словах о черепахе, превращающейся в зайца в гонке за идеальным КК, говорили о квантовых точках (искусственных атомах, гигантских по\xa0сравнению с\xa0реальными атомами, с\xa0контролируемыми параметрами). А сейчас на графиках патентной активности как раз у КТ самая ломаная линия с двумя пиками и двумя провалам за последние 8 лет, действительно напоминающая заячье петляние.Что касается географии по модальностям, то США лидирует по патентным публикациям в области фотонных технологий и технологий квантовых точек, Китай — в области сверхпроводящих, ионных ловушек и топологических квантовых вычислений, у Японии заметен явный крен в сторону сверхпроводящих и фотонных технологий. Наиболее сбалансированное распределение по разным модальностям в европейских патентных публикациях.\xa0Также, наверное, стоит сказать, что хотя в Китае зарегистрировано наибольшее число патентных заявок по квантовым вычислениям, Америка лидирует по числу патентных заявок по каждому основному подходу к их физической реализации в виде КК.\xa0Это может указывать на то, что Штаты лидируют в научно-исследовательской деятельности в области квантового «железа», в то время как КНР уделяет больше внимания квантовому «софту».Сегодня речь идет о КК уже третьего поколения. Время от времени появляются сообщении об очередной демонстрации «квантового превосходства» над обычными компьютерами, когда КК за несколько минут совершают вычисления, на которые классическому компьютеру потребовалось был то годы, то миллиарды лет. Введены в строй КК с квантовоустойчивыми системами постквантовой криптографии. Вот только самого квантового компьютера, который имело бы смысл атаковать и взламывать, пока как не было, так и нет, есть только обещания, что вот-вот он появится. Ожидание его появления народ, похоже, уже сильно напрягает. Заметен скептицизм насчет его пользы вообще, мол, он никогда полностью не заменит классический компьютер Тьюринга, он эффективен лишь тогда, когда нужно перебрать множество вариантов и выбрать один правильный и в лучшем случае он будет использоваться в качестве сервера, который будет подключаться к обычному компьютеру по мере необходимости.Возможно, будет и так. Только не надо забывать, что КК всего 45 лет, включая его теоретическое «внутриутробное» развитие. А классический компьютер, если считать дату его рождения (или, по аналогии с КК «теоретического» зачатия) от двоичной арифметики и алгебры Лейбница (начало XVIII века), разностной машины Бэббиджа (первая половина XIX века), булевой системы алгебраической логики (середина XIX века) до алгоритма Тьюринга и первых мейнфреймов, скоро отпразднует свое 250-летие.А тем, кто сильно волнуется, что скептики все-таки окажутся правы, наверное, полезно напомнить про «Землю Санникова». То, что промысловику мамонтовых бивней Якову Санникову привиделось на горизонте «матерой землей», на деле оказалось маленьким островком Вилькицкого. Но не прошло и десяти лет, как Беллинсгаузен и Лазарев открыли Антарктиду. Пусть в другом полушарии, пусть не с пасущимися на ней мамонтами, а с пингвинами, но огромный и неведомый ранее материк. Инженерно-изобретательская мысль сейчас тоже видит на IT-горизонте нечто грандиозное и обязательно его откроет.Бесплатный поиск, мониторинг и регистрация товарных знаков\xa0 и других объектов интеллектуальной собственностиПоиск по программамРегистрация программы',), kwargs={}
Результат: вторая половина 1990х и начало нулевых годов нашего века было временем когда физики перешли от теории к практике были опробованы технологии манипуляции лазером с удерживаемыми ионами ионами бериллия удерживаемые в электромагнитной ловушке которые выполняли роль кубитов фундаментальных единиц квантовой информации также был реализован на практике первый квантовый логический вентиль появились сверхпроводящие кубиты основанные на эффекте джозефсона с достаточно длительным временем когерентности и главное возможностью контролировать их квантовую когерентность были проведены эксперименты с использованием фотонов в качестве кубитов которые демонстрировали относительно низкую скорость декогеренции поскольку они слабо взаимодействуют с окружающей средой ими легче было манипулировать передавать их на большие расстояния и использовать даже при комнатной температуре дальнейшая история квантового компьютера описана в деталях много раз и профессиональными itисториками и копирайтерами вовлеченных в процесс компаний и в массмедиа с фотографиями квантового холодильника создающего внутри температуру близкую к абсолютному нулю в виде люстры в стиле техно опубликованы десятки выверенных таймлайнов эволюции квантового компьютера на любой вкус  и длинные и короткие а если считать публикации в сми по поводу каждого шага в масштабировании числа кубитов и прочих инноваций в области квантовых компьютеров то число этих публикаций уже можно измерять сотнями добавлять сюда еще одну нет смыслачто же касается длившейся ровно 20 лет теоретической эпохи квантового компьютера то итог ее подводит статья дэвида дивинценцо сотрудника ibm research rd подразделения корпорации ibm опубликованной им в 2000 году в журнале fortschritte der physik достижения физики в ней он перечислил пять основных требований к реальному в железе квантовому компьютеру и два дополнительных для квантовой связи желающие могут посмотреть их самостоятельно сейчас они выглядят само собой разумеющимися да и число требований с тех пор выросло с точки зрения истории квантового компьютера интересно в его статье другое его исследование выполнено на грант army research office директората в составе армейской исследовательской лаборатории командования по развитию боевых возможностей армии сша devcom arl который отвечал за программу внешних исследований армии то есть исследований которые пентагон заказывал гражданским ученым если компетентных армейских в данной области не имелось иными словами военное ведомство сша поинтересовалось мнением ibm насчет перспектив квантового компьютера и дэвид дивинценцо по поручению своего начальства в ibm в довольно сдержанных тонах с оговорками типа пока конечная вычислительная мощность классических машин остается неизвестной изложил это мнение при соблюдении определенных условий квантовый компьютер имеет реальную перспективу с точки зрения научных исследований в области квантовой физики а это  интерес впк к квантовому компьютеру  в свою очередь означало господдержку разработчикам квантовых компьютеров оживление у конкурентов ibm в предвидении скорого появления нового рынка и у венчурных фондов в ожидании новых стартапов даром что все это происходило на фоне пика кризиса доткомов их пузырь лопнул в марте 2000 года а статья дивинценцо вышла в апреле того же года впрочем единственным объективным показателем резкого нарастания интереса к квантовому компьютеру было оживление инженерноизобретательской мысли в этой области это продемонстрировал скачок числа патентных заявок в 2001 году сразу на 70 по сравнению с 2000 годом а ведь это были не научные статьи а заявки на изобретение или усовершенствование конкретного квантового компьютера еще десять лет после этого инженеры и изобретатели работали что называется в кредит только в начале десятых годов нашего века состоялись первые куплипродажи реального квантового компьютера правда этот новый рынок и по сей день находится в зачаточном состоянии но жить можно и в кредит особенно когда запутанность денег расходуемых на создание квантовых компьютеров кк и их телепортация из госбюджетов развитых стран те кармана тамошнего налогоплательщика и из бюджетов частных компаний в карманы разработчиков и производителей кк достигла сотен миллионов долларов в год приближаясь к миллиарду до квантового превосходства в itсекторе было еще очень далеко но динамика трат на кк явно не подчинялась закону мура характеризовавшему ситуацию на рынке обычного компьютера полвека назад когда он начал расти экспоненциально памятуя предупреждение фейнмана финансисты не углублялись в дебри квантовых парадоксов а попытались понять что происходит по косвенному показателю  ретроспективной динамике патентов на разновидности кк ее географии и основным патентодержателям то есть патентному ландшафту как удачно назвал этот инструмент патентной аналитики в 2015 году доцент иллинойского технологического института энтони трипп подобных региональных ландшафтов нарисовано уже много но пожалуй первый внятный общемировой ландшафт опубликовал в 2020 году французский финансовый аналитик мишель курек проработавший четверть века в крупных французских банках и главное по первой своей специальности инженерэлектронщик эта публикация свободно доступна в интернете желающие могут почитать ее сами или хотя бы глянуть в ней на графики и гистограммы чтобы увидеть как быстро и причудливо менялся этот ландшафт если же коротко то в курек в основном анализирует патенты за период 20102020 гг всего он нашел их 9905 штук почему именно за этот период скорее всего потому именно в это десятилетие среднегодовой их прирост составлял 188 или 371 за десятилетие а после 2015 года возрос до 2715 то есть шел уже по экспоненте тут впрочем надо делать поправку на то что задержка с публикацией патентов после подачи патентной заявки обычно составляет 18 месяцев то есть фактически это была статистика изобретений и усовершенствований в области кктехнологий за 20082018 гг кроме этого в то десятилетие правительства китая сша канады великобритании стран ес и отдельно ещё германии приступили к реализации крупных многолетних планов с объемом финансирования свыше 1 миллиарда в частном секторе в 2018 году было осуществлено 32 операции по венчурному финансированию стартапов на общую сумму 173 млн в год в 2019 году эти цифры были еще больше а 2020 год с 479 млн только за первое полугодие стал рекордным в конце 2019 года и наша страна объявила о своем пятилетнем плане в области квантовых технологий собираясь выделить на них около 1млрд было и такое из пакета общей программы исследований и разработок в области цифровых технологий на том момент 37 млрди наконец в начале проанализированного мишелем куреком десятилетия 2011 году произошла первая купляпродажа реального в железе а не чертежах квантового компьютера канадской компании dwave quantum systems inc его купила аэрокосмическая корпорация lockheed martin в 2013 году следующую модель кк той же компании на пару приобрели nasa и google inc потом к ним прибавились новые покупатели  университет южной калифорнии и лосаламосская национальная лаборатория министерства энергетики сша говорят что lockheed martin заплатила за свою машину около 10 миллионов долларов и гуглу их кк обошелся в такую же сумму но покупатели про сумму заплаченных ими денег молчали только сказали что в нее входит обслуживание и ремонт их кк однако деньги явно были большими тем более что это были не универсальные компьютеры у гугла помощнее чем у локхидмартин а заточенные на только на одну разновидность квантового исчисленияконтинентальная географии тоже была показательной в это десятилетие на долю азии китая с японией южной кореей тайванем индией и малайзией пришлось 64 патентов на сша вместе с канадой  216 а на европу в целом включая ес великобританию швейцарию и россию  135 вклад других континентов был минимален только австралия выделялась как место активных инноваций в этой области если смотреть по странам то на долю сша и китая приходится более 75 всех патентов как раз в это десятилетие кнр обогнала америку 5161 патент против 2401 россия занимала 8 место 82 патента после австралии 104 и перед францией 71 всего же 32 страны подали заявки по крайней мере на один патент с датой приоритета после 2010 года что касается статистики подачи патентных заявок то в топ20 заявителей в 20102020 гг вошли 11 китайских организаций а именно пять китайских компаний во главе с ruban quantum technology со 1е место в топ20 и еще четыре компании 6е 9е 12е и 18е места четыре университета 7е 8е 10е и 19е места и два нии 12е и 20е места американских организаций там только шесть ibm intel micromass thermo fisher scientific inc в такой последовательности они занимают в топ20 со 2го по 5 место и google с microsoft technology licensing дочкой microsoft corporation занимающих 14 и 15 место кроме китайцев и американцев в топ20 японские toshiba corp 11место и shimadzu corp 13е место а также упоминавшаяся выше канадская компания dwave quantum systems inc 16е месторазумеется подать заявку на патент на кк и собрать его поставить на поток и продавать  очень разные вещи равно как и понятия заявителя на патент и его правообладателя но картинка весьма показательная оказывается по крайней мере в предыдущее нынешнему десятилетие весьма активными генераторами патентных заявок в области кк были китайские университеты почти наравне конкурируя в этом плане с такими itгигантам сша как ibm intel microsoft google что как считает автор публикации было результатом их стимуляции в первую очередь бюджетными вливаниями разумеется партией и правительством кнрследующий патентный ландшафт кк подобного масштаба обрисовал в прошлом году фанчжоу фред цю тоже весьма опытный патентовед штатный сотрудник отделения юридической компании sheppard mullin в кремниевой долине общая выручка sheppard mullin превышает 1 млрд в год неопытных в таких фирмах не держат он рассматривал патенты во временном отрезке с 2004го по 2023й год включительно но если не считать всплеска патентной активности в последние годы когда порог патентных заявок превысил 18 тыс в год в целом картина оставалась такой же как у курека по количеству опубликованных патентных заявок на кк лидировало национальное управление интеллектуальной собственности китая cnipa за ним следовали управление по патентам и товарным знакам сша uspto европейское патентное ведомство epo и японское патентное ведомство jpo и далее остальныено на данном ландшафте есть весьма важное отличие здесь образно говоря появился рельеф ведущих модальностей квантовых вычислений то есть прослеживалась динамика патентов на разные физические подходы к реализации кк и сразу стало видно что например число патентных заявок на сверхпроводящие квантовые вычисления почти соответствует общему количеству патентных заявок на другие квантовые технологии вместе взятых интерпретировать это можно поразному в данном исследовании предлагается такое объяснение сверхпроводящие квантовые вычисления являются наиболее коммерчески зрелым подходом и отражают влияние богатых крупных корпораций которые лидируют в этой области со стороны это выглядит немного смешно получается что им крупным корпорациям жалко уже потраченных ими денег на разработку сверхпроводящих кк причем больших денег и они полны решимости довести дело конца чтобы вернуть свои затратыпосле сверхпроводящих квантовых вычислений наибольшее количество патентных заявок приходится на технологии основанные на фотонных квантовых точечных ионных ловушках и топологических методах относительно небольшое число патентных заявок на квантовые вычисления с использованием нейтральных атомов ядерного магнитного резонанса и азотных вакансий по той же финансовой логике указывает на то что эти технологии разрабатываются в основном академическими учреждениями и компаниями на ранних стадиях их компаний развития то есть пока это хлеб бедных но что касается инженерноизобретательской логики особенно если она не ставится в рамки начальством то несмотря на ранее сравнительно небольшое число патентных заявок на квантовые вычисления с нейтральным атомом ямр и азотной вакансией в самые последние годы наблюдается их быстрый рост при этом график ретроспективной динамики роста квантовых вычислений на нейтральных атомах точьвточь повторяет таковой для квантовых вычислений на фотонах и захваченных ионах но с трехлетней задержкой что указывает на потенциал квантовых вычислений на нейтральных атомах стать основным подходом в создании универсального кккак образно писали в itблогах в прошлом году сверхпроводящие кубиты до сих пор были зайцем в гонке за полномасштабными квантовыми вычислениями но теперь сзади приближается черепаха кубиты состоящие из нейтральных атомов недавние достижения превратили эти кубиты на нейтральных атомах из аутсайдеров в ведущих соперников и добавляли что уже как минимум пять компаний стремятся коммерциализировать квантовые вычисления на нейтральных атомах впрочем лучше самостоятельно посмотреть графики патентной динамики по всем 8 основным модальностям квантовых вычислений и соответственно модальностям кк ландшафт фреда цю тоже свободно доступен в интернете тогда наверное вспомнится что в 2015 году те же словах о черепахе превращающейся в зайца в гонке за идеальным кк говорили о квантовых точках искусственных атомах гигантских по сравнению с реальными атомами с контролируемыми параметрами а сейчас на графиках патентной активности как раз у кт самая ломаная линия с двумя пиками и двумя провалам за последние 8 лет действительно напоминающая заячье петляниечто касается географии по модальностям то сша лидирует по патентным публикациям в области фотонных технологий и технологий квантовых точек китай  в области сверхпроводящих ионных ловушек и топологических квантовых вычислений у японии заметен явный крен в сторону сверхпроводящих и фотонных технологий наиболее сбалансированное распределение по разным модальностям в европейских патентных публикациях также наверное стоит сказать что хотя в китае зарегистрировано наибольшее число патентных заявок по квантовым вычислениям америка лидирует по числу патентных заявок по каждому основному подходу к их физической реализации в виде кк это может указывать на то что штаты лидируют в научноисследовательской деятельности в области квантового железа в то время как кнр уделяет больше внимания квантовому софтусегодня речь идет о кк уже третьего поколения время от времени появляются сообщении об очередной демонстрации квантового превосходства над обычными компьютерами когда кк за несколько минут совершают вычисления на которые классическому компьютеру потребовалось был то годы то миллиарды лет введены в строй кк с квантовоустойчивыми системами постквантовой криптографии вот только самого квантового компьютера который имело бы смысл атаковать и взламывать пока как не было так и нет есть только обещания что вотвот он появится ожидание его появления народ похоже уже сильно напрягает заметен скептицизм насчет его пользы вообще мол он никогда полностью не заменит классический компьютер тьюринга он эффективен лишь тогда когда нужно перебрать множество вариантов и выбрать один правильный и в лучшем случае он будет использоваться в качестве сервера который будет подключаться к обычному компьютеру по мере необходимостивозможно будет и так только не надо забывать что кк всего 45 лет включая его теоретическое внутриутробное развитие а классический компьютер если считать дату его рождения или по аналогии с кк теоретического зачатия от двоичной арифметики и алгебры лейбница начало xviii века разностной машины бэббиджа первая половина xix века булевой системы алгебраической логики середина xix века до алгоритма тьюринга и первых мейнфреймов скоро отпразднует свое 250летиеа тем кто сильно волнуется что скептики всетаки окажутся правы наверное полезно напомнить про землю санникова то что промысловику мамонтовых бивней якову санникову привиделось на горизонте матерой землей на деле оказалось маленьким островком вилькицкого но не прошло и десяти лет как беллинсгаузен и лазарев открыли антарктиду пусть в другом полушарии пусть не с пасущимися на ней мамонтами а с пингвинами но огромный и неведомый ранее материк инженерноизобретательская мысль сейчас тоже видит на itгоризонте нечто грандиозное и обязательно его откроетбесплатный поиск мониторинг и регистрация товарных знаков  и других объектов интеллектуальной собственностипоиск по программамрегистрация программы
----------------------------------------
2025-05-19 17:36:31 - Вызов функции: normalize_text
Аргументы: args=('дизайн',), kwargs={}
Результат: дизайн
----------------------------------------
2025-05-19 17:36:31 - Вызов функции: normalize_text
Аргументы: args=('фото',), kwargs={}
Результат: фото
----------------------------------------
2025-05-19 17:36:31 - Вызов функции: contains_keywords
Аргументы: args=('Вторая половина 1990-х и начало нулевых годов нашего века было временем, когда физики перешли от теории к практике.\xa0Были опробованы технологии манипуляции лазером с удерживаемыми ионами (ионами бериллия, удерживаемые в электромагнитной ловушке), которые выполняли роль кубитов, фундаментальных единиц квантовой информации. Также был реализован на практике первый квантовый логический вентиль. Появились сверхпроводящие кубиты, основанные на эффекте Джозефсона, с достаточно длительным временем когерентности и, главное, возможностью контролировать их квантовую когерентность. Были проведены эксперименты с использованием фотонов в качестве кубитов, которые демонстрировали относительно низкую скорость декогеренции, поскольку они слабо взаимодействуют с окружающей средой. Ими легче было манипулировать, передавать их на большие расстояния и использовать даже при комнатной температуре.\xa0Дальнейшая история квантового компьютера описана в деталях много раз и профессиональными IT-историками, и копирайтерами вовлеченных в процесс компаний, и в масс-медиа с фотографиями квантового холодильника, создающего внутри температуру близкую к абсолютному нулю, в виде люстры в стиле техно. Опубликованы десятки выверенных таймлайнов эволюции квантового компьютера на любой вкус — и длинные, и короткие. А если считать публикации в СМИ по поводу каждого шага в масштабировании числа кубитов и прочих инноваций в области квантовых компьютеров, то число этих публикаций уже можно измерять сотнями. Добавлять сюда еще одну нет смысла.Что же касается длившейся ровно 20 лет теоретической эпохи квантового компьютера, то итог ее подводит статья Дэвида ДиВинценцо, сотрудника IBM Research, R&D подразделения корпорации\xa0IBM, опубликованной\xa0им в 2000 году в журнале «Fortschritte der Physik» («Достижения физики»). В ней он перечислил пять основных требований к реальному (в «железе») квантовому компьютеру и два дополнительных для квантовой связи. Желающие могут посмотреть их самостоятельно, сейчас они выглядят само собой разумеющимися, да и число требований с тех пор выросло.\xa0С точки зрения истории квантового компьютера интересно в его статье другое. Его исследование выполнено на грант Army Research Office, директората в составе Армейской исследовательской лаборатории Командования по развитию боевых возможностей армии США\xa0(DEVCOM ARL), который отвечал за программу «внешних исследований армии», то есть исследований, которые Пентагон заказывал гражданским ученым, если компетентных армейских в данной области не имелось. Иными словами, военное ведомство США поинтересовалось мнением IBM насчет перспектив квантового компьютера. И Дэвид ДиВинценцо по поручению своего начальства в IBM в довольно сдержанных тонах, с оговорками (типа «пока конечная вычислительная мощность классических машин остается неизвестной»), изложил это мнение: при соблюдении определенных условий квантовый компьютер «имеет реальную перспективу с точки зрения научных исследований в области квантовой физики».\xa0А это — интерес ВПК к квантовому компьютеру — в свою очередь, означало господдержку разработчикам квантовых компьютеров, оживление у конкурентов IBM в предвидении скорого появления нового рынка и у венчурных фондов в ожидании новых стартапов, даром что все это происходило на фоне пика кризиса доткомов (их пузырь лопнул в марте 2000 года, а статья ДиВинценцо вышла в апреле того же года).\xa0Впрочем, единственным объективным показателем резкого нарастания интереса к квантовому компьютеру было оживление инженерно-изобретательской мысли в этой области. Это продемонстрировал скачок числа патентных заявок в 2001 году сразу на 70% по сравнению с 2000 годом. А ведь это были не научные статьи, а заявки на изобретение или усовершенствование конкретного квантового компьютера.\xa0Еще десять лет после этого инженеры и изобретатели работали, что называется, в кредит. Только в начале десятых годов нашего века состоялись первые купли-продажи реального квантового компьютера, правда, этот новый рынок и по сей день находится в зачаточном состоянии. Но жить можно и в кредит, особенно когда «запутанность денег», расходуемых на создание квантовых компьютеров (КК), и их «телепортация» из госбюджетов развитых стран (т.е. кармана тамошнего налогоплательщика) и из бюджетов частных компаний в карманы разработчиков и производителей КК достигла сотен миллионов долларов в год, приближаясь к миллиарду.\xa0До «квантового превосходства» в IT-секторе было еще очень далеко, но динамика трат на КК явно не подчинялась закону Мура, характеризовавшему ситуацию на рынке обычного компьютера полвека назад, когда он начал расти экспоненциально. Памятуя предупреждение Фейнмана, финансисты не углублялись в дебри квантовых парадоксов, а попытались понять, что происходит по косвенному показателю — ретроспективной динамике патентов на разновидности КК, ее географии и основным патентодержателям, то есть «патентному ландшафту», как удачно назвал этот инструмент патентной аналитики в 2015 году доцент Иллинойского технологического института Энтони Трипп.\xa0Подобных региональных ландшафтов нарисовано уже много, но, пожалуй, первый внятный общемировой ландшафт опубликовал в 2020 году французский финансовый аналитик Мишель Курек, проработавший четверть века в крупных французских банках и, главное, по первой своей специальности инженер-электронщик. Эта публикация свободно доступна в интернете, желающие могут почитать ее сами или хотя бы глянуть в ней на графики и гистограммы, чтобы увидеть, как быстро и причудливо менялся этот ландшафт.\xa0Если же коротко, то в Курек в основном анализирует патенты за период 2010-2020 гг. (всего он нашел их 9905 штук). Почему именно за этот период? Скорее всего потому, именно в это десятилетие среднегодовой их прирост составлял 18,8% (или 371% за десятилетие), а после 2015 года возрос до 27,15%. То есть шел уже по экспоненте. Тут, впрочем, надо делать поправку на то, что задержка с публикацией патентов после подачи патентной заявки обычно составляет 18 месяцев, то есть фактически это была статистика изобретений и усовершенствований в области КК-технологий за 2008-2018 гг.\xa0Кроме этого, в то десятилетие правительства Китая, США, Канады, Великобритании, стран ЕС (и отдельно ещё Германии) приступили к реализации крупных многолетних планов с объемом финансирования свыше $1 миллиарда. В частном секторе в 2018 году было осуществлено 32 операции по венчурному финансированию стартапов на общую сумму $173 млн в год. В 2019 году эти цифры были еще больше, а 2020 год с $479 млн только за первое полугодие стал рекордным. В конце 2019 года и наша страна объявила о своем пятилетнем плане в области квантовых технологий, собираясь выделить на них около $1млрд (было и такое!) из пакета общей программы исследований и разработок в области цифровых технологий (на том момент $3,7 млрд).И, наконец, в начале проанализированного Мишелем Куреком десятилетия, 2011 году, произошла первая купля-продажа реального, в «железе», а не чертежах, квантового компьютера канадской компании D-Wave Quantum Systems Inc.\xa0Его купила аэрокосмическая корпорация Lockheed Martin. В 2013 году следующую модель КК той же компании на пару приобрели NASA и Google Inc. Потом к ним прибавились новые покупатели — Университет Южной Калифорнии\xa0и Лос-Аламосская национальная лаборатория\xa0министерства энергетики США. Говорят, что Lockheed Martin заплатила за свою машину около 10 миллионов долларов, и «Гуглу» их КК обошелся в такую же сумму. Но покупатели про сумму заплаченных ими денег молчали, только сказали, что в нее входит обслуживание и ремонт их КК. Однако деньги явно были большими, тем более что это были не универсальные компьютеры (у «Гугла» помощнее, чем у «Локхид-Мартин»), а заточенные на только на одну разновидность квантового исчисления.Континентальная географии тоже была показательной. В это десятилетие на долю Азии (Китая с Японией, Южной Кореей, Тайванем, Индией и Малайзией) пришлось 64% патентов, на США вместе с Канадой — 21,6%, а на Европу в целом (включая ЕС, Великобританию, Швейцарию и Россию) — 13,5%. Вклад других континентов был минимален, только Австралия выделялась как место активных инноваций в этой области. Если смотреть по странам, то на долю США и Китая приходится более 75% всех патентов. Как раз в это десятилетие КНР обогнала Америку (5161 патент против 2401). Россия занимала 8 место (82 патента) после Австралии (104) и перед Францией (71). Всего же 32 страны подали заявки по крайней мере на один патент с датой приоритета после 2010 года.\xa0Что касается статистики подачи патентных заявок, то в ТОП-20 заявителей в 2010-2020 гг. вошли 11 китайских организаций, а именно: пять китайских компаний во главе с Ruban\xa0Quantum\xa0Technology Со. (1-е место в ТОП-20) и еще четыре компании (6-е, 9-е, 12-е и 18-е места); четыре университета (7-е, 8-е, 10-е и 19-е места) и два НИИ (12-е и 20-е места). Американских организаций там только шесть: IBM, Intel, Micromass, Thermo\xa0Fisher\xa0Scientific\xa0Inc. (в такой последовательности они занимают в ТОП-20 со 2-го по 5- место) и Google с Microsoft Technology Licensing (дочкой Microsoft Corporation), занимающих 14 и 15 место. Кроме китайцев и американцев в ТОП-20 японские Toshiba\xa0Corp. (11-место) и Shimadzu\xa0Corp. (13-е место), а также упоминавшаяся выше канадская компания D-Wave Quantum Systems Inc (16-е место).Разумеется, подать заявку на патент на КК и собрать его, поставить на поток и продавать — очень разные вещи, равно как и понятия заявителя на патент и его правообладателя, но картинка весьма показательная. Оказывается, по крайней мере в предыдущее нынешнему десятилетие, весьма активными генераторами патентных заявок в области КК были китайские университеты, почти наравне конкурируя в этом плане с такими IT-гигантам США, как IBM, Intel, Microsoft, Google. Что, как считает автор публикации, было результатом их стимуляции (в первую очередь бюджетными вливаниями, разумеется) партией и правительством КНР.Следующий патентный ландшафт КК подобного масштаба обрисовал в прошлом году Фанчжоу (Фред) Цю, тоже весьма опытный патентовед, штатный сотрудник отделения юридической компании Sheppard Mullin в Кремниевой Долине. Общая выручка Sheppard Mullin превышает $1 млрд в год, неопытных в таких фирмах не держат. Он рассматривал патенты во временном отрезке с 2004-го по 2023-й год включительно. Но если не считать всплеска патентной активности в последние годы, когда порог патентных заявок превысил 18 тыс. в год в целом картина оставалась такой же, как у Курека. По количеству опубликованных патентных заявок на КК лидировало Национальное управление интеллектуальной собственности Китая (CNIPA), за ним следовали Управление по патентам и товарным знакам США (USPTO), Европейское патентное ведомство (EPO) и Японское патентное ведомство (JPO) и далее остальные.Но на данном ландшафте есть весьма важное отличие. Здесь, образно говоря, появился рельеф «ведущих модальностей квантовых вычислений», то есть прослеживалась динамика патентов на разные физические подходы к реализации КК. И сразу стало видно, что, например,\xa0число патентных заявок на сверхпроводящие квантовые вычисления почти соответствует общему количеству патентных заявок на другие квантовые технологии вместе взятых.\xa0Интерпретировать это можно по-разному. В данном исследовании предлагается такое объяснение. Сверхпроводящие квантовые вычисления являются наиболее коммерчески зрелым подходом и отражают влияние богатых крупных корпораций, которые лидируют в этой области. Со стороны это выглядит немного смешно: получается, что им, крупным корпорациям, жалко уже потраченных ими денег на разработку сверхпроводящих КК, причем больших денег, и они полны решимости довести дело конца, чтобы вернуть свои затраты.После сверхпроводящих квантовых вычислений наибольшее количество патентных заявок приходится на технологии, основанные на фотонных, квантовых точечных, ионных ловушках и топологических методах.\xa0Относительно небольшое число патентных заявок на квантовые вычисления с использованием нейтральных атомов, ядерного магнитного резонанса и азотных вакансий, по той же финансовой логике, указывает на то, что эти технологии разрабатываются в основном академическими учреждениями и компаниями на ранних стадиях их, компаний, развития, то есть пока это хлеб бедных.\xa0Но что касается инженерно-изобретательской логики, особенно если она не ставится в рамки начальством, то несмотря на ранее сравнительно небольшое число патентных заявок на квантовые вычисления с нейтральным атомом, ЯМР и азотной вакансией в самые последние годы наблюдается их быстрый рост. При этом график ретроспективной динамики роста квантовых вычислений на нейтральных атомах точь-в-точь повторяет таковой для квантовых вычислений на фотонах и захваченных ионах, но с трехлетней задержкой. Что указывает на потенциал квантовых вычислений на нейтральных атомах стать основным подходом в создании универсального КК.Как образно писали в IT-блогах в прошлом году: «Сверхпроводящие кубиты до сих пор были зайцем в гонке за полномасштабными квантовыми вычислениями. Но теперь сзади приближается черепаха: кубиты, состоящие из нейтральных атомов. Недавние достижения превратили эти «кубиты на нейтральных атомах» из аутсайдеров в ведущих соперников». И добавляли, что «уже как минимум пять компаний стремятся коммерциализировать квантовые вычисления на нейтральных атомах».\xa0Впрочем, лучше самостоятельно посмотреть графики патентной динамики по всем 8 основным «модальностям квантовых вычислений» и, соответственно, «модальностям КК». Ландшафт Фреда Цю тоже свободно доступен в интернете. Тогда, наверное, вспомнится, что в 2015 году те же словах о черепахе, превращающейся в зайца в гонке за идеальным КК, говорили о квантовых точках (искусственных атомах, гигантских по\xa0сравнению с\xa0реальными атомами, с\xa0контролируемыми параметрами). А сейчас на графиках патентной активности как раз у КТ самая ломаная линия с двумя пиками и двумя провалам за последние 8 лет, действительно напоминающая заячье петляние.Что касается географии по модальностям, то США лидирует по патентным публикациям в области фотонных технологий и технологий квантовых точек, Китай — в области сверхпроводящих, ионных ловушек и топологических квантовых вычислений, у Японии заметен явный крен в сторону сверхпроводящих и фотонных технологий. Наиболее сбалансированное распределение по разным модальностям в европейских патентных публикациях.\xa0Также, наверное, стоит сказать, что хотя в Китае зарегистрировано наибольшее число патентных заявок по квантовым вычислениям, Америка лидирует по числу патентных заявок по каждому основному подходу к их физической реализации в виде КК.\xa0Это может указывать на то, что Штаты лидируют в научно-исследовательской деятельности в области квантового «железа», в то время как КНР уделяет больше внимания квантовому «софту».Сегодня речь идет о КК уже третьего поколения. Время от времени появляются сообщении об очередной демонстрации «квантового превосходства» над обычными компьютерами, когда КК за несколько минут совершают вычисления, на которые классическому компьютеру потребовалось был то годы, то миллиарды лет. Введены в строй КК с квантовоустойчивыми системами постквантовой криптографии. Вот только самого квантового компьютера, который имело бы смысл атаковать и взламывать, пока как не было, так и нет, есть только обещания, что вот-вот он появится. Ожидание его появления народ, похоже, уже сильно напрягает. Заметен скептицизм насчет его пользы вообще, мол, он никогда полностью не заменит классический компьютер Тьюринга, он эффективен лишь тогда, когда нужно перебрать множество вариантов и выбрать один правильный и в лучшем случае он будет использоваться в качестве сервера, который будет подключаться к обычному компьютеру по мере необходимости.Возможно, будет и так. Только не надо забывать, что КК всего 45 лет, включая его теоретическое «внутриутробное» развитие. А классический компьютер, если считать дату его рождения (или, по аналогии с КК «теоретического» зачатия) от двоичной арифметики и алгебры Лейбница (начало XVIII века), разностной машины Бэббиджа (первая половина XIX века), булевой системы алгебраической логики (середина XIX века) до алгоритма Тьюринга и первых мейнфреймов, скоро отпразднует свое 250-летие.А тем, кто сильно волнуется, что скептики все-таки окажутся правы, наверное, полезно напомнить про «Землю Санникова». То, что промысловику мамонтовых бивней Якову Санникову привиделось на горизонте «матерой землей», на деле оказалось маленьким островком Вилькицкого. Но не прошло и десяти лет, как Беллинсгаузен и Лазарев открыли Антарктиду. Пусть в другом полушарии, пусть не с пасущимися на ней мамонтами, а с пингвинами, но огромный и неведомый ранее материк. Инженерно-изобретательская мысль сейчас тоже видит на IT-горизонте нечто грандиозное и обязательно его откроет.Бесплатный поиск, мониторинг и регистрация товарных знаков\xa0 и других объектов интеллектуальной собственностиПоиск по программамРегистрация программы', ['дизайн', 'фото', 'web', 'python']), kwargs={}
Результат: True
----------------------------------------
2025-05-19 17:36:08 - Вызов функции: main
Аргументы: args=(), kwargs={}
Результат: complex object
----------------------------------------
